{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clasificacion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD4HrhR1SN7-"
      },
      "source": [
        "# Investigación corta #2. \r\n",
        "MÉTODOS DE APRENDIZAJE SUPERVISADO  \r\n",
        "\r\n",
        "David Martinez Garcia.\r\n",
        "Maestria en electrónica ITCR.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0hTkZYISmxK"
      },
      "source": [
        "# Selección y preprocesado de los datos.\r\n",
        "\r\n",
        "Debido a que la investigación se utilizó un set de datos en el cual no hay claridad de si es un set de datos para regresión o clasificación se busco un nuevo set de datos. \r\n",
        "\r\n",
        "En este caso, se propone el siguiente set: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \r\n",
        "\r\n",
        "Este set de datos corresponde a un set de datos que clasifica individuos y sus respectivos electrocardiogramas en 16 categorias. La categoria 1 corresponde a normal, la categoria 2-15 corresponde a un tipo de arritmia y la categoria 16 corresponde a otro tipo de patología."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMUcKw7uUEOF"
      },
      "source": [
        "Procederemos a cargar el set de datos al notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4TafP3GSMUh"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "arrhythmia_data = pd.read_csv(\"arrhythmia.data\", header=None)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-CCIrJpUf_2"
      },
      "source": [
        "Veamos las primeras lineas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "Hnc32Dn2UIdq",
        "outputId": "c19660a9-ecac-4559-a906-38f0111a4edc"
      },
      "source": [
        "arrhythmia_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>259</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>64</td>\n",
              "      <td>-2</td>\n",
              "      <td>?</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>-17</td>\n",
              "      <td>31</td>\n",
              "      <td>?</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34</td>\n",
              "      <td>70</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11</td>\n",
              "      <td>-5</td>\n",
              "      <td>20</td>\n",
              "      <td>?</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>61</td>\n",
              "      <td>3</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 280 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    ...  273  274  275  276   277   278 279\n",
              "0   75    0  190   80   91  193  371  ...  0.0  0.0  0.9  2.9  23.3  49.4   8\n",
              "1   56    1  165   64   81  174  401  ...  0.0  0.0  0.2  2.1  20.4  38.8   6\n",
              "2   54    0  172   95  138  163  386  ...  0.0  0.0  0.3  3.4  12.3  49.0  10\n",
              "3   55    0  175   94  100  202  380  ...  0.0  0.0  0.4  2.6  34.6  61.6   1\n",
              "4   75    0  190   80   88  181  360  ...  0.0  0.0 -0.1  3.9  25.4  62.8   7\n",
              "\n",
              "[5 rows x 280 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUvMEDR2U9tE"
      },
      "source": [
        "En primer lugar podemos notar que los nombres de las columnas no existen y ademas que hay algunos valores deconocidos. \"?\"\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ZGPoM6RqbIxq",
        "outputId": "ab243a76-fbb7-485e-e8bf-e502a2e9590a"
      },
      "source": [
        "names = [\"Age\",\"Sex\",\"Height\",\"Weight\",\"QRS duration\",\"P-R interval\",\"Q-T interval\",\"T interval\",\"P intervaL\",\"QRS\",\"T\",\"P\",\"QRST\",\"J\",\"Heart rate\",\"Q wave\",\"R wave\",\"S wave\",\"R' wave\",\"S' wave\",\"Number of intrinsic deflections\",\"Existence of ragged R wave\",\"Existence of diphasic derivation of R wave\",\"Existence of ragged P wavel\",\"Existence of diphasic derivation of P wave\",\"Existence of ragged T wave\",\"Existence of diphasic derivation of T wave\",\"DII_0\",\"DII_1\",\"DII_2\",\"DII_3\",\"DII_4\",\"DII_5\",\"DII_6\",\"DII_7\",\"DII_8\",\"DII_9\",\"DII_10\",\"DII_11\",\"DIII_0\",\"DIII_1\",\"DIII_2\",\"DIII_3\",\"DIII_4\",\"DIII_5\",\"DIII_6\",\"DIII_7\",\"DIII_8\",\"DIII_9\",\"DIII_10\",\"DIII_11\",\"AVR_0\",\"AVR_1\",\"AVR_2\",\"AVR_3\",\"AVR_4\",\"AVR_5\",\"AVR_6\",\"AVR_7\",\"AVR_8\",\"AVR_9\",\"AVR_10\",\"AVR_11\",\"AVL_0\",\"AVL_1\",\"AVL_2\",\"AVL_3\",\"AVL_4\",\"AVL_5\",\"AVL_6\",\"AVL_7\",\"AVL_8\",\"AVL_9\",\"AVL_10\",\"AVL_11\",\"AVF_0\",\"AVF_1\",\"AVF_2\",\"AVF_3\",\"AVF_4\",\"AVF_5\",\"AVF_6\",\"AVF_7\",\"AVF_8\",\"AVF_9\",\"AVF_10\",\"AVF_11\",\"V1_0\",\"V1_1\",\"V1_2\",\"V1_3\",\"V1_4\",\"V1_5\",\"V1_6\",\"V1_7\",\"V1_8\",\"V1_9\",\"V1_10\",\"V1_11\",\"V2_0\",\"V2_1\",\"V2_2\",\"V2_3\",\"V2_4\",\"V2_5\",\"V2_6\",\"V2_7\",\"V2_8\",\"V2_9\",\"V2_10\",\"V2_11\",\"V3_0\",\"V3_1\",\"V3_2\",\"V3_3\",\"V3_4\",\"V3_5\",\"V3_6\",\"V3_7\",\"V3_8\",\"V3_9\",\"V3_10\",\"V3_11\",\"V4_0\",\"V4_1\",\"V4_2\",\"V4_3\",\"V4_4\",\"V4_5\",\"V4_6\",\"V4_7\",\"V4_8\",\"V4_9\",\"V4_10\",\"V4_11\",\"V5_0\",\"V5_1\",\"V5_2\",\"V5_3\",\"V5_4\",\"V5_5\",\"V5_6\",\"V5_7\",\"V5_8\",\"V5_9\",\"V5_10\",\"V5_11\",\"V6_0\",\"V6_1\",\"V6_2\",\"V6_3\",\"V6_4\",\"V6_5\",\"V6_6\",\"V6_7\",\"V6_8\",\"V6_9\",\"V6_10\",\"V6_11\",\"JJ wave\",\"Q wave\",\"R wave\",\"S wave\",\"R' wave\",\"S' wave\",\"P wave\",\"T wave\",\"QRSA\",\"QRSTA\",\"DII_12\",\"DII_13\",\"DII_14\",\"DII_15\",\"DII_16\",\"DII_17\",\"DII_18\",\"DII_19\",\"DII_20\",\"DII_21\",\"DIII_12\",\"DIII_13\",\"DIII_14\",\"DIII_15\",\"DIII_16\",\"DIII_17\",\"DIII_18\",\"DIII_19\",\"DIII_20\",\"DIII_21\",\"AVR_12\",\"AVR_13\",\"AVR_14\",\"AVR_15\",\"AVR_16\",\"AVR_17\",\"AVR_18\",\"AVR_19\",\"AVR_20\",\"AVR_21\",\"AVL_12\",\"AVL_13\",\"AVL_14\",\"AVL_15\",\"AVL_16\",\"AVL_17\",\"AVL_18\",\"AVL_19\",\"AVL_20\",\"AVL_21\",\"AVF_12\",\"AVF_13\",\"AVF_14\",\"AVF_15\",\"AVF_16\",\"AVF_17\",\"AVF_18\",\"AVF_19\",\"AVF_20\",\"AVF_21\",\"V1_12\",\"V1_13\",\"V1_14\",\"V1_15\",\"V1_16\",\"V1_17\",\"V1_18\",\"V1_19\",\"V1_20\",\"V1_21\",\"V2_12\",\"V2_13\",\"V2_14\",\"V2_15\",\"V2_16\",\"V2_17\",\"V2_18\",\"V2_19\",\"V2_20\",\"V2_21\",\"V3_12\",\"V3_13\",\"V3_14\",\"V3_15\",\"V3_16\",\"V3_17\",\"V3_18\",\"V3_19\",\"V3_20\",\"V3_21\",\"V4_12\",\"V4_13\",\"V4_14\",\"V4_15\",\"V4_16\",\"V4_17\",\"V4_18\",\"V4_19\",\"V4_20\",\"V4_21\",\"V5_12\",\"V5_13\",\"V5_14\",\"V5_15\",\"V5_16\",\"V5_17\",\"V5_18\",\"V5_19\",\"V5_20\",\"V5_21\",\"V6_12\",\"V6_13\",\"V6_14\",\"V6_15\",\"V6_16\",\"V6_17\",\"V6_18\",\"V6_19\",\"V6_20\",\"V6_21\", \"Class\"]\r\n",
        "arrhythmia_data.columns = names\r\n",
        "arrhythmia_data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>J</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>...</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_17</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>64</td>\n",
              "      <td>-2</td>\n",
              "      <td>?</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>-17</td>\n",
              "      <td>31</td>\n",
              "      <td>?</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34</td>\n",
              "      <td>70</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11</td>\n",
              "      <td>-5</td>\n",
              "      <td>20</td>\n",
              "      <td>?</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13</td>\n",
              "      <td>61</td>\n",
              "      <td>3</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 280 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Sex  Height  Weight  QRS duration  ...  V6_18  V6_19  V6_20  V6_21  Class\n",
              "0   75    0     190      80            91  ...    0.9    2.9   23.3   49.4      8\n",
              "1   56    1     165      64            81  ...    0.2    2.1   20.4   38.8      6\n",
              "2   54    0     172      95           138  ...    0.3    3.4   12.3   49.0     10\n",
              "3   55    0     175      94           100  ...    0.4    2.6   34.6   61.6      1\n",
              "4   75    0     190      80            88  ...   -0.1    3.9   25.4   62.8      7\n",
              "\n",
              "[5 rows x 280 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmdmPdrKvJ2_"
      },
      "source": [
        "Veamos un resumen de lo que tenemos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohmpzoPIvJH9",
        "outputId": "faabd82f-1be1-41e1-b8a7-ddb7574c7815"
      },
      "source": [
        "arrhythmia_data['Heart rate'].describe()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     452\n",
              "unique     64\n",
              "top        72\n",
              "freq       21\n",
              "Name: Heart rate, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fm7wEJDcc_E"
      },
      "source": [
        "Convirtamos el set de datos a numerico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoxAPC1QchEH"
      },
      "source": [
        "arrhythmia_data_numeric = arrhythmia_data.apply(pd.to_numeric, errors='coerce')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSBc6w0NdH2d"
      },
      "source": [
        "Se puede evidenciar que para algunos valores (J, por ejemplo), existen valores NaN, se obtendrá la cantidad de valores NaN por columna para saber si estadisticamente es mejor eliminar alguna de esas columnas. Por ejemplo, en el caso de J tenemos que de 452, 376 son NaN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5k_KaZ9dW6P",
        "outputId": "d61c7343-7fd0-45e5-bcd2-8a388190eb31"
      },
      "source": [
        "arrhythmia_data_numeric.isna().sum()[0:15]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age               0\n",
              "Sex               0\n",
              "Height            0\n",
              "Weight            0\n",
              "QRS duration      0\n",
              "P-R interval      0\n",
              "Q-T interval      0\n",
              "T interval        0\n",
              "P intervaL        0\n",
              "QRS               0\n",
              "T                 8\n",
              "P                22\n",
              "QRST              1\n",
              "J               376\n",
              "Heart rate        1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ-WqwBFebim"
      },
      "source": [
        "Se plantea entonces eliminar las columnas cuyos datos tenga mas de 1/3 parte de NaN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "VRnORYL_eVk1",
        "outputId": "c81e834f-a2c2-4ef9-e1fc-f55f817d99b6"
      },
      "source": [
        "arrhythmia_data_numeric = arrhythmia_data_numeric.loc[:, (arrhythmia_data_numeric.isnull().sum(axis=0) <= len(arrhythmia_data_numeric.index)/3 )]\r\n",
        "arrhythmia_data_numeric.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>...</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_17</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>36</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 279 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Sex  Height  Weight  QRS duration  ...  V6_18  V6_19  V6_20  V6_21  Class\n",
              "0   75    0     190      80            91  ...    0.9    2.9   23.3   49.4      8\n",
              "1   56    1     165      64            81  ...    0.2    2.1   20.4   38.8      6\n",
              "2   54    0     172      95           138  ...    0.3    3.4   12.3   49.0     10\n",
              "3   55    0     175      94           100  ...    0.4    2.6   34.6   61.6      1\n",
              "4   75    0     190      80            88  ...   -0.1    3.9   25.4   62.8      7\n",
              "\n",
              "[5 rows x 279 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-t72LVkfkk4"
      },
      "source": [
        "Solo la columna J poseeía el desbalance de NaN Veamos cual es el maximo de NaN ahora:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-JWcf-ofvqT",
        "outputId": "256e246b-01ec-4358-ad27-775158a78d8f"
      },
      "source": [
        "arrhythmia_data_numeric.isna().sum().describe()\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    279.000000\n",
              "mean       0.114695\n",
              "std        1.401861\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        0.000000\n",
              "max       22.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4qmajeagGpg"
      },
      "source": [
        "El maximo corresponde a 22, o sea un 4.79% de los datos. Se considera que eso esta bien como para poder tratarlos de alguna otra manera. Veamos cuales categorias corresponden a los datos faltantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "qWDd68upzO_y",
        "outputId": "73e45b49-0567-41b2-d95e-a98e3b23891c"
      },
      "source": [
        "arrhythmia_data_numeric.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>...</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_17</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>36</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 279 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Sex  Height  Weight  QRS duration  ...  V6_18  V6_19  V6_20  V6_21  Class\n",
              "0   75    0     190      80            91  ...    0.9    2.9   23.3   49.4      8\n",
              "1   56    1     165      64            81  ...    0.2    2.1   20.4   38.8      6\n",
              "2   54    0     172      95           138  ...    0.3    3.4   12.3   49.0     10\n",
              "3   55    0     175      94           100  ...    0.4    2.6   34.6   61.6      1\n",
              "4   75    0     190      80            88  ...   -0.1    3.9   25.4   62.8      7\n",
              "\n",
              "[5 rows x 279 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dQYzkoGgF4t"
      },
      "source": [
        "na_data = arrhythmia_data_numeric.loc[:, arrhythmia_data_numeric.isna().any()]\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "SBpYwU802J-c",
        "outputId": "78eeee17-5181-415f-fe07-4eea1e4048d9"
      },
      "source": [
        "na_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>4.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>-27.0</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>66.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>-19.0</td>\n",
              "      <td>-61.0</td>\n",
              "      <td>-70.0</td>\n",
              "      <td>84.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>29.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>79.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        T     P  QRST  Heart rate\n",
              "0    13.0  64.0  -2.0        63.0\n",
              "1    37.0 -17.0  31.0        53.0\n",
              "2    34.0  70.0  66.0        75.0\n",
              "3    11.0  -5.0  20.0        71.0\n",
              "4    13.0  61.0   3.0         NaN\n",
              "..    ...   ...   ...         ...\n",
              "447   4.0  40.0 -27.0        63.0\n",
              "448  66.0  52.0  79.0        73.0\n",
              "449 -19.0 -61.0 -70.0        84.0\n",
              "450  29.0 -22.0  43.0        80.0\n",
              "451  79.0  52.0  47.0        75.0\n",
              "\n",
              "[452 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-hIzHhNirpc"
      },
      "source": [
        "Son solo 4 columnas, por lo podemos hacer estrategiasd para cada una de ellas. Comencemos por describirlas estadisticamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAI1LFJOi7Le",
        "outputId": "b7eb9d5f-2a9c-4512-fd13-2d6a51d19e37"
      },
      "source": [
        "print(\"Mean: \")\r\n",
        "print(na_data.mean())\r\n",
        "print(\"\")\r\n",
        "print(\"Median: \")\r\n",
        "print(na_data.median())\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean: \n",
            "T             36.150901\n",
            "P             48.913953\n",
            "QRST          36.716186\n",
            "Heart rate    74.463415\n",
            "dtype: float64\n",
            "\n",
            "Median: \n",
            "T             41.0\n",
            "P             56.0\n",
            "QRST          40.0\n",
            "Heart rate    72.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edtq_Ughi5-B"
      },
      "source": [
        "Los datos faltantes no parecen ser afectados por altos outliers. Dado que su media y su mediana son bastante similares. Es por esto que se cambiaran los datos faltantes por el promedio de la columna."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqu21NHO9H5M"
      },
      "source": [
        "Por alguna razon, los commandos fillna(arrhythmia_data_numeric.mean(), inplace=True) no funcionaron. Se utilizo el comando: .replace(np.nan, arrhythmia_data_numeric.mean()) y finalmente si funcionó."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL6gZZUOmxcm",
        "outputId": "00d8068b-a510-41b3-c965-2843dc7184c5"
      },
      "source": [
        "arrhythmia_data_numeric.fillna(arrhythmia_data_numeric.mean(), inplace=True)\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "LNU0ZOSc6DSo",
        "outputId": "cd804674-8acd-49b0-cbc0-c9d330c2b915"
      },
      "source": [
        "arrhythmia_data_numeric"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>...</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_17</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>36</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>80</td>\n",
              "      <td>199</td>\n",
              "      <td>382</td>\n",
              "      <td>154</td>\n",
              "      <td>117</td>\n",
              "      <td>-37</td>\n",
              "      <td>4.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>-27.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>-9.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-22.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-10.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-20.1</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>-8.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>85</td>\n",
              "      <td>100</td>\n",
              "      <td>137</td>\n",
              "      <td>361</td>\n",
              "      <td>201</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>66.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>10.8</td>\n",
              "      <td>27.7</td>\n",
              "      <td>137.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>5.9</td>\n",
              "      <td>69.2</td>\n",
              "      <td>129.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.2</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>50.7</td>\n",
              "      <td>82.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>62.4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>68</td>\n",
              "      <td>108</td>\n",
              "      <td>176</td>\n",
              "      <td>365</td>\n",
              "      <td>194</td>\n",
              "      <td>116</td>\n",
              "      <td>-85</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-61.0</td>\n",
              "      <td>-70.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>16</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.3</td>\n",
              "      <td>-34.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-75.7</td>\n",
              "      <td>-146.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>-36.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-71.2</td>\n",
              "      <td>-161.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>-30.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-39.6</td>\n",
              "      <td>-63.6</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.3</td>\n",
              "      <td>-28.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-44.2</td>\n",
              "      <td>-33.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>93</td>\n",
              "      <td>106</td>\n",
              "      <td>386</td>\n",
              "      <td>218</td>\n",
              "      <td>63</td>\n",
              "      <td>54</td>\n",
              "      <td>29.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>94.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.9</td>\n",
              "      <td>-6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.8</td>\n",
              "      <td>17.5</td>\n",
              "      <td>56.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.7</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>25.0</td>\n",
              "      <td>46.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>79</td>\n",
              "      <td>127</td>\n",
              "      <td>364</td>\n",
              "      <td>138</td>\n",
              "      <td>78</td>\n",
              "      <td>28</td>\n",
              "      <td>79.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>38.3</td>\n",
              "      <td>60.9</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.6</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>44.0</td>\n",
              "      <td>60.8</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.7</td>\n",
              "      <td>26.7</td>\n",
              "      <td>38.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>21.3</td>\n",
              "      <td>32.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 279 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Sex  Height  Weight  QRS duration  ...  V6_18  V6_19  V6_20  V6_21  Class\n",
              "0     75    0     190      80            91  ...    0.9    2.9   23.3   49.4      8\n",
              "1     56    1     165      64            81  ...    0.2    2.1   20.4   38.8      6\n",
              "2     54    0     172      95           138  ...    0.3    3.4   12.3   49.0     10\n",
              "3     55    0     175      94           100  ...    0.4    2.6   34.6   61.6      1\n",
              "4     75    0     190      80            88  ...   -0.1    3.9   25.4   62.8      7\n",
              "..   ...  ...     ...     ...           ...  ...    ...    ...    ...    ...    ...\n",
              "447   53    1     160      70            80  ...    0.7    0.6   -4.4   -0.5      1\n",
              "448   37    0     190      85           100  ...    0.4    2.4   38.0   62.4     10\n",
              "449   36    0     166      68           108  ...    1.5    1.0  -44.2  -33.2      2\n",
              "450   32    1     155      55            93  ...    0.5    2.4   25.0   46.6      1\n",
              "451   78    1     160      70            79  ...    0.5    1.6   21.3   32.8      1\n",
              "\n",
              "[452 rows x 279 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1063Ffdy87r7"
      },
      "source": [
        "arrhythmia_data_numeric = arrhythmia_data_numeric.replace(np.nan, arrhythmia_data_numeric.mean())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUeJzOygBscA"
      },
      "source": [
        "Realicemos una copia de los datos para poder utilizarlos mas adelante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkbRh7hhBr2i"
      },
      "source": [
        "arrhythmia_data_copy = arrhythmia_data_numeric.copy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "BBojKYXk9AyV",
        "outputId": "a0eeabac-3a9a-43c7-cb84-bd1138bd2e3d"
      },
      "source": [
        "arrhythmia_data_numeric"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>...</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_17</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>91</td>\n",
              "      <td>193</td>\n",
              "      <td>371</td>\n",
              "      <td>174</td>\n",
              "      <td>121</td>\n",
              "      <td>-16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>52.7</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>5.1</td>\n",
              "      <td>17.7</td>\n",
              "      <td>70.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>62.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>23.3</td>\n",
              "      <td>49.4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64</td>\n",
              "      <td>81</td>\n",
              "      <td>174</td>\n",
              "      <td>401</td>\n",
              "      <td>149</td>\n",
              "      <td>39</td>\n",
              "      <td>25</td>\n",
              "      <td>37.0</td>\n",
              "      <td>-17.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>27.7</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>11.8</td>\n",
              "      <td>34.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>21.6</td>\n",
              "      <td>43.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>20.4</td>\n",
              "      <td>38.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>95</td>\n",
              "      <td>138</td>\n",
              "      <td>163</td>\n",
              "      <td>386</td>\n",
              "      <td>185</td>\n",
              "      <td>102</td>\n",
              "      <td>96</td>\n",
              "      <td>34.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>20.4</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>49.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>94</td>\n",
              "      <td>100</td>\n",
              "      <td>202</td>\n",
              "      <td>380</td>\n",
              "      <td>179</td>\n",
              "      <td>143</td>\n",
              "      <td>28</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>52</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>28.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.6</td>\n",
              "      <td>34.6</td>\n",
              "      <td>61.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>80</td>\n",
              "      <td>88</td>\n",
              "      <td>181</td>\n",
              "      <td>360</td>\n",
              "      <td>177</td>\n",
              "      <td>103</td>\n",
              "      <td>-16</td>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>74.463415</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>36</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>-7.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>16.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>21.7</td>\n",
              "      <td>48.9</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>25.4</td>\n",
              "      <td>62.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>80</td>\n",
              "      <td>199</td>\n",
              "      <td>382</td>\n",
              "      <td>154</td>\n",
              "      <td>117</td>\n",
              "      <td>-37</td>\n",
              "      <td>4.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>-27.0</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>-9.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>-22.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-10.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-20.1</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>-8.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>85</td>\n",
              "      <td>100</td>\n",
              "      <td>137</td>\n",
              "      <td>361</td>\n",
              "      <td>201</td>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>66.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>10.8</td>\n",
              "      <td>27.7</td>\n",
              "      <td>137.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>5.9</td>\n",
              "      <td>69.2</td>\n",
              "      <td>129.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.2</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>50.7</td>\n",
              "      <td>82.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>62.4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>68</td>\n",
              "      <td>108</td>\n",
              "      <td>176</td>\n",
              "      <td>365</td>\n",
              "      <td>194</td>\n",
              "      <td>116</td>\n",
              "      <td>-85</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-61.0</td>\n",
              "      <td>-70.0</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.3</td>\n",
              "      <td>-34.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-75.7</td>\n",
              "      <td>-146.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>-36.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>-71.2</td>\n",
              "      <td>-161.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>-30.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-39.6</td>\n",
              "      <td>-63.6</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.3</td>\n",
              "      <td>-28.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-44.2</td>\n",
              "      <td>-33.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>155</td>\n",
              "      <td>55</td>\n",
              "      <td>93</td>\n",
              "      <td>106</td>\n",
              "      <td>386</td>\n",
              "      <td>218</td>\n",
              "      <td>63</td>\n",
              "      <td>54</td>\n",
              "      <td>29.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>94.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.9</td>\n",
              "      <td>-6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>3.8</td>\n",
              "      <td>17.5</td>\n",
              "      <td>56.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>29.7</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>25.0</td>\n",
              "      <td>46.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>70</td>\n",
              "      <td>79</td>\n",
              "      <td>127</td>\n",
              "      <td>364</td>\n",
              "      <td>138</td>\n",
              "      <td>78</td>\n",
              "      <td>28</td>\n",
              "      <td>79.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>38.3</td>\n",
              "      <td>60.9</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.6</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>44.0</td>\n",
              "      <td>60.8</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.7</td>\n",
              "      <td>26.7</td>\n",
              "      <td>38.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>21.3</td>\n",
              "      <td>32.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 279 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Sex  Height  Weight  QRS duration  ...  V6_18  V6_19  V6_20  V6_21  Class\n",
              "0     75    0     190      80            91  ...    0.9    2.9   23.3   49.4      8\n",
              "1     56    1     165      64            81  ...    0.2    2.1   20.4   38.8      6\n",
              "2     54    0     172      95           138  ...    0.3    3.4   12.3   49.0     10\n",
              "3     55    0     175      94           100  ...    0.4    2.6   34.6   61.6      1\n",
              "4     75    0     190      80            88  ...   -0.1    3.9   25.4   62.8      7\n",
              "..   ...  ...     ...     ...           ...  ...    ...    ...    ...    ...    ...\n",
              "447   53    1     160      70            80  ...    0.7    0.6   -4.4   -0.5      1\n",
              "448   37    0     190      85           100  ...    0.4    2.4   38.0   62.4     10\n",
              "449   36    0     166      68           108  ...    1.5    1.0  -44.2  -33.2      2\n",
              "450   32    1     155      55            93  ...    0.5    2.4   25.0   46.6      1\n",
              "451   78    1     160      70            79  ...    0.5    1.6   21.3   32.8      1\n",
              "\n",
              "[452 rows x 279 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JUxx5zd-a-y"
      },
      "source": [
        "Estudiemos los valores Outliers\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "LNfBjXNa-eWi",
        "outputId": "b8127038-af2e-4f96-f623-49df20aec83c"
      },
      "source": [
        "arrhythmia_data_numeric.describe()\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>...</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_17</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.00000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>46.471239</td>\n",
              "      <td>0.550885</td>\n",
              "      <td>166.188053</td>\n",
              "      <td>68.170354</td>\n",
              "      <td>88.920354</td>\n",
              "      <td>155.152655</td>\n",
              "      <td>367.207965</td>\n",
              "      <td>169.949115</td>\n",
              "      <td>90.004425</td>\n",
              "      <td>33.676991</td>\n",
              "      <td>36.150901</td>\n",
              "      <td>48.913953</td>\n",
              "      <td>36.716186</td>\n",
              "      <td>74.463415</td>\n",
              "      <td>5.628319</td>\n",
              "      <td>51.628319</td>\n",
              "      <td>20.920354</td>\n",
              "      <td>0.141593</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.035398</td>\n",
              "      <td>0.002212</td>\n",
              "      <td>0.011062</td>\n",
              "      <td>0.011062</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.008850</td>\n",
              "      <td>5.619469</td>\n",
              "      <td>54.336283</td>\n",
              "      <td>20.59292</td>\n",
              "      <td>0.433628</td>\n",
              "      <td>0.150442</td>\n",
              "      <td>31.637168</td>\n",
              "      <td>0.017699</td>\n",
              "      <td>0.028761</td>\n",
              "      <td>0.002212</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.015487</td>\n",
              "      <td>16.026549</td>\n",
              "      <td>41.982301</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.653540</td>\n",
              "      <td>8.039602</td>\n",
              "      <td>-10.150664</td>\n",
              "      <td>0.032965</td>\n",
              "      <td>-0.013496</td>\n",
              "      <td>0.226770</td>\n",
              "      <td>3.894690</td>\n",
              "      <td>-8.269027</td>\n",
              "      <td>32.422788</td>\n",
              "      <td>0.001106</td>\n",
              "      <td>-0.297566</td>\n",
              "      <td>11.839381</td>\n",
              "      <td>-7.034513</td>\n",
              "      <td>0.025664</td>\n",
              "      <td>-0.002876</td>\n",
              "      <td>0.547788</td>\n",
              "      <td>2.535841</td>\n",
              "      <td>10.081195</td>\n",
              "      <td>33.328540</td>\n",
              "      <td>-0.285398</td>\n",
              "      <td>-0.277212</td>\n",
              "      <td>11.369912</td>\n",
              "      <td>-3.607522</td>\n",
              "      <td>0.016814</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.546681</td>\n",
              "      <td>1.722124</td>\n",
              "      <td>17.840044</td>\n",
              "      <td>32.871460</td>\n",
              "      <td>-0.302434</td>\n",
              "      <td>-0.278982</td>\n",
              "      <td>9.048009</td>\n",
              "      <td>-1.457301</td>\n",
              "      <td>0.003982</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.514823</td>\n",
              "      <td>1.222345</td>\n",
              "      <td>19.326106</td>\n",
              "      <td>29.473230</td>\n",
              "      <td>3.880531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.466631</td>\n",
              "      <td>0.497955</td>\n",
              "      <td>37.170340</td>\n",
              "      <td>16.590803</td>\n",
              "      <td>15.364394</td>\n",
              "      <td>44.842283</td>\n",
              "      <td>33.385421</td>\n",
              "      <td>35.633072</td>\n",
              "      <td>25.826643</td>\n",
              "      <td>45.431434</td>\n",
              "      <td>57.342803</td>\n",
              "      <td>28.621694</td>\n",
              "      <td>35.980768</td>\n",
              "      <td>13.855298</td>\n",
              "      <td>10.650001</td>\n",
              "      <td>18.249901</td>\n",
              "      <td>20.541728</td>\n",
              "      <td>1.569483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.046393</td>\n",
              "      <td>0.047036</td>\n",
              "      <td>0.104708</td>\n",
              "      <td>0.104708</td>\n",
              "      <td>0.066445</td>\n",
              "      <td>0.066445</td>\n",
              "      <td>0.093759</td>\n",
              "      <td>11.220680</td>\n",
              "      <td>17.248213</td>\n",
              "      <td>21.06105</td>\n",
              "      <td>3.093161</td>\n",
              "      <td>2.692591</td>\n",
              "      <td>9.624951</td>\n",
              "      <td>0.132002</td>\n",
              "      <td>0.167319</td>\n",
              "      <td>0.047036</td>\n",
              "      <td>0.066445</td>\n",
              "      <td>0.066445</td>\n",
              "      <td>0.123615</td>\n",
              "      <td>21.906457</td>\n",
              "      <td>23.106034</td>\n",
              "      <td>...</td>\n",
              "      <td>3.414085</td>\n",
              "      <td>5.279719</td>\n",
              "      <td>7.066568</td>\n",
              "      <td>0.390403</td>\n",
              "      <td>0.264398</td>\n",
              "      <td>0.548988</td>\n",
              "      <td>2.990809</td>\n",
              "      <td>32.157008</td>\n",
              "      <td>37.362289</td>\n",
              "      <td>1.015566</td>\n",
              "      <td>1.758544</td>\n",
              "      <td>5.917391</td>\n",
              "      <td>5.061472</td>\n",
              "      <td>0.166763</td>\n",
              "      <td>0.046287</td>\n",
              "      <td>0.426941</td>\n",
              "      <td>2.429776</td>\n",
              "      <td>25.074695</td>\n",
              "      <td>34.361665</td>\n",
              "      <td>0.675060</td>\n",
              "      <td>0.992472</td>\n",
              "      <td>4.793656</td>\n",
              "      <td>2.850633</td>\n",
              "      <td>0.275907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.370548</td>\n",
              "      <td>1.708190</td>\n",
              "      <td>16.445472</td>\n",
              "      <td>24.421643</td>\n",
              "      <td>0.603551</td>\n",
              "      <td>0.548876</td>\n",
              "      <td>3.472862</td>\n",
              "      <td>2.002430</td>\n",
              "      <td>0.050118</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.347531</td>\n",
              "      <td>1.426052</td>\n",
              "      <td>13.503922</td>\n",
              "      <td>18.493927</td>\n",
              "      <td>4.407097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>232.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-172.000000</td>\n",
              "      <td>-177.000000</td>\n",
              "      <td>-170.000000</td>\n",
              "      <td>-135.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-32.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-48.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.600000</td>\n",
              "      <td>-3.100000</td>\n",
              "      <td>-11.800000</td>\n",
              "      <td>-242.400000</td>\n",
              "      <td>-146.200000</td>\n",
              "      <td>-3.200000</td>\n",
              "      <td>-20.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-42.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.900000</td>\n",
              "      <td>-2.600000</td>\n",
              "      <td>-8.200000</td>\n",
              "      <td>-124.800000</td>\n",
              "      <td>-161.400000</td>\n",
              "      <td>-4.800000</td>\n",
              "      <td>-14.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-30.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.900000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>-56.800000</td>\n",
              "      <td>-63.600000</td>\n",
              "      <td>-5.600000</td>\n",
              "      <td>-4.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-28.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>-44.200000</td>\n",
              "      <td>-38.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>-13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>-19.525000</td>\n",
              "      <td>9.850000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.875000</td>\n",
              "      <td>-9.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>-0.925000</td>\n",
              "      <td>11.275000</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>-4.725000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>8.675000</td>\n",
              "      <td>15.375000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.425000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>-2.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>11.450000</td>\n",
              "      <td>17.550000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>367.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>54.500000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>20.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.050000</td>\n",
              "      <td>-8.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>-4.700000</td>\n",
              "      <td>32.550000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>11.400000</td>\n",
              "      <td>32.750000</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>18.350000</td>\n",
              "      <td>30.350000</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>-1.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.350000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>27.900000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>384.000000</td>\n",
              "      <td>179.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>36.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>-5.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>5.525000</td>\n",
              "      <td>7.625000</td>\n",
              "      <td>56.025000</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.100000</td>\n",
              "      <td>-3.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>25.050000</td>\n",
              "      <td>52.325000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.125000</td>\n",
              "      <td>-1.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>27.900000</td>\n",
              "      <td>48.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>25.825000</td>\n",
              "      <td>41.125000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>83.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>780.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>188.000000</td>\n",
              "      <td>524.000000</td>\n",
              "      <td>509.000000</td>\n",
              "      <td>381.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>179.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>92.00000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>18.800000</td>\n",
              "      <td>165.400000</td>\n",
              "      <td>137.800000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>15.600000</td>\n",
              "      <td>103.400000</td>\n",
              "      <td>182.300000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>8.300000</td>\n",
              "      <td>82.100000</td>\n",
              "      <td>127.900000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>88.800000</td>\n",
              "      <td>115.900000</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 279 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age         Sex      Height  ...       V6_20       V6_21       Class\n",
              "count  452.000000  452.000000  452.000000  ...  452.000000  452.000000  452.000000\n",
              "mean    46.471239    0.550885  166.188053  ...   19.326106   29.473230    3.880531\n",
              "std     16.466631    0.497955   37.170340  ...   13.503922   18.493927    4.407097\n",
              "min      0.000000    0.000000  105.000000  ...  -44.200000  -38.600000    1.000000\n",
              "25%     36.000000    0.000000  160.000000  ...   11.450000   17.550000    1.000000\n",
              "50%     47.000000    1.000000  164.000000  ...   18.100000   27.900000    1.000000\n",
              "75%     58.000000    1.000000  170.000000  ...   25.825000   41.125000    6.000000\n",
              "max     83.000000    1.000000  780.000000  ...   88.800000  115.900000   16.000000\n",
              "\n",
              "[8 rows x 279 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p5JOd-rAtuN"
      },
      "source": [
        "Dado que se tienen 279 columnas será imposible identificar como se relacionan unas variables con otras a nivel visual. Sin embargo, con una simple inspeccion a los valores podemos notar que hay algunos que estan erroneos. Por ejemplo, El valor de Height (Altura) tiene un valor maximo de 780 cm, lo cual sabemos que es imposible para un humano. \r\n",
        "\r\n",
        "Filtraremos los datos por medio de una aproximación de media mas dos desviaciones estandar. Escribiendo la media como parámetro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "c-lT0oJnmMKf",
        "outputId": "de041029-a06f-4fa9-c58c-7c1844db4d48"
      },
      "source": [
        "mask = (arrhythmia_data_numeric > arrhythmia_data_numeric.mean() + 2*arrhythmia_data_numeric.std()) | (arrhythmia_data_numeric < arrhythmia_data_numeric.mean() - 2*arrhythmia_data_numeric.std())\r\n",
        "arrhythmia_data_numeric.mask(mask, arrhythmia_data_numeric.mean(), axis =1).describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>...</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_17</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>452.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>47.623664</td>\n",
              "      <td>0.550885</td>\n",
              "      <td>163.852602</td>\n",
              "      <td>68.858226</td>\n",
              "      <td>86.861873</td>\n",
              "      <td>158.791629</td>\n",
              "      <td>367.800033</td>\n",
              "      <td>163.793195</td>\n",
              "      <td>90.175043</td>\n",
              "      <td>35.747416</td>\n",
              "      <td>41.644553</td>\n",
              "      <td>51.624558</td>\n",
              "      <td>38.221955</td>\n",
              "      <td>73.112562</td>\n",
              "      <td>4.630903</td>\n",
              "      <td>49.853277</td>\n",
              "      <td>19.781424</td>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.390634</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>4.416575</td>\n",
              "      <td>52.988331</td>\n",
              "      <td>19.192732</td>\n",
              "      <td>0.009594</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>31.094976</td>\n",
              "      <td>0.000313</td>\n",
              "      <td>0.000827</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>12.435273</td>\n",
              "      <td>40.658861</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.093591</td>\n",
              "      <td>7.347503</td>\n",
              "      <td>-9.354224</td>\n",
              "      <td>0.001471</td>\n",
              "      <td>-0.001136</td>\n",
              "      <td>0.252188</td>\n",
              "      <td>3.838470</td>\n",
              "      <td>-4.748118</td>\n",
              "      <td>32.706842</td>\n",
              "      <td>-0.072090</td>\n",
              "      <td>-0.098414</td>\n",
              "      <td>11.429303</td>\n",
              "      <td>-6.392227</td>\n",
              "      <td>0.000852</td>\n",
              "      <td>-0.000013</td>\n",
              "      <td>0.583973</td>\n",
              "      <td>2.531532</td>\n",
              "      <td>11.839350</td>\n",
              "      <td>32.515043</td>\n",
              "      <td>-0.283457</td>\n",
              "      <td>-0.183718</td>\n",
              "      <td>10.953115</td>\n",
              "      <td>-3.300488</td>\n",
              "      <td>0.004020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.569352</td>\n",
              "      <td>1.762432</td>\n",
              "      <td>18.166374</td>\n",
              "      <td>32.139698</td>\n",
              "      <td>-0.284821</td>\n",
              "      <td>-0.197568</td>\n",
              "      <td>8.812744</td>\n",
              "      <td>-1.294946</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.541380</td>\n",
              "      <td>1.319869</td>\n",
              "      <td>18.920682</td>\n",
              "      <td>29.152975</td>\n",
              "      <td>3.078090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.211193</td>\n",
              "      <td>0.497955</td>\n",
              "      <td>10.390252</td>\n",
              "      <td>12.195902</td>\n",
              "      <td>9.655112</td>\n",
              "      <td>22.440778</td>\n",
              "      <td>24.491994</td>\n",
              "      <td>24.154760</td>\n",
              "      <td>15.928273</td>\n",
              "      <td>37.981980</td>\n",
              "      <td>36.079697</td>\n",
              "      <td>18.588722</td>\n",
              "      <td>29.351932</td>\n",
              "      <td>10.911728</td>\n",
              "      <td>8.268037</td>\n",
              "      <td>12.483900</td>\n",
              "      <td>18.987385</td>\n",
              "      <td>0.013276</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.619583</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>8.628435</td>\n",
              "      <td>13.568227</td>\n",
              "      <td>19.118353</td>\n",
              "      <td>0.063852</td>\n",
              "      <td>0.009996</td>\n",
              "      <td>7.479917</td>\n",
              "      <td>0.002336</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>15.902163</td>\n",
              "      <td>21.418800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.576782</td>\n",
              "      <td>4.136269</td>\n",
              "      <td>5.186761</td>\n",
              "      <td>0.023753</td>\n",
              "      <td>0.023525</td>\n",
              "      <td>0.432096</td>\n",
              "      <td>2.266041</td>\n",
              "      <td>19.849587</td>\n",
              "      <td>29.128155</td>\n",
              "      <td>0.650415</td>\n",
              "      <td>0.349539</td>\n",
              "      <td>4.786010</td>\n",
              "      <td>3.513896</td>\n",
              "      <td>0.004602</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.293758</td>\n",
              "      <td>1.929321</td>\n",
              "      <td>17.529215</td>\n",
              "      <td>27.867994</td>\n",
              "      <td>0.446371</td>\n",
              "      <td>0.396805</td>\n",
              "      <td>3.894200</td>\n",
              "      <td>2.117231</td>\n",
              "      <td>0.042457</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.246499</td>\n",
              "      <td>1.289934</td>\n",
              "      <td>12.981353</td>\n",
              "      <td>19.859730</td>\n",
              "      <td>0.397570</td>\n",
              "      <td>0.333748</td>\n",
              "      <td>2.922850</td>\n",
              "      <td>1.264859</td>\n",
              "      <td>0.000324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232567</td>\n",
              "      <td>1.084049</td>\n",
              "      <td>10.321392</td>\n",
              "      <td>15.404558</td>\n",
              "      <td>3.055031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>301.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>-57.000000</td>\n",
              "      <td>-76.000000</td>\n",
              "      <td>-8.000000</td>\n",
              "      <td>-32.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-23.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.800000</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>-66.900000</td>\n",
              "      <td>-36.900000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-3.100000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-16.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.002876</td>\n",
              "      <td>-0.300000</td>\n",
              "      <td>-2.300000</td>\n",
              "      <td>-39.100000</td>\n",
              "      <td>-33.000000</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>-9.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>-14.100000</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>-1.300000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>-5.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>-1.600000</td>\n",
              "      <td>-7.200000</td>\n",
              "      <td>-6.300000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>353.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.750000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>16.750000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>-12.025000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>-16.125000</td>\n",
              "      <td>12.875000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.200000</td>\n",
              "      <td>-8.625000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>1.650000</td>\n",
              "      <td>13.175000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.200000</td>\n",
              "      <td>-4.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>10.050000</td>\n",
              "      <td>17.700000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>6.675000</td>\n",
              "      <td>-2.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>46.471239</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>68.170354</td>\n",
              "      <td>86.500000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>367.207965</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>90.004425</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>39.500000</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.637168</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.050000</td>\n",
              "      <td>-8.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>3.894690</td>\n",
              "      <td>-5.050000</td>\n",
              "      <td>32.422788</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>10.350000</td>\n",
              "      <td>33.328540</td>\n",
              "      <td>-0.285398</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>-3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.546681</td>\n",
              "      <td>1.722124</td>\n",
              "      <td>17.840044</td>\n",
              "      <td>32.400000</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>-1.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.507412</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>18.900000</td>\n",
              "      <td>28.850000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>173.000000</td>\n",
              "      <td>382.250000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>65.250000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>5.628319</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>-5.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>7.225000</td>\n",
              "      <td>52.625000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>-3.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>3.625000</td>\n",
              "      <td>23.925000</td>\n",
              "      <td>49.950000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.400000</td>\n",
              "      <td>-1.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>45.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>25.025000</td>\n",
              "      <td>39.525000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>79.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>431.000000</td>\n",
              "      <td>241.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.141593</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.002212</td>\n",
              "      <td>0.011062</td>\n",
              "      <td>0.011062</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.008850</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.433628</td>\n",
              "      <td>0.150442</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.017699</td>\n",
              "      <td>0.028761</td>\n",
              "      <td>0.002212</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.004425</td>\n",
              "      <td>0.015487</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>54.900000</td>\n",
              "      <td>103.400000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>7.300000</td>\n",
              "      <td>59.600000</td>\n",
              "      <td>99.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>50.700000</td>\n",
              "      <td>80.800000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003982</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>45.100000</td>\n",
              "      <td>64.200000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 279 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age         Sex      Height  ...       V6_20       V6_21       Class\n",
              "count  452.000000  452.000000  452.000000  ...  452.000000  452.000000  452.000000\n",
              "mean    47.623664    0.550885  163.852602  ...   18.920682   29.152975    3.078090\n",
              "std     14.211193    0.497955   10.390252  ...   10.321392   15.404558    3.055031\n",
              "min     14.000000    0.000000  105.000000  ...   -7.200000   -6.300000    1.000000\n",
              "25%     37.000000    0.000000  160.000000  ...   11.800000   18.000000    1.000000\n",
              "50%     46.471239    1.000000  164.000000  ...   18.900000   28.850000    1.000000\n",
              "75%     58.000000    1.000000  170.000000  ...   25.025000   39.525000    4.000000\n",
              "max     79.000000    1.000000  190.000000  ...   45.100000   64.200000   10.000000\n",
              "\n",
              "[8 rows x 279 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s4jwuyGXuxM"
      },
      "source": [
        "Normalizemos ahora los datos para ser utilizados por los *algoritmos*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "6lRfpVyPX3GI",
        "outputId": "fcd0f4cd-3d7d-48f4-a720-ea16f358e8ad"
      },
      "source": [
        "arrhythmia_data_norm = (arrhythmia_data_numeric - arrhythmia_data_numeric.min()) / (arrhythmia_data_numeric.max() - arrhythmia_data_numeric.min())\r\n",
        "arrhythmia_data_norm"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>...</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_17</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.903614</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.270677</td>\n",
              "      <td>0.368321</td>\n",
              "      <td>0.501805</td>\n",
              "      <td>0.241758</td>\n",
              "      <td>0.590244</td>\n",
              "      <td>0.457478</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.676301</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.159664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.295775</td>\n",
              "      <td>0.793388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.660714</td>\n",
              "      <td>0.578431</td>\n",
              "      <td>0.584846</td>\n",
              "      <td>0.700352</td>\n",
              "      <td>0.224806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.804196</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648148</td>\n",
              "      <td>0.558824</td>\n",
              "      <td>0.624452</td>\n",
              "      <td>0.675298</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.457627</td>\n",
              "      <td>0.870130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.669173</td>\n",
              "      <td>0.592513</td>\n",
              "      <td>0.660574</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.381356</td>\n",
              "      <td>0.968531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.53125</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.507519</td>\n",
              "      <td>0.569579</td>\n",
              "      <td>0.466667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.674699</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.195489</td>\n",
              "      <td>0.332061</td>\n",
              "      <td>0.610108</td>\n",
              "      <td>0.150183</td>\n",
              "      <td>0.190244</td>\n",
              "      <td>0.577713</td>\n",
              "      <td>0.601124</td>\n",
              "      <td>0.442197</td>\n",
              "      <td>0.551495</td>\n",
              "      <td>0.075630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.580432</td>\n",
              "      <td>0.612324</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.260989</td>\n",
              "      <td>0.883450</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.453782</td>\n",
              "      <td>0.598598</td>\n",
              "      <td>0.570265</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.372881</td>\n",
              "      <td>0.922078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.564435</td>\n",
              "      <td>0.558747</td>\n",
              "      <td>0.614458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.360169</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.31250</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.500971</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.650602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.099259</td>\n",
              "      <td>0.523529</td>\n",
              "      <td>0.624060</td>\n",
              "      <td>0.311069</td>\n",
              "      <td>0.555957</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.497561</td>\n",
              "      <td>0.785924</td>\n",
              "      <td>0.592697</td>\n",
              "      <td>0.693642</td>\n",
              "      <td>0.667774</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.915289</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.395425</td>\n",
              "      <td>0.644434</td>\n",
              "      <td>0.596831</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.274725</td>\n",
              "      <td>0.867133</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.436975</td>\n",
              "      <td>0.533742</td>\n",
              "      <td>0.529823</td>\n",
              "      <td>0.743902</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.376271</td>\n",
              "      <td>0.889610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.491721</td>\n",
              "      <td>0.583812</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.402542</td>\n",
              "      <td>0.916084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.34375</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.424812</td>\n",
              "      <td>0.566990</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.662651</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103704</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.338346</td>\n",
              "      <td>0.385496</td>\n",
              "      <td>0.534296</td>\n",
              "      <td>0.260073</td>\n",
              "      <td>0.697561</td>\n",
              "      <td>0.586510</td>\n",
              "      <td>0.528090</td>\n",
              "      <td>0.476879</td>\n",
              "      <td>0.514950</td>\n",
              "      <td>0.226891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.316901</td>\n",
              "      <td>0.836777</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.519608</td>\n",
              "      <td>0.613046</td>\n",
              "      <td>0.694366</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.412088</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.483193</td>\n",
              "      <td>0.673094</td>\n",
              "      <td>0.653186</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.515254</td>\n",
              "      <td>0.879870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.601504</td>\n",
              "      <td>0.673866</td>\n",
              "      <td>0.687206</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.516949</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.592481</td>\n",
              "      <td>0.648544</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.903614</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.248120</td>\n",
              "      <td>0.345420</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>0.252747</td>\n",
              "      <td>0.502439</td>\n",
              "      <td>0.457478</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.667630</td>\n",
              "      <td>0.458472</td>\n",
              "      <td>0.255995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.299296</td>\n",
              "      <td>0.789256</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.539216</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>0.666197</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.462963</td>\n",
              "      <td>0.550420</td>\n",
              "      <td>0.617879</td>\n",
              "      <td>0.653477</td>\n",
              "      <td>0.560976</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.308475</td>\n",
              "      <td>0.970779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.593985</td>\n",
              "      <td>0.565155</td>\n",
              "      <td>0.587467</td>\n",
              "      <td>0.626506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.555085</td>\n",
              "      <td>0.874126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.21875</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.523308</td>\n",
              "      <td>0.656311</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.081481</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.187970</td>\n",
              "      <td>0.379771</td>\n",
              "      <td>0.541516</td>\n",
              "      <td>0.168498</td>\n",
              "      <td>0.570732</td>\n",
              "      <td>0.395894</td>\n",
              "      <td>0.508427</td>\n",
              "      <td>0.606936</td>\n",
              "      <td>0.358804</td>\n",
              "      <td>0.159664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.045775</td>\n",
              "      <td>0.809917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.457516</td>\n",
              "      <td>0.540216</td>\n",
              "      <td>0.528169</td>\n",
              "      <td>0.263566</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.079670</td>\n",
              "      <td>0.759907</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.403361</td>\n",
              "      <td>0.458808</td>\n",
              "      <td>0.441955</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.138983</td>\n",
              "      <td>0.730519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.451128</td>\n",
              "      <td>0.348452</td>\n",
              "      <td>0.328982</td>\n",
              "      <td>0.674699</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.182203</td>\n",
              "      <td>0.825175</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.46875</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.299248</td>\n",
              "      <td>0.246602</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.445783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.464706</td>\n",
              "      <td>0.338346</td>\n",
              "      <td>0.261450</td>\n",
              "      <td>0.465704</td>\n",
              "      <td>0.340659</td>\n",
              "      <td>0.356098</td>\n",
              "      <td>0.756598</td>\n",
              "      <td>0.682584</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.710963</td>\n",
              "      <td>0.243697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.429577</td>\n",
              "      <td>0.888430</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.738562</td>\n",
              "      <td>0.662334</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.618132</td>\n",
              "      <td>0.918415</td>\n",
              "      <td>0.375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.592437</td>\n",
              "      <td>0.850131</td>\n",
              "      <td>0.845796</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.718644</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.654135</td>\n",
              "      <td>0.773938</td>\n",
              "      <td>0.762924</td>\n",
              "      <td>0.614458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.944056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.618045</td>\n",
              "      <td>0.653722</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>0.433735</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090370</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.398496</td>\n",
              "      <td>0.335878</td>\n",
              "      <td>0.480144</td>\n",
              "      <td>0.315018</td>\n",
              "      <td>0.565854</td>\n",
              "      <td>0.255132</td>\n",
              "      <td>0.443820</td>\n",
              "      <td>0.315029</td>\n",
              "      <td>0.215947</td>\n",
              "      <td>0.336134</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.644366</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.803571</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.408779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.217054</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.565934</td>\n",
              "      <td>0.144522</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.609756</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.745763</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.187970</td>\n",
              "      <td>0.123830</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.690678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.71875</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034951</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>0.385542</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.288235</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.202290</td>\n",
              "      <td>0.555957</td>\n",
              "      <td>0.402930</td>\n",
              "      <td>0.307317</td>\n",
              "      <td>0.662757</td>\n",
              "      <td>0.578652</td>\n",
              "      <td>0.427746</td>\n",
              "      <td>0.591362</td>\n",
              "      <td>0.302521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.517241</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.309859</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.624183</td>\n",
              "      <td>0.603973</td>\n",
              "      <td>0.847183</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.326923</td>\n",
              "      <td>0.843823</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.504202</td>\n",
              "      <td>0.623576</td>\n",
              "      <td>0.633110</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.518644</td>\n",
              "      <td>0.886364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.616541</td>\n",
              "      <td>0.622750</td>\n",
              "      <td>0.650653</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.975524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.520301</td>\n",
              "      <td>0.551456</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>0.939759</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.081481</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.180451</td>\n",
              "      <td>0.242366</td>\n",
              "      <td>0.476534</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>0.380488</td>\n",
              "      <td>0.586510</td>\n",
              "      <td>0.719101</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.604651</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728873</td>\n",
              "      <td>0.869835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.480392</td>\n",
              "      <td>0.688328</td>\n",
              "      <td>0.729225</td>\n",
              "      <td>0.162791</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648352</td>\n",
              "      <td>0.853147</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.445378</td>\n",
              "      <td>0.739702</td>\n",
              "      <td>0.646494</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.423729</td>\n",
              "      <td>0.905844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.503759</td>\n",
              "      <td>0.601152</td>\n",
              "      <td>0.535248</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.440678</td>\n",
              "      <td>0.937063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.492481</td>\n",
              "      <td>0.462136</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 279 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Age  Sex    Height    Weight  ...     V6_19     V6_20     V6_21     Class\n",
              "0    0.903614  0.0  0.125926  0.435294  ...  0.741667  0.507519  0.569579  0.466667\n",
              "1    0.674699  1.0  0.088889  0.341176  ...  0.675000  0.485714  0.500971  0.333333\n",
              "2    0.650602  0.0  0.099259  0.523529  ...  0.783333  0.424812  0.566990  0.600000\n",
              "3    0.662651  0.0  0.103704  0.517647  ...  0.716667  0.592481  0.648544  0.000000\n",
              "4    0.903614  0.0  0.125926  0.435294  ...  0.825000  0.523308  0.656311  0.400000\n",
              "..        ...  ...       ...       ...  ...       ...       ...       ...       ...\n",
              "447  0.638554  1.0  0.081481  0.376471  ...  0.550000  0.299248  0.246602  0.000000\n",
              "448  0.445783  0.0  0.125926  0.464706  ...  0.700000  0.618045  0.653722  0.600000\n",
              "449  0.433735  0.0  0.090370  0.364706  ...  0.583333  0.000000  0.034951  0.066667\n",
              "450  0.385542  1.0  0.074074  0.288235  ...  0.700000  0.520301  0.551456  0.000000\n",
              "451  0.939759  1.0  0.081481  0.376471  ...  0.633333  0.492481  0.462136  0.000000\n",
              "\n",
              "[452 rows x 279 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZVM8XbnBTgc"
      },
      "source": [
        "Podemos notar que algunos de los datos promediados eran nominales (0 o 1). Devolvamos estos valores a sus originales. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZJtRqnUf0qR",
        "outputId": "26f8dc2d-0f9f-4fee-e2a3-d2b69ffaa6f3"
      },
      "source": [
        "arrhythmia_data_norm['Sex'] = arrhythmia_data['Sex']\r\n",
        "arrhythmia_data_norm.iloc[:,20:26] = arrhythmia_data_copy.iloc[:,20:26]\r\n",
        "arrhythmia_data_norm.iloc[:,32:38] = arrhythmia_data_copy.iloc[:,32:38]\r\n",
        "arrhythmia_data_norm.iloc[:,64:50] = arrhythmia_data_copy.iloc[:,64:50] \r\n",
        "arrhythmia_data_norm.iloc[:,56:62] = arrhythmia_data_copy.iloc[:,56:62]\r\n",
        "arrhythmia_data_norm.iloc[:,68:74] = arrhythmia_data_copy.iloc[:,68:74]\r\n",
        "arrhythmia_data_norm.iloc[:,80:86] = arrhythmia_data_copy.iloc[:,80:86]\r\n",
        "arrhythmia_data_norm.iloc[:,92:98] = arrhythmia_data_copy.iloc[:,92:98]\r\n",
        "arrhythmia_data_norm.iloc[:,104:110] = arrhythmia_data_copy.iloc[:,104:110] \r\n",
        "arrhythmia_data_norm.iloc[:,116:122] = arrhythmia_data_copy.iloc[:,116:122]\r\n",
        "arrhythmia_data_norm.iloc[:,128:134] = arrhythmia_data_copy.iloc[:,128:134]\r\n",
        "arrhythmia_data_norm.iloc[:,140:146] = arrhythmia_data_copy.iloc[:,140:146]\r\n",
        "arrhythmia_data_norm.iloc[:,152:158] = arrhythmia_data_copy.iloc[:,152:158]\r\n",
        "arrhythmia_data_norm['Class'] = arrhythmia_data['Class']\r\n",
        "arrhythmia_data_norm['Class']"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       8\n",
              "1       6\n",
              "2      10\n",
              "3       1\n",
              "4       7\n",
              "       ..\n",
              "447     1\n",
              "448    10\n",
              "449     2\n",
              "450     1\n",
              "451     1\n",
              "Name: Class, Length: 452, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0mHUhY3oY4W"
      },
      "source": [
        "Las columnas NaN que aparecen son debido a que toda la columna poseia unicamente valores 0. Veamos cuales son:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "XMD-tHdBpEo5",
        "outputId": "dfa9640f-aba8-4445-9a88-e29c2f674310"
      },
      "source": [
        "arrhythmia_data_norm.loc[:, arrhythmia_data_norm.isna().any()]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S' wave</th>\n",
              "      <th>AVL_4</th>\n",
              "      <th>V5_4</th>\n",
              "      <th>V6_4</th>\n",
              "      <th>S' wave</th>\n",
              "      <th>AVL_17</th>\n",
              "      <th>V5_17</th>\n",
              "      <th>V6_17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     S' wave  AVL_4  V5_4  V6_4  S' wave  AVL_17  V5_17  V6_17\n",
              "0        NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "1        NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "2        NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "3        NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "4        NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "..       ...    ...   ...   ...      ...     ...    ...    ...\n",
              "447      NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "448      NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "449      NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "450      NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "451      NaN    NaN   NaN   NaN      NaN     NaN    NaN    NaN\n",
              "\n",
              "[452 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4bwSRc9qOGZ"
      },
      "source": [
        "Guardemos las columnas en un vector de columnas para eliminarlas del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "NnpJHhZCqSVw",
        "outputId": "14ed275d-8e84-4a42-b1a2-3f83f2c3eec6"
      },
      "source": [
        "empty_columns = arrhythmia_data_norm.loc[:, arrhythmia_data_norm.isna().any()].columns\r\n",
        "arrhythmia_data_norm.drop(columns=empty_columns, inplace=True)\r\n",
        "arrhythmia_data_norm"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>DIII_2</th>\n",
              "      <th>...</th>\n",
              "      <th>V2_21</th>\n",
              "      <th>V3_12</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.903614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.270677</td>\n",
              "      <td>0.368321</td>\n",
              "      <td>0.501805</td>\n",
              "      <td>0.241758</td>\n",
              "      <td>0.590244</td>\n",
              "      <td>0.457478</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.676301</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.159664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.504344</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.295775</td>\n",
              "      <td>0.793388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.660714</td>\n",
              "      <td>0.578431</td>\n",
              "      <td>0.584846</td>\n",
              "      <td>0.700352</td>\n",
              "      <td>0.224806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.804196</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648148</td>\n",
              "      <td>0.558824</td>\n",
              "      <td>0.624452</td>\n",
              "      <td>0.675298</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.457627</td>\n",
              "      <td>0.870130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.669173</td>\n",
              "      <td>0.592513</td>\n",
              "      <td>0.660574</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.381356</td>\n",
              "      <td>0.968531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.53125</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.507519</td>\n",
              "      <td>0.569579</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.674699</td>\n",
              "      <td>1</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.195489</td>\n",
              "      <td>0.332061</td>\n",
              "      <td>0.610108</td>\n",
              "      <td>0.150183</td>\n",
              "      <td>0.190244</td>\n",
              "      <td>0.577713</td>\n",
              "      <td>0.601124</td>\n",
              "      <td>0.442197</td>\n",
              "      <td>0.551495</td>\n",
              "      <td>0.075630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.440329</td>\n",
              "      <td>0.179348</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.580432</td>\n",
              "      <td>0.612324</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.260989</td>\n",
              "      <td>0.883450</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.453782</td>\n",
              "      <td>0.598598</td>\n",
              "      <td>0.570265</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.372881</td>\n",
              "      <td>0.922078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.564435</td>\n",
              "      <td>0.558747</td>\n",
              "      <td>0.614458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.360169</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31250</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.500971</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.650602</td>\n",
              "      <td>0</td>\n",
              "      <td>0.099259</td>\n",
              "      <td>0.523529</td>\n",
              "      <td>0.624060</td>\n",
              "      <td>0.311069</td>\n",
              "      <td>0.555957</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.497561</td>\n",
              "      <td>0.785924</td>\n",
              "      <td>0.592697</td>\n",
              "      <td>0.693642</td>\n",
              "      <td>0.667774</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.422954</td>\n",
              "      <td>0.179348</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.915289</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.395425</td>\n",
              "      <td>0.644434</td>\n",
              "      <td>0.596831</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.274725</td>\n",
              "      <td>0.867133</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.436975</td>\n",
              "      <td>0.533742</td>\n",
              "      <td>0.529823</td>\n",
              "      <td>0.743902</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.376271</td>\n",
              "      <td>0.889610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.491721</td>\n",
              "      <td>0.583812</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.402542</td>\n",
              "      <td>0.916084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.34375</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.424812</td>\n",
              "      <td>0.566990</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.662651</td>\n",
              "      <td>0</td>\n",
              "      <td>0.103704</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.338346</td>\n",
              "      <td>0.385496</td>\n",
              "      <td>0.534296</td>\n",
              "      <td>0.260073</td>\n",
              "      <td>0.697561</td>\n",
              "      <td>0.586510</td>\n",
              "      <td>0.528090</td>\n",
              "      <td>0.476879</td>\n",
              "      <td>0.514950</td>\n",
              "      <td>0.226891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.517147</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.316901</td>\n",
              "      <td>0.836777</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.519608</td>\n",
              "      <td>0.613046</td>\n",
              "      <td>0.694366</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.412088</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.483193</td>\n",
              "      <td>0.673094</td>\n",
              "      <td>0.653186</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.515254</td>\n",
              "      <td>0.879870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.601504</td>\n",
              "      <td>0.673866</td>\n",
              "      <td>0.687206</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.516949</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.592481</td>\n",
              "      <td>0.648544</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.903614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.248120</td>\n",
              "      <td>0.345420</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>0.252747</td>\n",
              "      <td>0.502439</td>\n",
              "      <td>0.457478</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.667630</td>\n",
              "      <td>0.458472</td>\n",
              "      <td>0.255995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.474166</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.299296</td>\n",
              "      <td>0.789256</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.539216</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>0.666197</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.462963</td>\n",
              "      <td>0.550420</td>\n",
              "      <td>0.617879</td>\n",
              "      <td>0.653477</td>\n",
              "      <td>0.560976</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.308475</td>\n",
              "      <td>0.970779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.593985</td>\n",
              "      <td>0.565155</td>\n",
              "      <td>0.587467</td>\n",
              "      <td>0.626506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.555085</td>\n",
              "      <td>0.874126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.21875</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.523308</td>\n",
              "      <td>0.656311</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>0.638554</td>\n",
              "      <td>1</td>\n",
              "      <td>0.081481</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.187970</td>\n",
              "      <td>0.379771</td>\n",
              "      <td>0.541516</td>\n",
              "      <td>0.168498</td>\n",
              "      <td>0.570732</td>\n",
              "      <td>0.395894</td>\n",
              "      <td>0.508427</td>\n",
              "      <td>0.606936</td>\n",
              "      <td>0.358804</td>\n",
              "      <td>0.159664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.412894</td>\n",
              "      <td>0.233696</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.045775</td>\n",
              "      <td>0.809917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.457516</td>\n",
              "      <td>0.540216</td>\n",
              "      <td>0.528169</td>\n",
              "      <td>0.263566</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.079670</td>\n",
              "      <td>0.759907</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.403361</td>\n",
              "      <td>0.458808</td>\n",
              "      <td>0.441955</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.138983</td>\n",
              "      <td>0.730519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.451128</td>\n",
              "      <td>0.348452</td>\n",
              "      <td>0.328982</td>\n",
              "      <td>0.674699</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.182203</td>\n",
              "      <td>0.825175</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.46875</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.299248</td>\n",
              "      <td>0.246602</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.445783</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.464706</td>\n",
              "      <td>0.338346</td>\n",
              "      <td>0.261450</td>\n",
              "      <td>0.465704</td>\n",
              "      <td>0.340659</td>\n",
              "      <td>0.356098</td>\n",
              "      <td>0.756598</td>\n",
              "      <td>0.682584</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.710963</td>\n",
              "      <td>0.243697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.779607</td>\n",
              "      <td>0.233696</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.429577</td>\n",
              "      <td>0.888430</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.738562</td>\n",
              "      <td>0.662334</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.618132</td>\n",
              "      <td>0.918415</td>\n",
              "      <td>0.375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.592437</td>\n",
              "      <td>0.850131</td>\n",
              "      <td>0.845796</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.718644</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.654135</td>\n",
              "      <td>0.773938</td>\n",
              "      <td>0.762924</td>\n",
              "      <td>0.614458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.944056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.618045</td>\n",
              "      <td>0.653722</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>0.433735</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090370</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.398496</td>\n",
              "      <td>0.335878</td>\n",
              "      <td>0.480144</td>\n",
              "      <td>0.315018</td>\n",
              "      <td>0.565854</td>\n",
              "      <td>0.255132</td>\n",
              "      <td>0.443820</td>\n",
              "      <td>0.315029</td>\n",
              "      <td>0.215947</td>\n",
              "      <td>0.336134</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.492913</td>\n",
              "      <td>0.141304</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.644366</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.803571</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.408779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.217054</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.565934</td>\n",
              "      <td>0.144522</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.609756</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.745763</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.187970</td>\n",
              "      <td>0.123830</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.690678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.71875</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034951</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>0.385542</td>\n",
              "      <td>1</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.288235</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.202290</td>\n",
              "      <td>0.555957</td>\n",
              "      <td>0.402930</td>\n",
              "      <td>0.307317</td>\n",
              "      <td>0.662757</td>\n",
              "      <td>0.578652</td>\n",
              "      <td>0.427746</td>\n",
              "      <td>0.591362</td>\n",
              "      <td>0.302521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.517241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.726566</td>\n",
              "      <td>0.298913</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.309859</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.624183</td>\n",
              "      <td>0.603973</td>\n",
              "      <td>0.847183</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.326923</td>\n",
              "      <td>0.843823</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.504202</td>\n",
              "      <td>0.623576</td>\n",
              "      <td>0.633110</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.518644</td>\n",
              "      <td>0.886364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.616541</td>\n",
              "      <td>0.622750</td>\n",
              "      <td>0.650653</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.975524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.520301</td>\n",
              "      <td>0.551456</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>0.939759</td>\n",
              "      <td>1</td>\n",
              "      <td>0.081481</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.180451</td>\n",
              "      <td>0.242366</td>\n",
              "      <td>0.476534</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>0.380488</td>\n",
              "      <td>0.586510</td>\n",
              "      <td>0.719101</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.604651</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>...</td>\n",
              "      <td>0.588935</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728873</td>\n",
              "      <td>0.869835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.480392</td>\n",
              "      <td>0.688328</td>\n",
              "      <td>0.729225</td>\n",
              "      <td>0.162791</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648352</td>\n",
              "      <td>0.853147</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.445378</td>\n",
              "      <td>0.739702</td>\n",
              "      <td>0.646494</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.423729</td>\n",
              "      <td>0.905844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.503759</td>\n",
              "      <td>0.601152</td>\n",
              "      <td>0.535248</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.440678</td>\n",
              "      <td>0.937063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.492481</td>\n",
              "      <td>0.462136</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 271 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Age  Sex    Height    Weight  ...     V6_19     V6_20     V6_21  Class\n",
              "0    0.903614    0  0.125926  0.435294  ...  0.741667  0.507519  0.569579      8\n",
              "1    0.674699    1  0.088889  0.341176  ...  0.675000  0.485714  0.500971      6\n",
              "2    0.650602    0  0.099259  0.523529  ...  0.783333  0.424812  0.566990     10\n",
              "3    0.662651    0  0.103704  0.517647  ...  0.716667  0.592481  0.648544      1\n",
              "4    0.903614    0  0.125926  0.435294  ...  0.825000  0.523308  0.656311      7\n",
              "..        ...  ...       ...       ...  ...       ...       ...       ...    ...\n",
              "447  0.638554    1  0.081481  0.376471  ...  0.550000  0.299248  0.246602      1\n",
              "448  0.445783    0  0.125926  0.464706  ...  0.700000  0.618045  0.653722     10\n",
              "449  0.433735    0  0.090370  0.364706  ...  0.583333  0.000000  0.034951      2\n",
              "450  0.385542    1  0.074074  0.288235  ...  0.700000  0.520301  0.551456      1\n",
              "451  0.939759    1  0.081481  0.376471  ...  0.633333  0.492481  0.462136      1\n",
              "\n",
              "[452 rows x 271 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UcXpQVXzvVw"
      },
      "source": [
        "Debido a que existen muchas clases desbalanceadas, se decide añadir las clases que tienen menos de 6 instancias a la clase others (16) 10. Estas clases corresponden a 7,8,14,15 las clases 11,12 y 13 tambien tienen menos de 6 instancias, pero estan vacias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrzJjLch9YSr",
        "outputId": "04b4dee1-3d62-40b4-8e9b-025ef50e04da"
      },
      "source": [
        "arrhythmia_data_norm['Class'].value_counts()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     245\n",
              "10     50\n",
              "2      44\n",
              "6      25\n",
              "16     22\n",
              "4      15\n",
              "3      15\n",
              "5      13\n",
              "9       9\n",
              "15      5\n",
              "14      4\n",
              "7       3\n",
              "8       2\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9yJQtpN0E73"
      },
      "source": [
        "arrhythmia_data_norm['Class'] = arrhythmia_data_norm['Class'].replace([7,8,14,15,9],16)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi7NxBBD8DGp",
        "outputId": "927a976b-3c69-40bc-9d59-ab6baacffd8d"
      },
      "source": [
        "arrhythmia_data_norm['Class'].value_counts()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     245\n",
              "10     50\n",
              "16     45\n",
              "2      44\n",
              "6      25\n",
              "4      15\n",
              "3      15\n",
              "5      13\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "rxoObNsSjUn4",
        "outputId": "39397e55-5502-4d57-efb6-a7342d0594fa"
      },
      "source": [
        "arrhythmia_data_norm"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>DIII_2</th>\n",
              "      <th>...</th>\n",
              "      <th>V2_21</th>\n",
              "      <th>V3_12</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.903614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.270677</td>\n",
              "      <td>0.368321</td>\n",
              "      <td>0.501805</td>\n",
              "      <td>0.241758</td>\n",
              "      <td>0.590244</td>\n",
              "      <td>0.457478</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.676301</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.159664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.504344</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.295775</td>\n",
              "      <td>0.793388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.660714</td>\n",
              "      <td>0.578431</td>\n",
              "      <td>0.584846</td>\n",
              "      <td>0.700352</td>\n",
              "      <td>0.224806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.804196</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648148</td>\n",
              "      <td>0.558824</td>\n",
              "      <td>0.624452</td>\n",
              "      <td>0.675298</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.457627</td>\n",
              "      <td>0.870130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.669173</td>\n",
              "      <td>0.592513</td>\n",
              "      <td>0.660574</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.381356</td>\n",
              "      <td>0.968531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.53125</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.507519</td>\n",
              "      <td>0.569579</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.674699</td>\n",
              "      <td>1</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.195489</td>\n",
              "      <td>0.332061</td>\n",
              "      <td>0.610108</td>\n",
              "      <td>0.150183</td>\n",
              "      <td>0.190244</td>\n",
              "      <td>0.577713</td>\n",
              "      <td>0.601124</td>\n",
              "      <td>0.442197</td>\n",
              "      <td>0.551495</td>\n",
              "      <td>0.075630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.440329</td>\n",
              "      <td>0.179348</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.580432</td>\n",
              "      <td>0.612324</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.260989</td>\n",
              "      <td>0.883450</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.453782</td>\n",
              "      <td>0.598598</td>\n",
              "      <td>0.570265</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.372881</td>\n",
              "      <td>0.922078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.564435</td>\n",
              "      <td>0.558747</td>\n",
              "      <td>0.614458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.360169</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31250</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.500971</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.650602</td>\n",
              "      <td>0</td>\n",
              "      <td>0.099259</td>\n",
              "      <td>0.523529</td>\n",
              "      <td>0.624060</td>\n",
              "      <td>0.311069</td>\n",
              "      <td>0.555957</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.497561</td>\n",
              "      <td>0.785924</td>\n",
              "      <td>0.592697</td>\n",
              "      <td>0.693642</td>\n",
              "      <td>0.667774</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.422954</td>\n",
              "      <td>0.179348</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.915289</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.395425</td>\n",
              "      <td>0.644434</td>\n",
              "      <td>0.596831</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.274725</td>\n",
              "      <td>0.867133</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.436975</td>\n",
              "      <td>0.533742</td>\n",
              "      <td>0.529823</td>\n",
              "      <td>0.743902</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.376271</td>\n",
              "      <td>0.889610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.491721</td>\n",
              "      <td>0.583812</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.402542</td>\n",
              "      <td>0.916084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.34375</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.424812</td>\n",
              "      <td>0.566990</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.662651</td>\n",
              "      <td>0</td>\n",
              "      <td>0.103704</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.338346</td>\n",
              "      <td>0.385496</td>\n",
              "      <td>0.534296</td>\n",
              "      <td>0.260073</td>\n",
              "      <td>0.697561</td>\n",
              "      <td>0.586510</td>\n",
              "      <td>0.528090</td>\n",
              "      <td>0.476879</td>\n",
              "      <td>0.514950</td>\n",
              "      <td>0.226891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.517147</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.316901</td>\n",
              "      <td>0.836777</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.519608</td>\n",
              "      <td>0.613046</td>\n",
              "      <td>0.694366</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.412088</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.483193</td>\n",
              "      <td>0.673094</td>\n",
              "      <td>0.653186</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.515254</td>\n",
              "      <td>0.879870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.601504</td>\n",
              "      <td>0.673866</td>\n",
              "      <td>0.687206</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.516949</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.592481</td>\n",
              "      <td>0.648544</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.903614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.248120</td>\n",
              "      <td>0.345420</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>0.252747</td>\n",
              "      <td>0.502439</td>\n",
              "      <td>0.457478</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.667630</td>\n",
              "      <td>0.458472</td>\n",
              "      <td>0.255995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.474166</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.299296</td>\n",
              "      <td>0.789256</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.539216</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>0.666197</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.462963</td>\n",
              "      <td>0.550420</td>\n",
              "      <td>0.617879</td>\n",
              "      <td>0.653477</td>\n",
              "      <td>0.560976</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.308475</td>\n",
              "      <td>0.970779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.593985</td>\n",
              "      <td>0.565155</td>\n",
              "      <td>0.587467</td>\n",
              "      <td>0.626506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.555085</td>\n",
              "      <td>0.874126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.21875</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.523308</td>\n",
              "      <td>0.656311</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>0.638554</td>\n",
              "      <td>1</td>\n",
              "      <td>0.081481</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.187970</td>\n",
              "      <td>0.379771</td>\n",
              "      <td>0.541516</td>\n",
              "      <td>0.168498</td>\n",
              "      <td>0.570732</td>\n",
              "      <td>0.395894</td>\n",
              "      <td>0.508427</td>\n",
              "      <td>0.606936</td>\n",
              "      <td>0.358804</td>\n",
              "      <td>0.159664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.412894</td>\n",
              "      <td>0.233696</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.045775</td>\n",
              "      <td>0.809917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.457516</td>\n",
              "      <td>0.540216</td>\n",
              "      <td>0.528169</td>\n",
              "      <td>0.263566</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.079670</td>\n",
              "      <td>0.759907</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.403361</td>\n",
              "      <td>0.458808</td>\n",
              "      <td>0.441955</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.138983</td>\n",
              "      <td>0.730519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.451128</td>\n",
              "      <td>0.348452</td>\n",
              "      <td>0.328982</td>\n",
              "      <td>0.674699</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.182203</td>\n",
              "      <td>0.825175</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.46875</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.299248</td>\n",
              "      <td>0.246602</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.445783</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.464706</td>\n",
              "      <td>0.338346</td>\n",
              "      <td>0.261450</td>\n",
              "      <td>0.465704</td>\n",
              "      <td>0.340659</td>\n",
              "      <td>0.356098</td>\n",
              "      <td>0.756598</td>\n",
              "      <td>0.682584</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.710963</td>\n",
              "      <td>0.243697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.779607</td>\n",
              "      <td>0.233696</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.429577</td>\n",
              "      <td>0.888430</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.738562</td>\n",
              "      <td>0.662334</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.618132</td>\n",
              "      <td>0.918415</td>\n",
              "      <td>0.375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.592437</td>\n",
              "      <td>0.850131</td>\n",
              "      <td>0.845796</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.718644</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.654135</td>\n",
              "      <td>0.773938</td>\n",
              "      <td>0.762924</td>\n",
              "      <td>0.614458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.944056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.618045</td>\n",
              "      <td>0.653722</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>0.433735</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090370</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.398496</td>\n",
              "      <td>0.335878</td>\n",
              "      <td>0.480144</td>\n",
              "      <td>0.315018</td>\n",
              "      <td>0.565854</td>\n",
              "      <td>0.255132</td>\n",
              "      <td>0.443820</td>\n",
              "      <td>0.315029</td>\n",
              "      <td>0.215947</td>\n",
              "      <td>0.336134</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.492913</td>\n",
              "      <td>0.141304</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.644366</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.803571</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.408779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.217054</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.565934</td>\n",
              "      <td>0.144522</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.609756</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.745763</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.187970</td>\n",
              "      <td>0.123830</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.690678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.71875</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034951</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>0.385542</td>\n",
              "      <td>1</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.288235</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.202290</td>\n",
              "      <td>0.555957</td>\n",
              "      <td>0.402930</td>\n",
              "      <td>0.307317</td>\n",
              "      <td>0.662757</td>\n",
              "      <td>0.578652</td>\n",
              "      <td>0.427746</td>\n",
              "      <td>0.591362</td>\n",
              "      <td>0.302521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.517241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.726566</td>\n",
              "      <td>0.298913</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.309859</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.624183</td>\n",
              "      <td>0.603973</td>\n",
              "      <td>0.847183</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.326923</td>\n",
              "      <td>0.843823</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.504202</td>\n",
              "      <td>0.623576</td>\n",
              "      <td>0.633110</td>\n",
              "      <td>0.597561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.518644</td>\n",
              "      <td>0.886364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.616541</td>\n",
              "      <td>0.622750</td>\n",
              "      <td>0.650653</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.975524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.520301</td>\n",
              "      <td>0.551456</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>0.939759</td>\n",
              "      <td>1</td>\n",
              "      <td>0.081481</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.180451</td>\n",
              "      <td>0.242366</td>\n",
              "      <td>0.476534</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>0.380488</td>\n",
              "      <td>0.586510</td>\n",
              "      <td>0.719101</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.604651</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>...</td>\n",
              "      <td>0.588935</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728873</td>\n",
              "      <td>0.869835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.480392</td>\n",
              "      <td>0.688328</td>\n",
              "      <td>0.729225</td>\n",
              "      <td>0.162791</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648352</td>\n",
              "      <td>0.853147</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.445378</td>\n",
              "      <td>0.739702</td>\n",
              "      <td>0.646494</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.423729</td>\n",
              "      <td>0.905844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.503759</td>\n",
              "      <td>0.601152</td>\n",
              "      <td>0.535248</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.440678</td>\n",
              "      <td>0.937063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.492481</td>\n",
              "      <td>0.462136</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 271 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Age  Sex    Height    Weight  ...     V6_19     V6_20     V6_21  Class\n",
              "0    0.903614    0  0.125926  0.435294  ...  0.741667  0.507519  0.569579     16\n",
              "1    0.674699    1  0.088889  0.341176  ...  0.675000  0.485714  0.500971      6\n",
              "2    0.650602    0  0.099259  0.523529  ...  0.783333  0.424812  0.566990     10\n",
              "3    0.662651    0  0.103704  0.517647  ...  0.716667  0.592481  0.648544      1\n",
              "4    0.903614    0  0.125926  0.435294  ...  0.825000  0.523308  0.656311     16\n",
              "..        ...  ...       ...       ...  ...       ...       ...       ...    ...\n",
              "447  0.638554    1  0.081481  0.376471  ...  0.550000  0.299248  0.246602      1\n",
              "448  0.445783    0  0.125926  0.464706  ...  0.700000  0.618045  0.653722     10\n",
              "449  0.433735    0  0.090370  0.364706  ...  0.583333  0.000000  0.034951      2\n",
              "450  0.385542    1  0.074074  0.288235  ...  0.700000  0.520301  0.551456      1\n",
              "451  0.939759    1  0.081481  0.376471  ...  0.633333  0.492481  0.462136      1\n",
              "\n",
              "[452 rows x 271 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sqJm7Zz9jnZ"
      },
      "source": [
        "Veamos que la clase 1 posee muchos datos en comparación al resto de las cases. Procederemos a botar unos cuantos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNGh_NXf9s-m",
        "outputId": "3035396a-3b38-419d-930f-80066f1cbcc8"
      },
      "source": [
        "filtering_data = arrhythmia_data_norm[arrhythmia_data_norm['Class'] == 1].sample(180).index\r\n",
        "arrhythmia_data_balanced = arrhythmia_data_norm[~arrhythmia_data_norm.index.isin(filtering_data)]\r\n",
        "arrhythmia_data_balanced['Class'].value_counts()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     65\n",
              "10    50\n",
              "16    45\n",
              "2     44\n",
              "6     25\n",
              "4     15\n",
              "3     15\n",
              "5     13\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "ThLe6j5uiMDg",
        "outputId": "5df2a8c7-9ad6-44b6-de13-fe2f2e1417d4"
      },
      "source": [
        "arrhythmia_data_balanced"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>QRS duration</th>\n",
              "      <th>P-R interval</th>\n",
              "      <th>Q-T interval</th>\n",
              "      <th>T interval</th>\n",
              "      <th>P intervaL</th>\n",
              "      <th>QRS</th>\n",
              "      <th>T</th>\n",
              "      <th>P</th>\n",
              "      <th>QRST</th>\n",
              "      <th>Heart rate</th>\n",
              "      <th>Q wave</th>\n",
              "      <th>R wave</th>\n",
              "      <th>S wave</th>\n",
              "      <th>R' wave</th>\n",
              "      <th>Number of intrinsic deflections</th>\n",
              "      <th>Existence of ragged R wave</th>\n",
              "      <th>Existence of diphasic derivation of R wave</th>\n",
              "      <th>Existence of ragged P wavel</th>\n",
              "      <th>Existence of diphasic derivation of P wave</th>\n",
              "      <th>Existence of ragged T wave</th>\n",
              "      <th>Existence of diphasic derivation of T wave</th>\n",
              "      <th>DII_0</th>\n",
              "      <th>DII_1</th>\n",
              "      <th>DII_2</th>\n",
              "      <th>DII_3</th>\n",
              "      <th>DII_4</th>\n",
              "      <th>DII_5</th>\n",
              "      <th>DII_6</th>\n",
              "      <th>DII_7</th>\n",
              "      <th>DII_8</th>\n",
              "      <th>DII_9</th>\n",
              "      <th>DII_10</th>\n",
              "      <th>DII_11</th>\n",
              "      <th>DIII_0</th>\n",
              "      <th>DIII_1</th>\n",
              "      <th>DIII_2</th>\n",
              "      <th>...</th>\n",
              "      <th>V2_21</th>\n",
              "      <th>V3_12</th>\n",
              "      <th>V3_13</th>\n",
              "      <th>V3_14</th>\n",
              "      <th>V3_15</th>\n",
              "      <th>V3_16</th>\n",
              "      <th>V3_17</th>\n",
              "      <th>V3_18</th>\n",
              "      <th>V3_19</th>\n",
              "      <th>V3_20</th>\n",
              "      <th>V3_21</th>\n",
              "      <th>V4_12</th>\n",
              "      <th>V4_13</th>\n",
              "      <th>V4_14</th>\n",
              "      <th>V4_15</th>\n",
              "      <th>V4_16</th>\n",
              "      <th>V4_17</th>\n",
              "      <th>V4_18</th>\n",
              "      <th>V4_19</th>\n",
              "      <th>V4_20</th>\n",
              "      <th>V4_21</th>\n",
              "      <th>V5_12</th>\n",
              "      <th>V5_13</th>\n",
              "      <th>V5_14</th>\n",
              "      <th>V5_15</th>\n",
              "      <th>V5_16</th>\n",
              "      <th>V5_18</th>\n",
              "      <th>V5_19</th>\n",
              "      <th>V5_20</th>\n",
              "      <th>V5_21</th>\n",
              "      <th>V6_12</th>\n",
              "      <th>V6_13</th>\n",
              "      <th>V6_14</th>\n",
              "      <th>V6_15</th>\n",
              "      <th>V6_16</th>\n",
              "      <th>V6_18</th>\n",
              "      <th>V6_19</th>\n",
              "      <th>V6_20</th>\n",
              "      <th>V6_21</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.903614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.270677</td>\n",
              "      <td>0.368321</td>\n",
              "      <td>0.501805</td>\n",
              "      <td>0.241758</td>\n",
              "      <td>0.590244</td>\n",
              "      <td>0.457478</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.676301</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.159664</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.504344</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.295775</td>\n",
              "      <td>0.793388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.660714</td>\n",
              "      <td>0.578431</td>\n",
              "      <td>0.584846</td>\n",
              "      <td>0.700352</td>\n",
              "      <td>0.224806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.804196</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648148</td>\n",
              "      <td>0.558824</td>\n",
              "      <td>0.624452</td>\n",
              "      <td>0.675298</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.457627</td>\n",
              "      <td>0.870130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.669173</td>\n",
              "      <td>0.592513</td>\n",
              "      <td>0.660574</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.381356</td>\n",
              "      <td>0.968531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.53125</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.507519</td>\n",
              "      <td>0.569579</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.674699</td>\n",
              "      <td>1</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.195489</td>\n",
              "      <td>0.332061</td>\n",
              "      <td>0.610108</td>\n",
              "      <td>0.150183</td>\n",
              "      <td>0.190244</td>\n",
              "      <td>0.577713</td>\n",
              "      <td>0.601124</td>\n",
              "      <td>0.442197</td>\n",
              "      <td>0.551495</td>\n",
              "      <td>0.075630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.440329</td>\n",
              "      <td>0.179348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.580432</td>\n",
              "      <td>0.612324</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.260989</td>\n",
              "      <td>0.883450</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.453782</td>\n",
              "      <td>0.598598</td>\n",
              "      <td>0.570265</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.372881</td>\n",
              "      <td>0.922078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.564435</td>\n",
              "      <td>0.558747</td>\n",
              "      <td>0.614458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.360169</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.31250</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.485714</td>\n",
              "      <td>0.500971</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.650602</td>\n",
              "      <td>0</td>\n",
              "      <td>0.099259</td>\n",
              "      <td>0.523529</td>\n",
              "      <td>0.624060</td>\n",
              "      <td>0.311069</td>\n",
              "      <td>0.555957</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.497561</td>\n",
              "      <td>0.785924</td>\n",
              "      <td>0.592697</td>\n",
              "      <td>0.693642</td>\n",
              "      <td>0.667774</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.422954</td>\n",
              "      <td>0.179348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.204225</td>\n",
              "      <td>0.915289</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.395425</td>\n",
              "      <td>0.644434</td>\n",
              "      <td>0.596831</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.274725</td>\n",
              "      <td>0.867133</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.436975</td>\n",
              "      <td>0.533742</td>\n",
              "      <td>0.529823</td>\n",
              "      <td>0.743902</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.376271</td>\n",
              "      <td>0.889610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.491721</td>\n",
              "      <td>0.583812</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.402542</td>\n",
              "      <td>0.916084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.34375</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.424812</td>\n",
              "      <td>0.566990</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.903614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.248120</td>\n",
              "      <td>0.345420</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>0.252747</td>\n",
              "      <td>0.502439</td>\n",
              "      <td>0.457478</td>\n",
              "      <td>0.533708</td>\n",
              "      <td>0.667630</td>\n",
              "      <td>0.458472</td>\n",
              "      <td>0.255995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.474166</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.299296</td>\n",
              "      <td>0.789256</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.539216</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>0.666197</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.417582</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.462963</td>\n",
              "      <td>0.550420</td>\n",
              "      <td>0.617879</td>\n",
              "      <td>0.653477</td>\n",
              "      <td>0.560976</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.308475</td>\n",
              "      <td>0.970779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.593985</td>\n",
              "      <td>0.565155</td>\n",
              "      <td>0.587467</td>\n",
              "      <td>0.626506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.555085</td>\n",
              "      <td>0.874126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.21875</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.523308</td>\n",
              "      <td>0.656311</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.156627</td>\n",
              "      <td>0</td>\n",
              "      <td>0.094815</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.338346</td>\n",
              "      <td>0.318702</td>\n",
              "      <td>0.321300</td>\n",
              "      <td>0.241758</td>\n",
              "      <td>0.443902</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.682584</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.740864</td>\n",
              "      <td>0.336134</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.288043</td>\n",
              "      <td>0.975684</td>\n",
              "      <td>0.697183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.839286</td>\n",
              "      <td>0.669935</td>\n",
              "      <td>0.313634</td>\n",
              "      <td>0.258451</td>\n",
              "      <td>0.403101</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.851648</td>\n",
              "      <td>0.400932</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.592437</td>\n",
              "      <td>0.674847</td>\n",
              "      <td>0.719232</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.629870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.624060</td>\n",
              "      <td>0.553636</td>\n",
              "      <td>0.588512</td>\n",
              "      <td>0.674699</td>\n",
              "      <td>0.853659</td>\n",
              "      <td>0.516949</td>\n",
              "      <td>0.902098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.53125</td>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.433835</td>\n",
              "      <td>0.451133</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444</th>\n",
              "      <td>0.349398</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090370</td>\n",
              "      <td>0.335294</td>\n",
              "      <td>0.195489</td>\n",
              "      <td>0.272901</td>\n",
              "      <td>0.335740</td>\n",
              "      <td>0.402930</td>\n",
              "      <td>0.360976</td>\n",
              "      <td>0.574780</td>\n",
              "      <td>0.573034</td>\n",
              "      <td>0.583815</td>\n",
              "      <td>0.531561</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.212121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.681756</td>\n",
              "      <td>0.309783</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.169014</td>\n",
              "      <td>0.902893</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.637255</td>\n",
              "      <td>0.599559</td>\n",
              "      <td>0.863732</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.203297</td>\n",
              "      <td>0.918415</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.599474</td>\n",
              "      <td>0.612162</td>\n",
              "      <td>0.621951</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.315254</td>\n",
              "      <td>0.925325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.616541</td>\n",
              "      <td>0.539237</td>\n",
              "      <td>0.593734</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.330508</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>0.438346</td>\n",
              "      <td>0.489968</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>0.542169</td>\n",
              "      <td>0</td>\n",
              "      <td>0.103704</td>\n",
              "      <td>0.405882</td>\n",
              "      <td>0.270677</td>\n",
              "      <td>0.255725</td>\n",
              "      <td>0.519856</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.404878</td>\n",
              "      <td>0.771261</td>\n",
              "      <td>0.688202</td>\n",
              "      <td>0.580925</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.218487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.620690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430270</td>\n",
              "      <td>0.222826</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.116197</td>\n",
              "      <td>0.756198</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.696429</td>\n",
              "      <td>0.539216</td>\n",
              "      <td>0.526238</td>\n",
              "      <td>0.559155</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.778555</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.314815</td>\n",
              "      <td>0.487395</td>\n",
              "      <td>0.497371</td>\n",
              "      <td>0.519639</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.281356</td>\n",
              "      <td>0.834416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.511278</td>\n",
              "      <td>0.433405</td>\n",
              "      <td>0.425065</td>\n",
              "      <td>0.626506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.300847</td>\n",
              "      <td>0.916084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.608333</td>\n",
              "      <td>0.396241</td>\n",
              "      <td>0.363754</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>0.445783</td>\n",
              "      <td>0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.464706</td>\n",
              "      <td>0.338346</td>\n",
              "      <td>0.261450</td>\n",
              "      <td>0.465704</td>\n",
              "      <td>0.340659</td>\n",
              "      <td>0.356098</td>\n",
              "      <td>0.756598</td>\n",
              "      <td>0.682584</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.710963</td>\n",
              "      <td>0.243697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.779607</td>\n",
              "      <td>0.233696</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.429577</td>\n",
              "      <td>0.888430</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.738562</td>\n",
              "      <td>0.662334</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.618132</td>\n",
              "      <td>0.918415</td>\n",
              "      <td>0.375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.592437</td>\n",
              "      <td>0.850131</td>\n",
              "      <td>0.845796</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.718644</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.654135</td>\n",
              "      <td>0.773938</td>\n",
              "      <td>0.762924</td>\n",
              "      <td>0.614458</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.944056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.618045</td>\n",
              "      <td>0.653722</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>0.433735</td>\n",
              "      <td>0</td>\n",
              "      <td>0.090370</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.398496</td>\n",
              "      <td>0.335878</td>\n",
              "      <td>0.480144</td>\n",
              "      <td>0.315018</td>\n",
              "      <td>0.565854</td>\n",
              "      <td>0.255132</td>\n",
              "      <td>0.443820</td>\n",
              "      <td>0.315029</td>\n",
              "      <td>0.215947</td>\n",
              "      <td>0.336134</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.241379</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.492913</td>\n",
              "      <td>0.141304</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.644366</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.803571</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.408779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.217054</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.565934</td>\n",
              "      <td>0.144522</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.609756</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.745763</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.187970</td>\n",
              "      <td>0.123830</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.690678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.71875</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034951</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>0.939759</td>\n",
              "      <td>1</td>\n",
              "      <td>0.081481</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.180451</td>\n",
              "      <td>0.242366</td>\n",
              "      <td>0.476534</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>0.380488</td>\n",
              "      <td>0.586510</td>\n",
              "      <td>0.719101</td>\n",
              "      <td>0.641618</td>\n",
              "      <td>0.604651</td>\n",
              "      <td>0.260504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>...</td>\n",
              "      <td>0.588935</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.728873</td>\n",
              "      <td>0.869835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.480392</td>\n",
              "      <td>0.688328</td>\n",
              "      <td>0.729225</td>\n",
              "      <td>0.162791</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.648352</td>\n",
              "      <td>0.853147</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574074</td>\n",
              "      <td>0.445378</td>\n",
              "      <td>0.739702</td>\n",
              "      <td>0.646494</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.423729</td>\n",
              "      <td>0.905844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.503759</td>\n",
              "      <td>0.601152</td>\n",
              "      <td>0.535248</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.440678</td>\n",
              "      <td>0.937063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40625</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.492481</td>\n",
              "      <td>0.462136</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>272 rows × 271 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Age  Sex    Height    Weight  ...     V6_19     V6_20     V6_21  Class\n",
              "0    0.903614    0  0.125926  0.435294  ...  0.741667  0.507519  0.569579     16\n",
              "1    0.674699    1  0.088889  0.341176  ...  0.675000  0.485714  0.500971      6\n",
              "2    0.650602    0  0.099259  0.523529  ...  0.783333  0.424812  0.566990     10\n",
              "4    0.903614    0  0.125926  0.435294  ...  0.825000  0.523308  0.656311     16\n",
              "5    0.156627    0  0.094815  0.264706  ...  0.683333  0.433835  0.451133     16\n",
              "..        ...  ...       ...       ...  ...       ...       ...       ...    ...\n",
              "444  0.349398    0  0.090370  0.335294  ...  0.691667  0.438346  0.489968      1\n",
              "445  0.542169    0  0.103704  0.405882  ...  0.608333  0.396241  0.363754      1\n",
              "448  0.445783    0  0.125926  0.464706  ...  0.700000  0.618045  0.653722     10\n",
              "449  0.433735    0  0.090370  0.364706  ...  0.583333  0.000000  0.034951      2\n",
              "451  0.939759    1  0.081481  0.376471  ...  0.633333  0.492481  0.462136      1\n",
              "\n",
              "[272 rows x 271 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldvEVYnhtW3p"
      },
      "source": [
        "# Metricas para evaluar modelos de regresion y clasificacion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV9uTeCx9Y10"
      },
      "source": [
        "En primer lugar hay que notar que nuestros modelos de clasificación serán multiclase (tenemos 16 clases distintas). \r\n",
        "\r\n",
        "A continuacion se presentan distintas métricas para evaluar modelos de clasificación multiclase (Dado la naturaleza de nuestro modelo). Los ejemplos y definiciones se encuentran en scikit-learn.org"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LMZb7bF95ik"
      },
      "source": [
        "## Balanced Acuracy\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0lq5nWfCKum"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score\r\n",
        "\r\n",
        "> Calcula la precisión balanceada con el fin de trabajar con sets de datos balanceados. Se define como el promedio de certitud en cada clase.\r\n",
        "\r\n",
        "Ejemplo tomado de https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score y mas ejemplos en el análisis de los modelos implementados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DNtRyNa9YGV",
        "outputId": "f52095ef-ef96-4277-a961-31bdb3b16bd5"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "y_true = [0, 1, 0, 0, 1, 0]\r\n",
        "y_pred = [0, 1, 0, 0, 0, 1]\r\n",
        "balanced_accuracy_score(y_true, y_pred)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtEqKre7CRd9"
      },
      "source": [
        "## Cohen's kappa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNiM8KXUCYDm"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "> Estadistica que mide el nivel de concordancia entre dos anotadores en un problema de clasificacion. (En nuestro caso, el set de datos vs lo predicho). Valores mayores a 0.8 por lo general son buenos\r\n",
        "\r\n",
        "Ejemplo tomado de: https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-kappa\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xucn0nkoDAU-",
        "outputId": "6e720bb7-f405-42c5-830a-a046ddb775c0"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "y_true = [0, 1, 0, 0, 1, 0]\r\n",
        "y_pred = [0, 1, 0, 0, 0, 1]\r\n",
        "balanced_accuracy_score(y_true, y_pred)\r\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlwN-QOeDon2"
      },
      "source": [
        "## Matriz de confusión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yycv20xiD1H1"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\r\n",
        "\r\n",
        "\r\n",
        "> Evalua la presicion de la clasificación, de forma que cada entrada i,j es iigual al numero de observaciones del grupo i predecidas en el grupo j.\r\n",
        "\r\n",
        "Ejemplo tomado de: https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2rlqmZEFPct",
        "outputId": "690c5291-f46a-4c7d-8046-0156636833bc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "y_true = [2, 0, 2, 2, 0, 1]\r\n",
        "y_pred = [0, 0, 2, 2, 0, 2]\r\n",
        "confusion_matrix(y_true, y_pred)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4OxQthYGFe7"
      },
      "source": [
        "## Hinge Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sihqzMMpJyb0"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss\r\n",
        "\r\n",
        "\r\n",
        "> Computa la distancia promedio entre el modelo y los datos utilizando en \"hinge loss\" (considera solo errores de prediccion)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Dp0OfWLpiq",
        "outputId": "7839ddf4-bb54-4f24-b9da-c384799e5aa3"
      },
      "source": [
        "from sklearn import svm\r\n",
        "from sklearn.metrics import hinge_loss\r\n",
        "import numpy as np\r\n",
        "X = np.array([[0], [1], [2], [3]])\r\n",
        "Y = np.array([0, 1, 2, 3])\r\n",
        "labels = np.array([0, 1, 2, 3])\r\n",
        "est = svm.LinearSVC()\r\n",
        "est.fit(X, Y)\r\n",
        "\r\n",
        "pred_decision = est.decision_function([[-1], [2], [3]])\r\n",
        "y_true = [0, 2, 3]\r\n",
        "hinge_loss(y_true, pred_decision, labels=labels)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5641215399431175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v97hwJ5PL8W9"
      },
      "source": [
        "## Matthews correlation coefficient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37bnRclkMEcm"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef\r\n",
        "\r\n",
        "\r\n",
        "> Mide la calidad de clasificadores binarios o multiclase. Toma en cuenta los verdaderos y falsos positivos y negativos. +1 representa prediccion perfecta, 0 prediccion promedio aleatorio y -1 prediccion inversa.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qudzdlMM2ud",
        "outputId": "ad86cbcd-e568-4a24-b5ae-8671dfa77653"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\r\n",
        "y_true = [+1, +1, +1, -1]\r\n",
        "y_pred = [+1, -1, +1, +1]\r\n",
        "matthews_corrcoef(y_true, y_pred)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR4Tbw5QNFTm"
      },
      "source": [
        "## Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEnTw4BxNJc2"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "> UNa curva ROC consiste en una grafica que ilustra el desempeño de un clasificador conforme se varia su umbral de discriminacion. La curva se representa tomando la fraccion de verdaderos positvos vs la fraccion de falsos positivos a varios valores de umbral.El escore ROC AUC encuentra el area bajo la curva ROC de modo que la información de la curva queda almacenado en un solo valor.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XinhrXOOTMX",
        "outputId": "833471df-2a90-438d-d94f-060c477bcade"
      },
      "source": [
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "X, y = load_iris(return_X_y=True)\r\n",
        "clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\r\n",
        "roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9913333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBK50UpF-bz6"
      },
      "source": [
        "# Validacion Cruzada\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcrQGgl1QwnC"
      },
      "source": [
        "## Metodo general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atMh0Ct-RR42"
      },
      "source": [
        "La validación cruzada consiste en un metodo para evitar overfitting. \r\n",
        "\r\n",
        "Tradicionalmente se dividen los datos en test y training con el fin de evitar overfitting, sin embargo aun asi es posible caer en overfitting ya que los parámetros se pueden modificar hasta que el estimador funciona de manera optima, de alguna manera esto se puede ver como que la informacion de test se filtra al modelo.\r\n",
        "\r\n",
        "Se propone una solucion denominada Validacion Cruzada(CV por sus siglas en ingles) con el aproximacion basica: k-fold CV.\r\n",
        "\r\n",
        "En primer lugar se parte de un set de training y test, sin embargo el set de training se divide en k sets mas pequeños (folds). Para cada uno de los folds el modelo se entrena utilizando k-1 subsets y el modelo se valida utilizando la parte resultante de los datos.\r\n",
        "\r\n",
        "El desempeño de la k-fold CV es el promedio de los valores computados.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDYh0YQZUk2m"
      },
      "source": [
        "## Estimación de parametros utilizando grid search con Validacion Cruzada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXL8ixwFVfzw"
      },
      "source": [
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0TDIeTOViUE"
      },
      "source": [
        "Normalmente para setear los valores de los hiperparámetros se setean valores aleatorios que se van cambiando tras tener un mejor desempeño, sin embargo, dependiendo modelo este proceso puede ser complicado. Por lo cual es mejor tener un algoritmo que automaticamente puede encontrar los mkejores parametros para un modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12EfrYPkUYO2"
      },
      "source": [
        "Es por esto que se puede utilizar el algoritmo de GridSearch para encontrar los mejores hiperparámetros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2AlQctgxnW_"
      },
      "source": [
        "El ejemplo de esto se puede ver aplicado para cualquiera de los modelos obtenidos, ya que se aplico el metodo para obtener los parametros optimos en cada uno de ellos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ss7LSM2ZYd5"
      },
      "source": [
        "# Modelo Investigado: Redes Neuronales. (Perceptrón multicapa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-jgE_HtZibr"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "263oCpD0aHzx"
      },
      "source": [
        "\r\n",
        "> Consiste en un algoritmo de aprendizaje supervisado que aprende una funcion ![image.png](data:image/png;base64,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) a partir de un set de entrenamiento. \r\n",
        "\r\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAw8AAANTCAYAAADokCFaAAAgAElEQVR4AeydB5gkVfW3X8lJkCQoqCAZFREEFBUEFQQEFRRFCSqYRUliVpIkRVABWRBwd+v2rKOIIKKICEgSUUHAQBAUCUrOS9jwPb8/t/yK3u6e6u6q7qqe332eebq76oZz39szc07de84BFxMwgYkIrAm8DtgE2CD+vBbYAngr8E7gfcCewKeA9wObAasA803Ueby/MPAN4BfAm3O2cTUTMAETMAETMAETMAETMIGKEZBRcBMwt8XPX4EZwBeBvYAjgF8Cc2LdG4APAQtOMKedM30/ACw5QX3fNgETMAETMAETMAETMAETqCiB58SdgawBcX8HWV8NXJkxCK4FlupQf+tM3QeBRTvU9S0TMAETMAETMAETMAETMIGKE9goo+DLiLhrAnmXB+7ItDkPWKBDm72BAGzZoY5vmYAJmIAJmIAJmIAJmIAJ1ICA/Be025DuPvwzh8zyhUjr63WrHG1cxQRMwARMwARMwARMwARMYAQIXJ8xBuTPMFFZPVNfxsNXJ2rg+yZgAiZgAiZgAiZgAiZgAqNB4IqMMSA/homKdiuezLRpTNTA903ABEzABEzABEzABEzABEaDwPkZQ+CqHFOS30P22NKhOdq4igmYgAmYgAmYgAmYgAmYwAgQODNjDFyWYz7bZOrLiHhLjjauYgImYAImYAImYAImYAImMAIEpmWMgUtzzOf4TP2zO9RXHogXA6+ICen0Pk9Ru5cArwHWA56fp1FTnRcBb4t5KhTpabGm+/5oAiZgAiZgAiZgAiZgAibQA4Gs8XD5BO2VbTo9snQhoCNMrcoU4KlMXbXZt1XFzLVtYzbqWYCOT50IaCdEbZW4bvdM3XZvJc9pwL8AyfAB4EhAfh3fAfYDPt6usa+bgAmYgAmYgAmYgAmYgAl0JjCeUfLb+Txo90DKt7JM3wN8GZi/c7e8IGamTo2Nz3SoL7+JtN57mupJ2U/vfanpXvbjQsAfgDtbJKRbGPhZ7OfUbCO/NwETMAETMAETMAETMAETyE9AR49S5fxh4GPx5xBAirYUct1/FPgIICU9b3l/pu9Pt2m0QabObW2Szv0+1nmkTR+6/IVYZ/82dVYAlOlaRoSLCZiACZiACZiACZiACZhADwR+kVHeHweOBQ4CDgCOAsYAHWfScaLHgOnAm3OOo3qpYaIjT63Krpk6MgBalayfxVKtKgC/iv0c3ua+LusIk45buZiACZiACZiACZiACZiACfRAIFW6peS3O7akbpUcTjsRT0clXU/wdTSpU3ldxjBoZzwsAfwduLGDD8XJmX5e1mbAP8c6D0RH61bVJK+iS7mYgAmYgAmYgAmYgAmYgAn0QOCCjGIu/4eJyicz9e8HXt2hwUaZuvt0qKfEc/ppVRR96d5MPxu3qhQdpNNdDhk4U4G1WtTt5thVi+a+ZAImYAImYAImYAImYAKTl8BFGcU8yYkhmxtCOwaLt2mncKupQq9jUN0WGQo/Bv6U6Uc+Eq2KjBj5ZaTj6XU2MANYt1UDXzMBEzABEzABEzABEzABE+iOwCUZhVthTvOUd2TaSElv56uQPbb0+TwdA88DdMTpauAMYDkg6/OgyE/tyhbAXU2ypUbED2L+iHZtfd0ETMAETMAETMAETMAETGACAvJzSJ/WKzdCnrJGpo3atotgtFmmXqcwqxpThoaOGslp+3bgvRlBvpHpZ+3M9VZvFwEU2Ul9pPNKX2fG5HOt2vmaCZiACZiACZiACZiACZjABARuyCjZesKfp8g/QUeCUqX85jaNtBOQ1ulkPKRhVlU3tDgGpbCxaT9y3M5TlNtB/hn/ybRVH9qZsN9DHoKuYwImYAImYAImYAImYAJNBJRULVXMv9V0r93HZTNt1PacNhWzoVrbGQ/ZUK0KA9uqKPxqKuNqLSooYlOr66qqezqOlbbXq3Y5XEzABEzABEzABEzABEzABLokoMRrqWJ9TM62m2baqG07w2DrTL0vtuk7G+1JidxalRMy/azTosIO0TG6xa3/Xfpepo/d/3fVb0zABEzABEzABEzABEzABHIRmB+Yk1GqpWDnKadk2iivwovbNNo2U+9zLepoV+DJWEfZn9uVNMu1DJVXtai0TUxit2qLe+mlpTNzbRexKa3rVxMwARMwARMwARMwARMwgSYC2WhIUsynNd1v9XE9QI7H6W7Fu1pVitfek6nXynh4bkahV3/rt+hLkZ2yBs6OLepsGcdRtuzntLivSwtEQ0XHtOzz0AaSL5uACZiACZiACZiACZhAOwLfzCj3Ut4nyr6sSEf/zLSRI3On8tVMXeVraFWyORy0oyElPy2bANcA2Z2OVn4Zr8+M0y4k7HbRCNkq7dyvJmACJmACJmACJmACJmACnQksCshn4bvAUxmlW8aDnvAry/QngHcDbwTeCXwZaMQwqqonhf7tHYaR74KSwt2a6V/HkvYCnt/UTkeIdE/96udfwHExz8OVwCrAzpn7CuW6L7BLxtBQJuv7AOVyUF9ykH5RZpydgH8AH8xc81sTMAETMAETMAETMAETMIEJCCh8qpTrk4ETge8Aepp/NKCoRtpNOCwq8Mr7oKNMUsq/HfMnvHKC/nVsSE//vwbsD3wM+DDwWeDrwLGAojVly/LAwXHn43xA426fMQ6UwVr9KFu0diGU90H307IgsGb8oDwPOi4lY0dRoH4Y55M1JtJ2fjUBEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzABEzCB0SEwF54zDRYfhxWnw+oB1m/A6xN4zTR4+Ris0oDlTgclfnMxARMwARMwARMwARMwARMYZQJTYLEx2KQBuwY4KEAIcGWAewPMCTA358/TAW4L8JsAUxrw2Qa8I4F1D4L5Rpmh52YCJmACJmACJmACJmACI0kggSUDbBvgyACXB3gqp3EgI2JmgHsCPBBAxkJew0L1fxbggAAbXwgLjCRcT8oETMAETMAETMAETMAE6k4gwEsT+EKAqwLMbqH0Px7g2gb8JIGjA3ykAVvOgHXG4EWnw/NaKfw6rqRjS9Ng1Qas14DtA+ybwAkBzgtwS4BZLcZ7NIFzAuwmY6bufC2/CZiACZiACZiACZiACdSagJT+BPYP8PsWyruOJJ0pRX8MXj0O85c12VPhuQG2DvD1Bvw2wBNN8ujzmQm8R/4VZcnhfk3ABEzABEzABEzABEzABJoIaMcggV+08Fe4OoEDG/AyOUI3NRvYx7hbsXkC3wnwnyZD4tEA39VOxsAE8kAmYAImYAImYAImYAImMJkIaOdAT+4D/KFJGb8xgYMbsHYVeUjuAG9uwKnRjyL1odBRpxnTYYMqym2ZTMAETMAETMAETMAETKB2BBTFKIEPR9+CrOL94zHYtE4TGoeF5AMR4OomA+iCBry2TnOxrCZgAiZgAiZgAiZgAiZQKQIBtgjw54yi/UiAb4/CkR8dvQrw8+zRqwQa8uOo1CJYGBMwARMwARMwARMwAROoMoEZsFp0dk53GmYmcJgiIlVZ7l5kU46IBpyVMZAe1zEs5abopT+3MQETMAETMAETMAETMIFJQSAeUVK41SczyvTYVHjxqANI4E1Nuyy36dqoz9vzMwETMAETMAETMAETMIGuCQR4SQxzmu42XDnZ/ACic/VHAvw3Gk/Kfv2tc2HhroG6gQmYgAmYgAmYgAmYgAmMIoEG7BrgwagwP9WAL5WZl6HqDKfB8wOcne6+NOC66fDKqstt+UzABEzABEzABEzABEygNALKhxAgpEpygL8F2LC0AWvWsbJgB1BeCO3GPNmAj9ZsChbXBEzABEzABEzABEzABPonMA7LB7giYzgcPw6L9t/zaPUQYI0EfpdySuDoYSbAGy26no0JmIAJmIAJmIAJmEDlCUyHtQL8IyrEjwXYsfJCD1HAC2GBAMenBkSAH9vQGuKCeGgTMAETMAETMAETMIHBEJgObwxwvxThBO5KYKPBjFz/UQJ8JsDsyO538o2o/6w8AxMwARMwARMwARMwARNoQSDAtmkYVjkBT4YQrC0w9HVpOuyQ8YO4cTq8oK8O3dgETMAETMAETMAETMAEqkYg5jGYqafmDbgwgSWrJmNd5JkOGwS4Jx5j+ov8R+oiu+U0ARMwARMwARMwARMwgY4EpsMbAsi3QVGDLp0Gi3ds4JsTEhiDVwV4IBpj14zDMhM2cgUTMAETMAETMAETMAETqDKBMdgkwMPRcPi9dxyKW60AG2fYXmW2xbF1TyZgAiZgAiZgAiZgAgMmMBVWklN0NByuDrD0gEUY+eEa8PrUB6IBZzmM68gvuSdoAiZgAiZgAiZgAqNH4FxYOJOf4JYGLDd6s6zGjBLYKsCsaKR9rRpSWQoTMAETMAETMAETMAETyEkgwClRmX08wPo5m7lajwQSODDyntOA7Xvsxs1MwARMwARMwARMwARMYLAEEvhYVGTlIL3bYEefvKMpeVzk/pAS8U1eEp65CZiACZiACZiACZhALQhMg5enuRwCfLcWQo+IkOOwRAJ/jQbEn6fAgiMyNU/DBEzABEzABEzABExg1AgcBPOlfg4JXGbldfArPAPWDPCIDIgGfGnwEnhEEzABEzABEzABEzABE8hBIMBn4lPvJ3xsJgewkqp4HUoC625NwARMwARMwARMwASKITAGq6QhQwN8uZhe3UsvBLQDFODKuPvwW4dv7YWi25iACZiACZiACZiACZRGIMAvo7J6nY8rlYY5d8cNWC/AU1oTObDnbuiKJmACJmACJmACJmACJlAmgZhnQJGVZifwmjLHct/5CTTg8HiM7O5psHj+lq5pAiZgAiZgAiZgAiZgAiURSI/IJNAoaQh32wMBGQwB7o67D1/ooQs3MQETMAETMAETMAETMIHiCCghWXy6PctO0sVxLaqnBPaP63P/OCxVVL/uxwRMwARMwARMwARMwAS6IiBH3ABXR+V0aleNXXkgBMZh0QTuimt00EAG9SAmYAImYAImYAImYAIm0EwgwNujUvr0DFit+b4/V4NAgE/HdXoogSWrIZWlMAETMAETMAETMAETmFQEApwbldLTJ9XEazbZc2HhzO7DR2omvsU1ARMwARMwARMwAROoO4EEVlZ0pWg8bFz3+Yy6/JnIS1eO+lw9PxMwARMwARMwARMwgYoRCPCVaDhcWzHRLE4LAjpWFmCO1iyBV7So4ksmYAImYAImYAImYAImUDyB6Ch9ixTRBuxd/AjusQwCAS6IBt9xZfTvPk3ABEzABEzABEzABExgHgIBtohK6MwAS89TwRcqSaABu8R1u/dCWKCSQlooEzABEzABEzABEzCB0SIQ4Ji46/Cj0ZrZaM9GjtMBHtHaTYc3jPZsPTsTMAETMAETMAETMIFKEAhwfTQe9qqEQBYiN4EEztHaJXBY7kauaAImYAImYAImYAImYAK9EJgKK0n51M8YrNJLH24zPAIJ7BPX76rhSeGRTcAETMAETMAETMAEJgWBBD4Ulc+bJsWER2ySDXhZXL/ZDVhuxKbn6ZiACZiACZiACZiACVSJQIAZUfk8sUpyWZb8BALcGdfwvflbuaYJmIAJmIAJmIAJmIAJdEkgwL+keCbwzi6bjnL1NYFl6zLBAFOj8fDtushsOU3ABEzABEzABEzABGpGYByWSBONVdjfYUlgLnBDyXgXBrYHfgnMAT5V8niFdZ/xezi/sE7dkQmYgAmYgAmYgAmYgAlkCYzBq+MT68cPgvmy9yr0vkzjYX/gPOBWYHY0UmSo6GefCjHoKEoD3qp1bMDtHSv6pgmYgAmYgAmYgAmYgAn0SiDA7lHpvKbXPgbQrkzjQdGl3gR8BrinrsaDdo2iEajjZ+LlYgImYAImYAImYAImYALFEkjgiKh0jhXbc6G9lWk8ZAXdvMl4+HT2ZpXfz4XnBHhcazkGm1RZVstmAiZgAiZgAiZgAiZQUwIBfhyNh4MqPIVBGQ9CoGM/6bGlT1SYyTyiNeAarWUDdp3npi+YgAmYgAmYgAmYgAmYQL8EAlwQjYcqOwcP0ni4LGM8fKRfvoNsH+DX0XjYe5DjeiwTMAETMAETMAETMIFJQiDAVdF42K3CUx6k8XBmxnj4UIWZzCNagDOi8fCleW76ggmYgAmYgAmYgAmYgAn0SyDAjVI4p8MO/fZVYvtBGg8/zhgPu5c4p8K7DnCa1jKBowvv3B2agAmYgAmYgAmYgAmYQID/xKfVchauahmk8TCeMR7eV1UgreRqwLHReDip1X1fMwETMAETMAETMAETMIG+CASYKYVzDF7VV0flNh6k8TAjYzzsXO60iu09gYO1lgGqHDmr2Em7NxMwARMwARMwARMwgcERCPC0FM5p8PLBjfq/kV4JvDHHz3ZRob8tR920vzX/N0p3bxoZ42HH7poOt3aAL2stG/Cj4Uri0U3ABEzABEzABEzABEaSQID7487DpkOY4G8yinoaHrWo1yk9zifJyFRlP5B5pidfB63lFJg2z01fMAETMAETMAETMAETMIF+CQS4VQpnAtv021cP7b8C6JjQRD9nRIX+4Rx107726kEeNZmaMR627bGPoTQLMOVtMHdBeGooAnhQEzABEzABEzABEzCB0SYQ4M/ReHhPhWc6SJ+H02tsPIx9/f8nuHtthdfTopmACZiACZiACZiACdSRQAN+K+MhQJUTog3SeDg1Yzy8vU5rGuBcreX8z+w8/LROsltWEzABEzABEzABEzCBGhBI4Jy483BghcUdpPFwSsZ42KnCTOYRLcDlWsvl4HpgJrDIPJV8wQRMwARMwARMwARMwAR6JZDASXHnoVcH416H7qbdII0HcUidtqt8lGsefgH+q7XcAI4DHgNqladingn5ggmYgAmYgAmYgAmYQLUIBPh0NB4uqZZkz5JmkMbDyRnj4f3PkqLCH6bCsnEd524NbwBmAxdVWGSLZgImYAImYAImYAImUDcCDXhLVDrvq7DsgzQeQsZ4+GCFmTxLtOnwhriOj86F5wD/Bp4GVn1WRX8wARMwARMwARMwARMwgV4JTIWV0ifW0+D5vfZTcrtBGg9nZ4yHA0qeV2Hdy+E9ruNVsVNFjboROKSwQdyRCZiACZiACZiACZiACQR4SIrn9GeyPVcRyCCNh5szxsNRVYTRSqYAx0XjQXkqVHYHbgKUlXu+eM0vJmACJmACJmACJmACJtAfgQAXS/FswJf666m01oMyHt6WMRzkNK2oRRq78iXAVdF42DcKu3L0e7gL2LryE7CAJmACJmACJmACJmAC9SAQ4CtR8ayqg22ZxsPqwPeAK4E5TcaDDIgHgZ8AlU26Ng7LBJitNUzgFZlvnY4t/Qj4Yeaa35qACZiACZiACZiACZhA7wQCbByNhyenweK991RaywWAt/JMFKGiB1kK2BZ4C7AlsHkcZ1NAP28EtgJUr5IlwLvj+t3RJKDCzuoY0xPAsk33/NEETMAETMAETMAETMAEuidwEMwX4L6ogEqRdqkRgQacrLVrwA+axFaeimuBi4FPN93zRxMwARMwARMwARMwARPojUACP4wK6LG99eBWwyIQ4Na4drs0yaDoWcr38Cngz033/NEETMAETMAETMAETMAEeiPQgA/GnYdbY56A3jpyq4ESCLB+XLdZ47B8i8Hl9L0b8DCwYYv7vmQCJmACJmACJmACJmAC3REYh6UCPB6fYOv8v0sNCCRwQjQeft5G3O9Eh3Blzj6xTR1fNgETMAETMAETMAETMIHuCASYJkVUR5i6a+nawyAwDosGeDAaDzu2keEdwA3AJsADwCJt6vmyCZiACZiACZiACZiACeQn0IDNoyL6ZAOWy9/SNYdBIMBucb3+OwUWbCPD0tHvYSXgL8D729TzZRMwARMwARMwARMwARPojkCAm6SQNmC/7lq69qAJNOC30Xj4xgRj/xHYlWfW9IIJ6vq2CZiACZiACZiACZiACeQj0IDPR4X01g5Ps/N15lqlEcjk5pg7A9aZYCAZF6fxjEP1k8CqE9T3bRMwARMwARMwARMwAROYmECApTPn6D8+cQvXGAaBAOfFHaKzcoyv3B23xnpnAIfkaOMqJmACJmACJmACJmACJjAxgQZ8NSqmt59uB9uJgQ24RgNeH3eH5kyHV+YY/rnA03HHYTvgNmC+HO1cxQRMwARMwARMwARMwAQ6E0hgyTTjdAL7dK7tu4MmEOCiaNz9qIuxLwf2BOYH7gC27qKtq5qACZiACZiACZiACZhAewIBPhefbv9XxkT7mr4zSAIBto7rMjuBdbsY++tAEusfDox30dZVTcAETMAETMAETMAETKA9gWmweIA7pagmcFL7mr4zKAJTYLEA/4jGw9Qux30TcGdsszrwBLBsl324ugmYgAmYgAmYgAmYgAm0JtCAnaKiOifAZq1r+eqgCAQ4Jq7HfdPg+V2Ou2g0GNaO7S4GPtNlH65uAiZgAiZgAiZgAiZgAu0JBDgzKqw32nm6Paey7ySwUYBZWosE9uhxvIuANIKW+vhzj/24mQmYgAmYgAmYgAmYgAnMS2AMXhjgoai0HjFvDV8pm4DybQS4Nhpx5/cx3leB1Ml6MeAh4NV99OemJmACJmACJmACJmACJvBsAgl8LCqusxqw5bPv+lPZBAJ8K/J/LMBL+xjv9cA9wHNiHycDJ/bRn5uagAmYgAmYgAmYgAmYwLMJzIXnBPhlVGDvCfCSZ9fwp7IIJPC+yH1u+P9HjnodbkHgMWC92MEmwAOA/CFcTMAETMAETMAETMAETKAYAjHzdBrp54/jVjiLAduhlwDrB3g8Gg+ndajaza3zeHbujr8A7++mA9c1ARMwARMwARMwARMwgQkJJPCKAI9KmU1g+oQNXKFnAlNh2QC3RsPh9+fCwj139uyGnwPOzlzaD/hN5rPfmoAJmIAJmIAJmIAJmEAxBBqwc3qMpgFywHUpmEDMsXFJ5KwkfSsXOMTGwIMx07S6XR54Eli1wDHclQmYgAmYgAmYgAmYgAk8QyDAoakBoUzU5lIcAR0HC3BB5Pt4A+TkXGSZP0ZZ2ijT6RnAoZnPfmsCJmACJmACJmACJmACxREI8O3UgEiefYa+uEEmWU86mhTgvMj1yQa8tSQEOrZ0YKbv7YDbgPky1/zWBEzABEzABEzABEzABIohECMwnZIxID5ZTM+Ts5dxWCiBcyLPpxvwjhJJ7Av8MtO/diPuoDxjJTOU35qACZiACZiACZiACUxKAgfBfAGS1IAIcMikBNHnpGMkq4sjx9kN2KXPLidq/krgUUChW9NyODCefvCrCZiACZiACZiACZiACRROYBzmb8APUgNCUZj0FL3wgUa0QyV9C/D3yO/JMJiwqUoSdy/wugzW1YEngGUz1/zWBEzABEzABEzABEzABIon0IAvBZgTleCL9DS9+FFGq8cx2CTAfyOz+wJsNsAZ/hj4StN4FwOfabrmjyZgAiZgAiZgAiZgAiZQPIEE3hNgZlSGb5gOGxQ/ymj02IC9MgngbgywxoBn9gngwqYx9wD+3HTNH03ABEzABEzABEzABEygHAINeG2Au6MB8VQCX5BvRDmj1a/XcVi+AWdFPnMDXDwOywxhJmvHY0qLZMZeLIZxfXXmmt+aQEpAv8cKHbxEesGvJmACJmACJmACJtA3gTF4YYBfZRTkS8Zglb47rnkHY7BdgP9ELrMDHDlk/5A7gS2bsJ4MfK/pmj9Wm8AmwAXAecA5wFnAuTFz+GXAn4C/ApcC/wS07lcCOrp2MPCCnNM7H5gbDcw1c7ZxNRMwARMwARMwAROYmIBCuSr/Q4AnorL8UAM+IQfriVuPVo0GLBfgf2FtA/xzwP4N7YAG4LCmm1JElYF60abr/lhtAtotmh6Veyn46c8JwKbAc6P4cpZ/SfR3eSjWk6P8ScDiHaaoXamnM/1+qUNd3zIBEzABEzABEzCB3ghMg5cH+HO6C9GA6xJ4U2+91avVFFgwwL4BHkjnH2BqAktWZCZ7Anoy3VyuB3ZtvujPlSewQDT8UsNBrzt0kHpF4N8Zg0DJAzsdMTwl1r0PWLdDv75lAiZgAiZgAiZgAr0TiJmTvxzg0YwS/dMZsFrvvVa7ZYBtMyFY5dtwUwO2r5jUL41Pk5vPsO8Xj7xUTFyLk4PATzLGgIyHibKUy4dhdqbNFycYQ9+ZrJ/MBNV92wRMwARMwARMwAR6JBB9IaZmQrrKoXr6dFDSstoXOYY3YKcAV2SMpAcT2H/Ivg2d2OoM/DZNFZYHngSkKLrUi8DnM4aAjIctcogvf4h0t+LyHPVdxQRMwARMwARMwAQGRyCBjQJcnlGw9WT+VwlsNTgpihtpHBaVP0eAmzNzmp3ASYquVNxIpfR0GnB0i57PAA5tcd2Xqk1AIXhTQ0Cv8neYqCizeNpmZlPm8Yna+r4JmIAJmIAJmIAJDIZAA94a4NcZhVtGxLV6Uj8GLxqMFL2PoiRvDTg2wD2ZOcyU0TAD6hKNZjfgDy0obBfPw3c6A9+imS8NmYDWMzUE9LphDnmmZNpox0m+Ey4mYAImYAImYAImUE0CY/CqAEmApzNK+JwELmvA3tPzh5IsfYKStQFHBbg1I6uMHhkQB9Vgp6GZ0UrxzPvzmm4oKtYdOc7MNzXzxyETeGfGEJDx8PIc8lyVaeMkgTmAuYoJmIAJmIAJmEAFCGi3IYAcq//SpJgrJ8IlCRyhXAmnQ7OiW5r002DVALs14OQAygQtQyH9mRXgvAAf0NGl0oQov+MbgLe3GOZw4EctrvtSdQm8JWMIyHhYawJRF4r+LeluxYcnqGK6Ur0AACAASURBVO/bJmACJmACJmACJlA9Ag1YrwGHB7glo6ynSvuceLzpBPkayFciwEv7ySExBRZL4BUJvDOBAwOMBbijzdiXJvDJafD86pHrSSLF+P92i5arxyzUy7W450vVJKDoSakhoNd1JhDzuEx9JYFTHojmotwfBwLKGTEjJqCb1lypxWf5+3waOD6TuE7t9gf03cpTFo5jS7argYsB+em8LjbeIE8nrmMCJmACJmACJjCJCATYMMABAc4OcH8LhT41Kp7S7kADfhvg3AR+GOD7AY4LcKh2LgIc34AfBDgjZsFWZCQZCTJI0n6aX+UIfZp2GBJYeQTR7wxc22ZeUtb2aXPPl6tHQBnDs8ZDu2NLOpZ2SKbutzo4SssIOADQkaa0b+UCaVdkgHwzGp73AB/nmQzzL4sGiPqQb8V723UQrysr/c3AT4GNYw4K9b0+oKhQylGhhIYuJmACJmACJmACJtCagDJXa1ciwKfkmBzgNw24fQLlv9kYaPdZxsffo5FyTAN2mQryCRj1IuVQsf5bRYbavYNhMepc6ji/bTMKvpT0N2QmsQygJ/VHRH+WR4GT47VMtbZvXwjMif23MzbVWIZIamQc3KI3ZTbXffWV7iA0V5PT9u8ARX/SuM1FRxdvj/1UJelis4z+bAImYAImYAImUFUCOnakfBEJvKsBH1XEJjkwN+Cb0chI4o7D8QGOlG9FAvsE2DOBbZSwrp9jT1Xl0oVc1wHagWguiwEPARs13/DnShJodph+HFAujwdiQsBUqdfrOdEhXrsQeYuc6NW2nWO1+tJugOo8RetgB8o9kcrRzsciPX71+w6C7RH7qXxktg5z8C0TMAETMAETMAETqCUB+Tx8r43kCuXZ7l6bJr48JALvzijmUtBlTMgpWkVhd3Xs7rWAsoinhsBd8VhSHiNCx4jUr/wP2pVrYh35R7QqCmOcGg+tdibURr4SqjMLWKNVJ/GYlY4uTeTX0aa5L5uACZiACZiACZiACfRKQNGWFHWpVZHDrJ4m1zmiVKt5jeI1+RGkirleOx27kzPyVzP1r2Di/CTaoVK/nY4trQ0o03W7gAIfzIwpw7RV2SlT5x/Ajm2cubcGFm/Vga+ZgAmYgAmYgAmYgAmUR0BnyOX30E7ZlIPsruUN754LIvD+jNItJV/HziYq2iFIDQ4dcerkQ5AaD3+dqNM291cErsyMp0hfrYoMDx17SuXSq76Du8QdlFZtfM0ETMAETMAETMAETGCABJRpup2BoGMuFw5QFg/VGwE5uGcV7gVzdLNUkz/EDzq0kdGg/m/sUKfVLR0tUgSms4B3ZWT8bqvK8Zp2H3RsKTsfvf977KNVWNkO3fmWCZiACZiACZiACZhAkQSOjjH0W/WpSEwKr/nSVjd9rTIEPtSkbOcV7G+Zdopw1M7o0NE2KfC35OhYux4fAC4DHov5HaTwK3xsahAcO0E/isb060z9tJ1eZey+coL2vm0CJmACJmACJmACJlASgW1iZJ523Z8BHNbupq9XgkDqaCzlWsd+8hZlEs8q5q9q0zB1mL61zf308qGZqEtnAi9ObwCrZcaSwZqnbAr8MtMulVXhWl+QpwPXMQETMAETMAETMAETKJbAEvH4yqptut0uJuZS1B6XahL4UkbB1tP+vOX0TDsp5hu2aSijQfc7GQ/aTUiV+y+36EehVdP7h7e43+nS5sCfMu3Vz0GdGvieCZiACZiACZiACZhAeQR0xGTPNt0rlKfCe761zX1fHj6BozKKdTfZl+XPkir0yg3R7tjSbbFeO+NB+UDSfs5ug0P+D2mddjsPp7Rpq8uKEjU908f5Her6lgmYgAmYgAmYgAmYQIkEdCxJGYDbFT0p1hEXl2oSODGjVOfdeVB0pUcy7XQ8qF1Jc0Po+FKrkg39qiRurcpWmbGOa1UB+C+gMKztinJXyHFaRshP2lXydRMwARMwARMwARMwgXIJbAnc2WGI1YEngOU61PGt4RHQ0/70qb5e80Qk2jfTRtnE5ZPQrvwn1m2XE0RZq9PxP96mE4VnTetMbVNHOxyXThCWNTWUvtKmD182ARMwARMwARMwARMomcAi0ThQoq925WJgn3Y3fX1oBBTdSLsNqWKuV/mxdCobNLV5X4fK+m4oF4j6va+NYaJM5en4F7Xoa2cgdbpWPUVMalVuiv18rtXNeO1nwD2Acke4mIAJmIAJmIAJmIAJDImAzr9/osPYyiXQKcNwh6a+VRKBBZqyRacK/EfaPL1X6F2FUX0gKumPAp0MB4n9loxhoP5bOVWvCyjUq+7L0Dg+hvdVSNVDAGWxXhmYE+vodeMWTP4S7yti1Cdb3NeRJvlmbN/ini+ZgAmYgAmYgAmYgAkMkICOgXTya9ATbh1vkXOsy3AJKDP4NCB1ZE6Nhuyr/Bn+AfwOuCQ+rdf9p+M1RUTqdAztzcA1cUfq3hhx635ABoeOKb2hCYF8GpRELiuDdgjkHL1orKtdg/S+EsH9EciGh1XyuJcBOwI6inUeoEhSHwV01ElGyCuaxvVHEzABEzABEzABEzCBIRBQYi4pe53Oy08BvjcE2TzkvAS0i7ASsAKwLKCM0TqupGNG2pHQOi4OPB94CSC/FdWV03Geoj7001zUbzpWq3urAAqtqiNwrdpLZiUdXLrN7ki2z2ViXzJMJLuLCZiACZiACZiACZhARQgoTKeeKq/XQZ5NYhKw9Elyh6q+ZQImYAImYAImYAImYAImMMoEFK5zIqfo64FdRxmC52YCJmACJmACJmACJmACJjAxgQPjWfNONfcD5FztYgImYAImYAImYAImYAImMIkJyBlaGYqVVbpd0Vn7JyfIC9Cura+bgAmYgAmYgAmYgAmYgAmMCAEZDTIeJoqodAagrNQuJmACJmACJmACJmACJmACk5jAWUCnJF1Cs10M3TnfJObkqZuACZiACZiACZiACZjApCcgh2k5Tncq2qG4A9imUyXfMwETMAETMAETMAETMAETGG0CCtWqkK0K3dqpHD5BUrlObX3PBEzABEzABEzABEzABExgBAgoCZiSxb1+grko6dgTE2QpnqAL3zYBEzABEzABEzABEzABE6g7gR8BX8kxiYtz5IXI0Y2rmIAJmIAJmIAJmIAJmIAJ1JXAx3PmctgduK6uk7TcJmACJmACJmACJmACJmAC/RNYKx5JWmSCrhYDHsoR2nWCbnzbBEzABEzABEzABEzABEygzgQUTWnLHBOYApyUo56rmIAJmIAJmIAJmIAJmIAJjCiBJGciuE3i7sOiI8rB0zIBEzABEzABEzABEzABE5iAwIeAyyeok96+Htgt/eBXEzABEzABEzABEzABEzCByUVgVeBpYIkc094vp4N1jq5cxQRMwARMwARMwARMwARMoI4Ebs2ZRXp54ElgtTpO0jKbgAmYgAmYgAmYgAmYgAn0T+BU4Oic3ZyR00ciZ3euZgImYAImYAImYAImYAImUCcCuwJ/yCnwtsDtwPw567uaCZiACZiACZiACZiACZjACBF4ITAbeF6OOcloUHjXbXLUdRUTMAETMAETMAETMAETMIERJPB34O0553U48OOcdV1tchFYEFgaeBGwBrASsKR3qibXl8CzNQETMAETMAETGH0C3wO+nXOaq0fH6eVy1ne10SCwELA2sD2wL3Ai8CvgZuDe+J2YC7T7eRy4G/gLcBZwDPBx4C3AKsB8o4HJszABEzABEzABEzCB0SfwbuC6LqZ5cVQgu2jiqjUjsHhU7A8FtN5PdDAM2hkM3Vx/ADgHOBBQUsIFasbL4pqACZiACZiACQyLwDgsFWDDBN6TwIEJHBbguADfDzAjgXMCXBDgZwHGApzSgGMDHNqAzybwrgDrj+fLXzCsaVZpXIVhld+DXvOU3bs0NvL06TrDJ7AOcDBwZcz/0az86zui0L7nAccDnwbeBmwGbAisBawcjy4tBiwLvARYF9gIeCMgQ/WLwOnApcB/2hgljwLnA58CVhg+GktgAiZgAiZgAiZQCQIBXhJgNxkAAS4PcHeAuUX9JHBXgEsSOCHAe8dADsIu8xK4Fth53sstr0gxfAjYuOVdX6wTgZdGZV7r32wsaDfgZ3E34DXAwiVNTH4RWwHpLsfMJllktFwAfCQaJCWJ4W5NwARMwARMwAQqR2AqrJTAhxOYHuBfHYyEJwP8LcDPAyQJnNSAbwb4WgL7N+ATAQ4IcFCAYwJMCRAS+EWAGwM83aHvmxpwagJ7NPxUM/2OHAeclH7I8Tqly/o5unSVARFQ1CwZilc0Kelz4m7AZ4D1huiHIP+K18VdEDnzZ40aZUT/KfD6AbHyMCZgAiZgAiZgAoMmIAU9gU824LcB5rRQ6qXsfz+BjwV4s3YjDurTgfJCWGAGrBZg6wCfCjAtwK0txp4V4NcN2Gsclhk0mwqNtwNwQxfy6Fy6dh+0C+FSDwJaKx0DuqVJIf89sH+MklTFmawPHBmPTGUNicuBdwzRyKkiK8tkAiZgAiZgAvUkMAUWbMCuUswDSEHPHkW6PoHvyDdh0E/+x+BFCbxPOxkBbmqS66noT7Fjv8ZLDVdNeR5mxfCaecW/Htgtb2XXGxoBHQs6BLgvYzQ8AhwLrDY0qXobWDsSChWso0ypISGjd0+HhO0NqFuZgAmYgAmYwFAJJLBkPE707ybF/JYAX58GLx+qgE2Dj8Gr43GoZnl1tOkTUybXk/WrujQG9gMuakLqj9UhoPCn8hP4b0bRvhP4fM6kgNWZybySyOg5AVAI2NSIkN/Gm+at6ismYAImYAImYAKVI6An+lEJfyhjNDwc4LsJyNmy0mUuPCfAZtF34rHMHO5TtKdxWLHSEyhGuKOA07roStGZnqzh0+supljbqlsA12QU69vj03n5E4xSUb4RRYhSdKbUiDgbWHOUJum5mIAJmIAJmMDIEFBY1Wg0yME5PZp0m5yatQtRx4lOhWUb8NWmyE+PBzhkGij+/aiWtwL/7HJyZwBf77KNq5dHQOFRxzOKtJ7MS7kedd8UZbNOADl9y4h4Ks7b+SLK+665ZxMwARMwARPIT2Ac5o8OztnQqlc3YBc5K+fvqbo1T4dFGvDRADekhlEDbldoWe1UVFfyniWTYSSlS+E785ZtAT3VVgQfl+ESULhTHUuS8iwlOlTYCbosUtrllAN4uguhnBVrlDWY+zUBEzABEzABE8hBQMd7GnBdqlAHuFNhT0dUoUbO0wovG+C/mTlfKX+JHLjqVkWJu+R8mrfIaLgDkBHhMhwCiwAKtZs+db8N0LGlyVpk2CuqVOoP8Rjw0ckKw/M2ARMwARMwgaERGIeFGnBUgNlRiZ4Z/QGWGJpQAxxYx7ASODpAekRLuSS+ol2YAYpR9lBK1KUn1t0UHVtSBByXwRNYG1DUq/RJ+w9jhufBS1K9EZXZ+uoMG/lC1PIoZfXQWiITMAETMAETmIBAA17WgGvSJ+8NOEv5GCZoNpK3Y/6Ii1IWCVwWujvqU2UuemKtoy/dlNWj47QcqF0GR2BLQFmgZTg8DOw+uKFrM5IcxL+R2ZWRobVKbaS3oCZgAiZgAiZQRwIJ7BNgZlSWH1VCtTrOo0iZ41GmAzO7EIos9YEixxhSXzoCMxPQE+1uikK27ttNA9fti8CHon+KDAdlYZYB59KewNbAg9HQUujaykeAaz8V3zEBEzABEzCBihLQMaWYmTmNovT7YOfDZ61WgPUDXJ/uQgQ4fgSOMf0G+MSzJjrxBz311lNdl3IJ6Dz/EZmjOFqrpcsdcmR61zGmWyM7GcjvHZmZeSImYAImYAImMGwC47BMgItTpbgBh49KFKWi2SoqUwInpKyUpXoc6uwH8mXgR11yUijQh4CNu2zn6t0RUGK01L/hVGDB7ppP+torAL+LDOVg7qNek/4rYQAmYAImYAJ9E9DuQoAbozL8RALv67vTSdBBgE8FmBW5/WkMXljTaW8K3EP34WinAPpxKYfAsRnD4QvlDDEpel0UODOynAW8Z1LM2pM0ARMwARMwgTIIJLBRgHujAnxPA15fxjij2mcC2wSQ/4OOev17OqxVw7nqabYy9r6yS9k3ibsPo56QrEsshVRX9u90x+FzhfQ4uTvRd/ynkenTwDsmNw7P3gRMwARMwAR6IBDP798fFd8bptsJsweK/5fm9hUB/hU53lFTjr8A9ukBgPwefBSkB3AdmhySMRy+1qGeb3VHQJGYfh7ZPulcJd3Bc20TMAETMIFJTkChWAPcExXev4yDw2728Z1IYOUAt0Set43VLzzkZwHFxe+27Aco8pJLMQQUwSvdcTiymC7dS4bAwsCvImPttr0ic89vTcAETMAETMAEWhGYAWsG+E+64zAOK7aq52vdEZgGq+roUuR66xi8qLsehlpb2bMV2rLbBHgyOvUU16FD+1++DWPYXBkPJ/bfnXtoQ0A+EFdFA+JmR69qQ8mXTcAETMAETEAEGrBCRsG9eSqsZDLFEZDzeQJ3RQPixtPhecX1XmpP88UEZBv1MMoZgLJOu/ROYDngX1Gh/S2wQO9duWUOAjLslf9BhpqO7On772ICJmACJmACJpAlMAUWDHBJerRmKrw4e9/viyGQwLqZI2E/n9t9FKNiBOm+FzmU9uKcuy1wRw+7Ft1LOJottNvz66jIiqPCi7qUT2BzQM7TMiAOL384j2ACJmACJmACNSOQyU0wcwx0TMWlJAIN2DzA0zLUEji4pGGK7vYzwHk9dCrl93Y7oPZA7pkmh0UFVse/nAm5Z4w9Ndw7spcB8baeenAjEzABEzABExhFAgl8KO44SJndYxTnWLU5JbBPZD6nAdtXTb4W8sh5VE6kvSQi07ElHV9y6Y7A+pmn35/qrqlrF0QgiQaEDOAlC+rT3ZiACZiACZhAfQkE2DDAE/Ep+HfqO5P6SR4gRAPiwRmwWsVn8BzgbnrL9SGHaT05d9Su/IusHZs/RsVVEavE32XwBJYB/hPXQRm9XUzABEzABExg8hKQn0MDrosK7EUX2hFzoF+GKbBYgD+n/Gvg/zAOfKVHSFKAFbrVJR+BA6PC+rijVeUDVmKtneNazAFeV+I47toETMAETMAEqk0gwFei4vpIzUKHVhtsF9IloCRyT2kdEvhYF02HUVXyXdjjwEoWp6RxLhMTWCMTlvWAiau7xgAInBUNiL8CSijnYgImYAImYAKTi8AMWCc9rtQAOQa6DIlAgEOjEfdwxY24NYEngEV6QLUY8BCwSQ9tJ1sT+YfISff3jlJVmaVX2Gp9f7Uu/ntZmWWxICZgAiZgAgMhoOMxAS6NCusVBzmO+UC4txvkXFg4gb/G9fh5u3oVua5woVv2KMsUQD8u7Qm8EtDxGCmpm7av5jtDIPDFuC53AUom52ICJmACJmACk4NAgD2jovrUNHj55Jh1tWc5BpsGmBPXZccKSzsdUPjQXsrG8emtdiFcWhNQPg0ZDue2vu2rQySwRAwaoPXxcbIhLoSHNgETMAETGCCBcVgowL+kpDbgqAEO7aEmINCAk6PxcH2Fd4M+CFw+wVQ63Zbfg/wfXOYlsEE0HKScbjjvbV+pAIH94xrdA8iYcDEBEzABEzCB0SaQwCejgvrQOCgMoUtFCMjfIfVDSeA9FRGrWYxVYu6BXhUnRVy6uLlTf/4/Aj+LiumZ5lFZAjqudGdcpy9UVkoLZgImYAImYAJFEDgdFglwRzQeDiqiT/dRLIEAx2t95ANR4d2HW4Btepy5cj0o54NyP7j8fwLK85H6Oig5nEt1CewTjYd/YX+x6q6SJTMBEzABE+ifQAP2i4bD/YmzpfYPtIQexuCFAWbGdXp/CUMU0eWpwDf66EjRhA7vo/0oNlUWbh1X+t0oTm7E5rR0JpTuW0dsbp6OCZiACZiACTxDQE+xA/w7PtX2dnuFvxgBjovGQ1XzIsio+UMfCLcFFLVJWZRdnuEgHjIe9jKQWhBI4nrJEHYxARMwARMwgdEjEGDbqJDqqbaenLlUlMAYrJJGXkrgNRUU84XAbHr/HslouB3YroJzG4ZIb4uK6KPAc4chgMfsmsAWcc2eAlbourUbmIAJmIAJmEDVCQQ4MxoPemLmUnECAc6L63VKRUX9O/COPmTTMR0/tX0G4E+iIqrjYC71IPAc4Oa4bp+th8iW0gRMwARMwARyEhiHFQM8LWV0OrwxZzNXGyKBBuwUjYeHp8HiQxSl3dAnAt9udzPHdTlMy3FaDtSTuSwMPBaV0DdMZhA1nPtX4rpdUkPZLbIJmIAJmIAJtCfQgM9HRfTG9rV8p0oEpsCCAf6jdWuAcitUrbwLuK5PoS4CFLp1Mpc3RQX0IWCByQyihnNXLg75qTzt42Y1XD2LbAImYAIm0J5AA66JxsPn2tfynaoRCHBkXLfzqiYbsFz0e3h+H7IpWdxf+mg/Ck2PjgqoMku71IuAji4pWZwMiB3qJbqlNQETMAETMIE2BBqwQup8OwPWbFPNlytIYAw2icbDTOXoqKCIfwZ27kOuxQA9cd+kjz7q3lQMpXx+su4TmaTyj8X1++4knb+nbQImYAImMGoEArw/KqC3jtrcRn0+4zB/gAe0fglsVcH5Hguc1KdcU4CT++yjrs1fEBVPGQ91Mez1PVSCyVcMAPqSwN7ADwcwVq9DfCCuoQIIuJiACZiACZhA/Qk04AfReJCSVtWiJ8+HAN8CjuvwcwywPaDjAmnRsZk9ASmyzW2/CSikYm1LgDPi+mnuVSs6qnFDn0JtDDwMaBdishX5jchw+HeNJq7fKclcRgLDlwIKW7svcDrwSBxLr1UtK0UZxURH+VxMwARMwARMoN4EGnC7lE9F76nwTPRPV8q/kqLpn3CrH0XmkXGwdtM8pHAo/GyqaKjtHOAX0Rip9ZGYBD4W169f5+QmbIV8XAqYBUiB6qdo3ffop4Oatv1q/K6fUyP5yzIe1gd+Fn1g5ICc/RtQZeNBS3dvlHezGq2jRTUBEzABEzCBeQk0YO341HrW6fC8eWtU8sorgVualAcpEodOIK12JFTvcUARbEaiTIfV4xrKAKzik83fA7v1CVtPmi/us486Nk/Py3+jRsKXZTxkEayXUcj1O62dqSqXS+Pfno9WWUjLZgImYAImYAITEmjAzlHxrFtEGynJ/2oyIPR0T0+62xUpsFI0Ru4feIB74zpW8cnmUcBp7RYl53XletDO0ho5649KtdRZWsfu6lIGYTyIxeGZ3//7Kw7n+1HWfvKeVHyKFs8ETMAETGBSEAhwUFQ6f1zDCb8mxk+XQZD+6NhSu3ItcGa7m3W+HuASraOOMFVwHlsD/yxALn1HpTBOljIfMDN+tzet0aQHZTwoe3n6e393xfkcEGX9VcXltHgmYAImYAIm0JlAAj+MSudhnWtW9m76TzlVIuTL0CpDtiKe3AEsW9mZ9CFYgFOiEVjFJ5vKfv0UIN+Tfsq2cQ3n76eTGrVdNaMcL10juQdlPGyU4XNnxfnIyVt/o7Rb6mICJmACJmAC9SXQgOukdDZg15rOQlGV5EyaGg961VNuhXBMy4uBB4At0wuj9tqA/aLxcH5F56Yz3/0evZHRcDuwXUXnWLRYG8Tv9RNFd1xyf4MyHl6W+b2/reQ59dt9auhU3bG733m6vQmYgAmYwCgTiDkCnohK54Y1nqt2ExTKMmtAKIyjioyL3wBHxs8j+ZLANtEIlHJdxaIwu6EAwb4O/KSAfurQxebxO131IznNLAdlPKyT+Z1XAIUql7Uysuo4mosJmIAJmIAJ1I/AOCwfDYe5U+t/nOf1Lfwf3g7sA1wFLFi/FcovsTKDp2s5pZpz1VGyIo6WrB4dp5W7Y9RLetTlHzWb6KCMh6xCfmPFGa2YMR7qEtWu4kgtngmYgAmYwMAJZEN8XggLDFyA4gf8QuYftHYh7ok/Ix+hpwErpMbDOCxTPNq+e1w4Ov825+DopeOLgP17aVizNrvE7/PVNZN7UMaDDMl0t/GvFWe0aEZWHaN0MQETMAETMIH6EZgOG0SF87H6Sd9SYh1R+mXmn7QUi98BI39MYAoslhoPAV7Sks7wL14AfKIAMXaPicIK6KrSXXwkfpd/WwEpXwHIaMvzkx4hlEKfp77q9JKfRA74qfGgSGpVLwoaIHnF0sUETMAETMAE6kcgwBZSOBO4q37St5VY+QAUVSlVKvT6pba1R+hGgFlaz2nw8opOS+tQREjgxYCHAIXqHeWyd/weV8EJXscCs79TRb/vJQP5KhmZ/lSDL0Ka4f7VNZDVIpqACZiACZjAvAQCvD0+rf77vHdre2Uh4PqMUiElZxbwutrOKKfgAR7QejbgtTmbDLqachUokZ92iPotU4CT++2k4u0/GL/HV1RATh270ZGzPD9KCKjfu8/mrK8+ezk2qeM/qRHzhwow6iSCdj8VRlryylfDxQRMwARMwATqR0DhWaPxIIfiUSmKxnMx8MWMYqF/2ArlWKdY+V2vR4B/R+PhLV03HkwDKYh6+vrKAobbGHgYUA6JUS3vit9hGcN1KoPyeVg58ztedb8QZb5PDZ0X1GkxLasJmIAJmIAJ/I9AgHdHZfO6/12s9xsdB5Byumb0c7gw8w9b/7hHMrt0umQB7o7G4GbptQq+ngvsW5BcUqr3KKivKnajzNyp4VtF+drJNCjj4YWZ3++q/w17UUbWUTZ4230nfN0ETMAETGAUCCSwVVQ2RyHraXpcSTsOadGTyfsy/7SliH0qvdnHq5KVKQyszqJXxvkxwEyt5xi8qo+5ld1UR1nOLmgQGSFVcCYuaDrzdKNjXvrOKsFhncqgjIcVMr/bVT96KT8kraWOULqYgAmYgAmYQD0JJPCaaDw8WM8ZPEtqHVe6psXZ6R0zCob+eStb7/rPapnvg47a6Cz3ZcD9mT4rkbVauR3iWs5VCN58UxpKLSUj1PdNBli/Rc7xTwKjGopXhmmqcBbhJ9Iv77ztB2U8aP3FAR8FuwAAIABJREFURz835xVuSPXkcyU59bdDOUo+NyQ5PKwJmIAJmIAJ9E4ggXWjwjl7bjFOrL0L019LHVeSUdAuiskpGSUjVTS6TdSk8/pSyvVPXxl/U6WlEsaDcjukxoNyPvSHs9TWchzVk/SNChpF0ZuOKKivqnWTVY5XrZpwHeQZlPGQ9Xn4Zwd5qnDr/fFvxl+An8f3u1ZBMMtgAiZgAiZgArkJTIWVUoXzVHhu7obVqignaD11PL2DWEsCaez5VOnXP/Ben+YelzEelDl56EW5HdK1VM6HoQvUWYCfFvjkdduYubqInYzOUg/nrqJT6Tu7zXCG72nUQRkP62R+D5UQssrl0CirjN1148MOHamssqFfZZ6WzQRMwARMYBgEsonFKn7UpR0eKYy/iiEQpUh0Ku/OKBqpAXFUpwYd7qVRcNSP4t8PvSSwUTQeHh26MBML8GngvImr5aqh78DtwNty1a5fJfl06Hu2X41EH5TxoMAA6e/y7IKOwpWF+UdR1kPiAGk0uCLynpQls/s1ARMwARMwgXkJpOE9k/opX8qinCpWN+XYRZBDtRTrVNlIX08AFpmXTMcritOetq9EToUAu0fjoQ5hd+U8qqzmC3aknP+m/F1+kr96rWqeFL9rOnpXlzIo40FJB9PfQ70qaVxVi6JBScb3RgF1DFKJ7XRNDzZcTMAETMAETKAeBAL8KiqdB9RAYiWFks+BohzJxyGrOARASbV0TjxbFgZ2B85pqp9tq3wBar9VtmGH96tl+lK+gaGXAEfGdZw2dGEmFkDHxf5b4K6NfFHkOC1H1FErn4nftUtqNLEyjQcZnAp4oL9XMzO/h/p9VqI4BUhQToUqFe2OpX+vsjlO9P6p+LuwbJUEtiwmYAImYAIm0JZAgG9HpfP7bStV58Yu0dnwIqDVj/wYmuP+S9E4tU39bB86/jQG5PknLufV1PhQ9KChlwacpXVM4AtRmJWATw5dsPYC/BD4avvbXd/RWu7fdavqN5BPjb5r2qnR7lkdyt7A7wDlqSiyyOg8EVDG7UtjMsjfxIcJOgZ3ASAja0bFWCmQg9ZQBm7zLqeOMemeHl64mIAJmIAJmED1CTTgo9F40D9jl3wEdGQqNR56Cfuab5QuagW4Ka6j8k+opKEh5V9QxfJRQEn8iiraXVIkm1Er2jl7PH7fKuGcP2qABzCf9HhVq++7DML0SNP2A5DFQ5iACZiACZhAfwSmwxui0vngeDGx9/sTqB6ts9lih54kLoElA8zWOs54Jrt2SlEZmJWUqugnwGn//bwqC7iOcjQ/ie21T0WYegh4Ta8dVLjdL6LxIN8Ol/oRuDiuXzaBZXYWClus39M7gG5DSGf78XsTMAETMAETKJ/AOCyaZiZW0rjyRxyJEXQkKN15eNmwZzQddogG4H0HgfIopEW7DopCo7wKE0WjStsM8lVRkt5U4IBTgDo5Fued+j7x+/b7vA1crzIEFAJbfg36e9Ept8nRsY6OWLqYgAmYgAmYQLUJBPh1VD6/Vm1JKyPdCzPGw3rDlirAd7V+CciPIFuUA0NHXhQOUrkwlsnerMB7OXcfVqAccl6X8/viBfZZha6UF0DKpwxBralLfQjsENdOOR2yhn3zDLQDd0OsmzdwQ3Mf/mwCJmACJmACgyEQ4HNR+bxsMCPWfpQVM8bDq4Y9mwB/j8bfni1kmQoczzOGhc5cFxUetcVQXV9SdKzLu27VuYGOan2gc5Va3k2THDYHBKjlZCaR0EpeKcNvPMec5ackA1HZspfIUd9VTMAETMAETGA4BKbDBlH5nDVevTCHw4HSeVSFBE2PLXU6itC5lwLujsGL4trN1fsWXUoh0bElRZFSDggd7alKkeP50wUrSvvG/B9VmWNRcqTHWpTbxKUeBHRkKc0t846cIn87/m1R/hkXEzABEzABE6gmgbnwnAD3xN0HZU926UxA/gOp8TDUJHEN2Cuu2187iKyn8XpireNWcspU7oCqlH8A2xQojPJ8KCSmHLJHqWQTE+q9S/UJfCT+nbgLUFK4PEVH7m4B5gCb52ngOiZgAiZgAiYwFAINODU+wT57KALUa9BtM8bDUM8nB7hU69aAwzsglON0ejxIMecfAd7aof4gbym/yDcKHlA+HkcU3GcVulMOAxmt2oVwqT4BObhrvbr9Lm4ZjYebgEWrP01LaAImYAImMCkJNOC10XiYNfbME+pJySHnpJV8Ld152DVnm8KrJbBuXLO500FZltuV1HE6DSu7c4UiML0P+GM7wXu8LuPuTkYv9LB8OfS9+0/FfFd6XKaRbqZAClor7SAoI323RccL1f6Ybhu6vgmYgAmYgAkMjECA6+NTbCU1cpmXgDJLS/HWUZvUeFCElB0BnW8eaGnAsdF4UHbliYocp7+bqaTIWorAlCejdqZZ4W9fEGPcFxlFaH5AYWDfVri0w+1QR1qUy0Lfvd2GK4pHn4CAQq5qnZQBu5eyJHBbdKB2CO1eCLqNCZiACZhA+QQS2Ccqo7fID6L8EWs1gjL9HgIoUdfBwFcBJX2SoXUokGZ2HsikzoWFA9wX1yuPIpk6TqfHILS+Cu1ahQhMfwPyOpTm5at1OjNv5RrV03dNSqkMv7zn6Gs0vZEQdY0YCEDrpF2wXot8gdSH/Jn098fFBEzABEzABKpFYCosG+CJuPtQlTPx1YJUEWkS2CMaDsoMnhoEE0mXOk6n9dROEZhOTi8M6VWRZRRlpsiioyJynFZkrFEqykD8YFQq9xqliY3QXJK4PqmfUT9T+0Hsq5NPUz/9u60JmIAJmIAJ9EcgwNSolF7RX09uXRaBcZg/wI3RyPtmF+NkHafTZlWIwLQTcF0qUIGvOs51QIH9VaUrHTnTE+l/AQtVRSjL8X8ElNBPuRq0PkVkT9dxPkVrUkjjDczYBEzABEzABCpHQI63AZ6WYjoG21VOQAtEZtfh0XFQaNK8pdlxOm037AhM8ruQwlX0LoGOc3UKYZvOv26vSwH3RwV177oJP+LynhHXJY8fUl4UOtInY+QaO8rnReZ6JmACJmACAyUQ4Ptx9+GP9n0YKPoJB7sQFghwc1yfIydsMG+FZsfptMawIzBJMZIMRZbFooPxUHNxFDmhTF/yt5FCKQfqlTLX/XZ4BPSwRWuin9cXLMaM2K98rVxMwARMwARMoFoEArwkwJNRQVUkIZeKEAiwZ1yXh+Wj0oNYzY7T2S6GGYHpW8BJWWEKeq8+Tymoryp1IwdaOZpLUXVuluGvjKKtKTqS1uP0EsTRDuM90Y/n5SX07y5NwARMwARMoD8CCZwQldSbunDI7W9Qt+5IYByWCnCH1iWBwzpW7nyz2XE6rZ1GYNKRiwXTiwN63R64sYSxNgYeBhTmdNTKpjGPgBTWXUZtcjWbj8Igax3+CyxTkuzvjWMo+ZzCEbuYgAmYgAmYQHUINGCFNBRo0n2G1OpMZIQkCXBKNOjukCHRx9RaOU6n3Q0rApPi2s8CVk4FKfBVzthKsDaKJVVa9VR6uVGcYA3mJCMudZKWgl9m+Wk0IA4scxD3bQImYAImYAI9EWjAB6Oy+vR0eGVPnbhRIQQCbBFgTlyPfnNKKNzn40CacbpZxjQC0z7NN0r+fGVJyc/2BS4pWfZhdb9EjLqUHl9yfpbBroSCECjnhvifM4ChlVRRzvIzgbUGMJ6HMAETMAETMIHuCAS4ICqsVylEaHetXbsIAjo2FuAmrUPyTGK3Irpt5zid9p1GYFKiqkEVOYCXdV5cOR/WHNREBjzOFnHXRgqsHWoHB38+4BeZ40qDclzfI455KSAZXEzABEzABEygOgRmwGoBHo8GhCK8uAyYQALfifzvm1ZcOFMdtXiAzgnmFP1ICckUu34QZSvgnyUN9GOgl+hUJYlTeLfKZyHjQcdn+slqXLhgI9zhEZG5cjBsNuB5pkaLjiC6mIAJmIAJmEC1CDTgs1F5nd2At1RLutGWJoH3RfZzAyhvQZGlneN0dgxFYPoHvUV2yvaT571Cq2qH4KV5KndZRwr1nSPuaPrDqMzKKFSGbZfyCLw7spbBNoxcGy+KgQAeBVYtb5ru2QRMwARMwAR6IKBcDwF+FpXYe8dglR66cZMuCcjPJMBjkftpXTbPU72T43TaftARmOSbsFc6eIGvOnJ3O6CoTqNaFFFKzuFSaBXGteike6PKrdt5pUf6xFnH/4ZVPhrX+gLAvi7DWgWPawImYAIm0JpADBN6Q1Rk/+Twra05FXU1wNIB/hF5X3U6LFJU35l+JnKcTqumEZgGkS/hYCCkAxf8+nXgzIL7rFp3q2eyT19bYtjQqs17UPIocMR9UWm/inJ+L/PORQbDb6IsH8nbyPVMwARMwARMYGAEZsA6AR6OCm1w9uly0CuLdAK/iJzvmQovLmek/+t1IsfpdOhBRWDaPB4vSsct8lVHeZ4CViiy0wr2pSfj8lXRk/E/0F9Y3wpOb2girQPcHblqh6eXJI1FC68jfjq6pEzjOsrkYgImYAImYALVIpDAOzMhQ79XLenqL40iWgUYi4bDrAZsWfKs8jhOpyKkxzXKjMCkzMkKIytFrYyiBHhyLh718pp4Jl4GxBWAQrq69E5gjWjUiuffK2aAfiYaNOf2Pj23NAETMAETMIESCTRg76jczm3AsSUONam6PgjmCzA1sp1dgoN0O555HKfTtoOIwPRr4BPpgAW/yun8rwX3WdXu3hCfSkvh/SOgHAEu3ROQ0XxXVNCV00G7cFUqCteqsK1aZ4VxdTEBEzABEzCB6hEI8LnUgHAG6v7XJzqlpxmk5yTw4f57zd1DHsfpbGdlR2BSSGCFVi2jKKKTjni8tozOK9indq50rEWK5W3AehWUscoivRN4LPK7lXKPEPbDQQnjlDhOCeRW7KcjtzUBEzABEzCB0ggkcHDWgLAPRG+o5ePQgFNTlgE+1VtPPbfK6zidDlB2BCYp9veWGEHmJOD76WQmwesGwB1RAX4YeOskmHMRU9w/5s2Q4aWjX1WPXnVgXONRDwpQxNq6DxMwARMwgWERCPCNVOlNoHEu6My6S04CCSwZ4FcpwzC88/h5HafTmZUZgWmBeF5fkW3KKBsDjwAKbTpZysrANVG5VFIznZN3aU1A34tTIysZDjOGHFWptZTzXlU44t9Hud8z721fMQETMAETMIGKEGjA5zNO1Jc2YLmKiFZpMRRFqQHXRcPh6QEfVWpm043jdNo2jcC0b3qhwNefA2X0m4qoaDkfTD9Mklc5TYurFGL9KEux/SCevfgyLG/MMDqkxB2wZ49czKeXx0SLigrlv8PFMHUvJmACJmACZRBowE4BHo+K8M0K61rGOKPSZwIbJXBX5PVggDdXYG7dOE6n4pYVgUkRkc5OBynhVYaJEtJNtqKn018GtPsgA0LHw3Suf7IXcflqhotyOexUUyiah9Z2rKbyW2wTMAETMIHJQqBJIVZm5I9PlrnnnWeMqHRAgCej4XBrAuvmbV9yvW4dp1NxyojApHP6cmyWUldG0VPZJ4E1y+i8Bn1uBNyQecL+A2D5GshdhohyIpdPQ7ojc14FIyp1M+8FM0fU3t5NQ9c1ARMwARMwgYETGIMXBbgqKsZzA/y8MfpJuXJxFpsGXJhh85tp1XLC7NZxOjvvNAJTUUclFH5SkWN0jKSsoohOR5bVeQ361dn+KRmlWYnl5CS8UA1kL0JEfVeVq2ZWZKBoRXvX7JhSOw4yvrW7dCeg32sXEzABEzABE6guAUUPCnBogFlRUb67Ae+orsTlSxbg/QEeiDy063BARaNTdes4ncJLIzBdDOjJZxFFUWM+V0RHbfrYNsbvl4P2ZC7icFPGiND7HUYYiL6f+wAPZOas5IFV2QEsCv3X4/xOL6pD92MCJmACJmACpRIYg00D/CN90p7AOTMm2TGRBF4R4NcpgwDXT4eyoggVsZ69OE6n46YRmIoKg6qnwDpCUlbRkajbge3LGqBG/Wq3QbsO2n1Ij+/8FnjbiDyJ11Lo+6nkg0r0ls5R73es0Tp1I6oi3ykhoubq8LzdkHNdEzABEzCB4REYhyUCfD8TjempAMeMw1LDk6r8kcdh+QROyuy+zFI27tNhkfJH73uEXhyn00HTCEz7pRf6eH1ZTNBV1E5GK1H0dPanrW5M0mvye1AejPQojxRPKaB7Ut8wzJrTwcA9GaNB/jSfnQRHtF4Tc1UoQeBzJ+l32tM2ARMwAROoI4EEXhPgiswTeB1l2nsKKOPvyJSYt0HZtxVBST4f+vm1diBqNEk98b+8D3nTCEw6DtNv+S/w+n476dB+NeAp7JfTjEhHeE6LTuXpU/q7gENrcrxHPjNvBE6JmZfTOSi6lAyJyeQcfkw0muTf4WICJmACJmAC9SGgM/4JvC/AbRnF+j75R1TMcbhrqFNhpQSObjIabgpQx2gn/ThOp+zSCEzaPeinKEGXQk+WWXTeXU+hXeYlsCJwGKDQpakCrlflyVDI19XnbTLUK3rSflwmo3Yqs/w4dGRJR5cmW9GcNf85wBaTbfKerwmYgAmYwAgQGIdFG/ClAHdnjIiZDTi5Af0qmwMlNB02CDA1gI5jpTsNdzRgv/F6R63p1XE6y18RmG7pM1nVRwAp92WW3YC/lTnACPStHcKPxdwYUkJTpVyvVwPf4pmgCMsOeK4vAbR+2mH4Z5NcTwByulewBu1ETOayWTQe/sGI7fZO5kX13E3ABExg0hGQEZHAxwLcmFG85zbgmgA6+iPFoHIlwBoN+GoCf83KHeDaBPaoudGQ8u7HcTrto4gITGsAUgLLfGIsxVhn4DVnl4kJvBg4MBoNWSNC72VYyGfmRODDwOYFZbGWc/tLga0B5SNJAJ3jbx5fvhq/itnDR9qvauJlmqfG8ZGXdmZcTMAETMAETKC+BJQ4TaFcA1yccazWU/w5AS6Vb4R2JIYV2jQmdltf4VUD/KHJYJidwC8S2Kq+K9BW8n4cp9NOpfRfBfQTgenfwJvSDkt6lZNwPzKWJFblu107hj09A5B/SrMyn35+BPgToNwa4iwFVv4TCsWr40QfijkWvggcDnwXUOI6ZRnXrpAS+qV9Nb8qYpLCkaqP51ee2PAEXCLuzsy2oTy8RfDIJmACJmACBROYCi9O4MAAVzcp6TIm5B9xtu434LXauSh4+P/rThGiGrB5PFr1ywAPNcuSwO8CfGYcdCZ8VEu/jtMpl34jMOkIlaIilVmUjE4KrhKnufROQBm7FZlJyvzvWvhKNCv+3XzWrsYd8Rjbd4B3F7Sr0fts69fyLdEI+zv1iPxWP8KW2ARMwARMYHgEGrB2AgcH+GMm5GnqV5DuTPwr5lE4McC+02GHAJuNwaumw+pS7qfB4to9kFEwHV6gY0fRV2GzuONxQPS3UPbnO5oNhfhZPg1XRINCxycmQynCcTrltGFUznuJwPSBPqM/pTJM9Con4A9OVMn3uyawdMwU/j7gK8A3Y2brAJwFXABcBpwP/ASYFo89HR2PR72TZ6KVjVRktq4pFtdAOz8y2iZzdvXiaLonEzABEzCBahJQCNQEtkngiAQua3JQzhoURb2fGeAiGS8JvGnUQsp2scpFOE6nw/UagUln7J8GdOyizLIvcGmZA7hvE6gAAfmCKDmi/EMUVtnFBEzABEzABEafgJySp8NaDdhekY1iQrYLAtwS4N4AT7TZQUiNCxkH9wS4OcD5CZygY0gBttWOxYWwwOhTzDXDIhynswP1GoFJ59q3yXZUwvvl4tn6tUro212aQJUIKHO4dh+uBcpMwlilOVsWEzABEzABE+hMQAbA6fC8BFbWUSXlYlBm63FQ5BaX/AR0nGeP/NU71kwjMP22y+y+CsX5jY49F3NTDr1HFdOVezGBShNQxCoZEAdVWkoLZwImYAImYAImUDsCRTlOpxNPIzCdml7I8boL8Mcc9fqtot0NZVL2zlO/JN2+6gSUk+M/McP6elUX1vKZgAmYgAmYgAnUh0CRjtPprNMITPunFyZ4VVQrndGW822ZRbtSOg++Q5mDuG8TqAiBneLuwx/wjmxFlsRimIAJmIAJmMBoECjScTolkkZg2i69MMHrX2O24Amq9X1bYWF/2ncv7sAE6kHgR9GA+Hw9xLWUJmACJmACJmACdSBQtON0OmfF6ld255elFzq8KkOu4vuXXVaLRzlWKHsg928CFSCgxHr3xkzuSvrnYgImYAImYAImYAKFECjScTorUN4ITDsCkmEQ5SLgs4MYyGOYQAUIvD/uPlwOzFcBeSyCCZiACZiACZjACBAo2nE6RZI3ApMcPGcDelJadtkN+FvZg7h/E6gQgZ9FA2KfCslkUUzABEzABEzABGpMoAzH6RRHGoHptPRCm9ergfe0uVfkZcmj41Q6ruViApOBgIIYPAg8BujonosJmIAJmIAJmIAJ9E3gB8B3++6ldQd5IjAdA5zUunnhVzVON+FkCxfAHZrAgAnsGXcfLgS0I+hiAiZgAiZgAiZgAn0RKMtxOhVqoghMyox7Y1q55NeNgUeAJUoex92bQJUI/CoaEB+vklCWxQRMwARMwARMoL4EynKcTomkEZhenl7IvC4Z8z2snLlW5lvN9UNlDuC+TaBiBF4SjeaHgRdXTDaLYwImYAImYAImUEMCZTlOZ1F0isD0O0AOzYMo+wKXDmIgj2ECFSLwibj78MsKyWRRTMAETMAETMAEakqgTMfpFEmnCExHAKenFUt+XQ54Elir5HHcvQlUiYB+/y6OBsQHqySYZTEBEzABEzABE6gngTIdp1Mi7SIwvQX4Z1ppAK8/Bo4awDgewgSqRGB14HHgAeAFVRLMspiACZiACZiACdSPQNmO0ymRNALTAekFYLG4G/DSzLUy324D3AUsUOYg7tsEKkhgv7j7cFYFZbNIJmACJmACJmACNSNQtuN0iiONwKRIS2n5LbBX+qHk1/mB24EdSh7H3ZtA1Qgo2/QV0YDYpWrCWR4TMAETMAETMIF6ERiE43RKpDkC00FASG8O4PUwwE9fBwDaQ1SOwDrAE8A9wPKVk84CmYAJmIAJmIAJ1IbAIBynszAUgenWqMBsFo8SZe+X+V4Zd58CVixzEPdtAhUl8IW4+/DDispnsUzABEzABEzABGpCYBCO0ymKNALTJTFxm5w59VR0UEVZdw8c1GAexwQqRED+Pn+MBsQ7KySXRTEBEzABEzABE6gZgUE5TqdY0ghMCtV6PqB49IMqyi3x90EN5nFMoGIE1ou7bwoesHTFZLM4JmACJmACJmACNSIwKMfpFEkagelcQGFUB1VkuDwEvG5QA3ocE6gYgYPj7sPUisllcUzABEzABEzABGpEYJCO0ykWRWDSsaWHAR1nGlQ5CTh1UIN5HBOoGIGFAD0smAtsWzHZLI4JmIAJmIAJmEBNCAzacTrF8l5gDrBTemEArxsDj0SfiwEM5yFMoHIEXg3MAv4NLFk56SyQCZiACZiACZhALQgM0nE6C+QG4L4Bh5DUk9cPZYXwexOYZASUcV27DydPsnl7uiZgAiZgAiZgAgURGLTjdCr2/sAdgCIw6UjFIMq+wGWDGMhjmEBFCSwSgwfIgHhTRWW0WCZgAiZgAiZgAhUnMGjHaeF4VXRi/gOgCEyDKMsBTwJr/z/2zgNskqpY/+81XBXTVTFi4hoRFXNOGK8B0zVgwISK4aroNUfMCTNyxYS7O2cWPxQjKCrJCIiA/kUURVRQQXIOEv7Pb7cOnu3t7unp6e7pnql6nt2Zb+b0CW/3dFedqnqri8F8DEegpwiwYXCJpD9KunpP5+jTcgQcAUfAEXAEHIEeIzCPxOkrWNgSyZsnSHpdR/jA8vShjsbyYRyBviLwcQtf+mRfJ+jzcgQcAUfAEXAEHIH+IjCvxOm9JL1REgxMJDNv0wFEj5Z0oiSKZ7k4AsuKwCaSjjXiggcsKwi+bkfAEXAEHAFHwBGoj8A8Eqf/R9K+NuWnWhjTneovodKRVzRPxxMqtfZGjsDiIrC1GQ+QF5AL4eIIOAKOgCPgCDgCjkBlBOaROH0HSecmCdPvkHRcBwxM75H0jcrIeENHYHERoP4JydMeyre459hX5gg4Ao6AI+AItIbAPBKnCSF6YLKiPST9ODEokq8ae3srSRdJulFjPXpHjsAwEbimpL9Y/Yd7DnMJPmtHwBFwBBwBR8ARmBcC80icXivp7cmCrybp55IIo2pTDpD0+jYHWIC+r2v5KA+V9HhJz5K0gyRodt9mSe4vlbSdpCdJerike0u68QKsfZmW8F/mffh1y0b7MmHqa3UEHAFHwBFwBJYCgXkkTr9I0oEZdG/SAQMTCu9vM+Mu6583sGrf75QUJB0i6TRTKAlpqfPvHElHSoLd6v2SniNp82UFeADrhi6Z8/yuAczVp+gIOAKOgCPgCDgCPUKg68TpW0u6QBIeh1TaZmBivDMl3T8ddEne38y8CLtJOnqCccC5+ZukYyT9QtJBkr4taUXSNyXtb54i+oFyF6OhzNg43gwUPBhbLAneQ1jmdew8E8631RAm7HN0BBwBR8ARcAQcgX4gMI/EaWKu86rdts3ARLLoF/sBe+uzuKWkN0g6vEC5R/GHOveDkvAGwcSDkfFvNWaGJ4PrCG8DO9mEpsHok2dUUKgMz8RdaozjhzSLAAxknCOuEacybhZb780RcAQcAUfAEVhoBLpOnMbb8d4CRGFg+lNLDEwkiFJf4hoFYw/9Y5T4V0s6OEdx/72kL0h6nqT/7GihN5T0FEkUJiOkiSrHqUGBgUHo1G06mo8PszECGHqckzdv/JV/4gg4Ao6AI+AIOAKOQD4CXSdOP1fST/Onsu7TNhmYMJS2Lxl7iF/dThIhSednlPNfSXpTj3IPrifpxZbzkhoSvP/akoaUzft621TSPyyUECplF0fAEXAEHAFHwBFwBCYi0HXiNOEx/5QEbWSetMnAxM78T/IGHeBnUN5Sv+K2Ym5pAAAgAElEQVTSxGggLIi6Flv2fD2bGYsTeRWpN+Jnlsx9hZ7Pf5Gm93Q7B3isHPdFOrO+FkfAEXAEHAFHoEUEuk6cJozmMSXriQxMTdOrstN6oaTbl4zd96/ua56bVOn+oSRi2Ieo/LEeWJpSbwTXBzkwLt0gQP4L1xO0vC6OgCPgCDgCjoAj4AhMRKDrxOnPSvrwhFm1xcCEojrECrt4bMbJTj3eG2LWF6XYF7kY5EekDE4/stoTEy4V/3pGBCigCF3veZJgRHNxBBwBR8ARcAQcAUdgIgJdJk5va1SgkybF7vNZku40qeEU3z9aEpWuh8Iws4klFqPYRW8D4UqLmmiMd2hXq4LMegnLwjPmxeimuMhrNIUtC7yh563DulVjSD/EEXAEHAFHwBFwBIaMQJeJ0zDxXCwJvvlJEhmYYBNqQq5oNQoI8+m73MtqLkSj4ZcFNLd9X0ed+ZG3sW9iMJ3qoUx1YJzqmH0M75dPdZQ3dgQcAUfAEXAEHIGlRKDrxOmjJD2xItKRgekqFdtPakZSMUXP+ioYOG+zxHIMh9ONqWiIOQ2zYkxuDIng0YBaJelas3bqx+cicFMrpgil8S1yW/iHjoAj4Ag4Ao6AI+AIJAh0mTj9KYtxT4YvfBsZmFAcm5BbSaK6LrHefRNi/2GEisryAZJu3rdJdjwfmLl2TzChFsiDOp7DsgwHnS7X3veWZcG+TkfAEXAEHIEBIrC7dNWxtOla6WarpOvtIzW1wzxANOY65S4Tp58k6ddTrLZpBiaUcqow90nYZSfHA+UNVqjXDpRBqS1M/1vSKYYP7Ew7tjXQkve7n2G8aDVRlvy0+vIdAUfAERgAAjtJV1gl3XwsPTRILw7Sh4P0tSD9aiydEKQzgnRxkC7L+ffPIJ0epOPH0pFB+kqQPjCWXjiWHrxK2uwyT+xr4yroKnH6upb3ME0uQ2RgenwDC99O0m8b6KepLl6WJAlzDu7cVMcL1g+J09815RYjCw8WYV4uzSGwubFenSGJmhwujoAj4Ag4Ao5AOwjsJl15LN03SG8I0t5BOjPHKMgzFOp+dmqQvh6kVwfp7iuuRDRxYrtMnD5cEkWqppHIwDSrck0oFMrRA6YZvIW25DF8JFGGYVK6egvjLFKXYAbVbwzt+pZj1vjp5T4AvmDr4gg4Ao6AI+AINIfASLqpKe/7BencAmPh5CD9NEirgvTWsfSMID1qJN0/SHcJ0m3WSjdZka6LR2EP6bZrpbuOpQfQLkjbclyQVgfpZ0HCaMgzOM4aSd8J0v+MJRh9XKZHoMvE6Z0l7Tb9FNUUA9NnJH2xxvhNHYIBEwt0oah93MOUpoKW+HzqXYAdhiihbS7NIABdK3U2wPZZzXTpvTgCjoAj4AgsLQIo5iPp5UH6UZAuzSjy542lA4L0riA9fHcJZbRxITciSI8ZSe8fST8J0oWZeRAO9QPCnDBKGp/AYnfYVeL0Y42KtA6aMDCRWDxLfgwF1ihKdo06E5jxGOYdqUihrXV6zHqAPtIYglByCUPzTYN6OOYddVtJ51ueyTThhXl9+WeOgCPgCDgCy4jASHpkkL6bk6fwKzwDa6X7rUj/Pg9sVqSrrZEeMpLeE6RjMobEReRa4MmYx9wGOGZXidOw6LBzDEXktNIUAxP5BV0nhlKgjvAkFF5Yn6pS1k6L0bK0J4QtJlL/StL1lmXhHazzdXad7tnBWD6EI+AIOAKOwCIgcIB0pSA9y5KW01AhFPR3jaQ79HGdFvb0wSAdlzEkCHt6MsncfZx3j+bUVeL0zySRvFxHIgPTLKxJMPb8tM7gNY8huRevCYYDHgdyOFxmR+BuVg8DXA+TdO3Zu/QeLBn9ULteYbtycQQcAUfAEXAE8hHAgxCkVwXpz4nyzQ7+6rXSPfKP6ueneERG0pczHpPfj6UdMI76Oeu5z6qrxOn3GYd/3QXDwEToUV0Gpk2NFvX2dScw5XHkWKDgQjVa12iacsilaX6fhOqWkDa8Uy6zI0C1b6iDT3Svzuxgeg+OgCPgCCwkAuzMB+nYxGiANenDJEcPecGrpc1H0ieDdE6ytqNIyh7yulqae1eJ0w+X9OcZ1zArAxMhGbD3tC2vN8PhUkkvbHuwJe3/gZLONZzDkmLQxrKpeI7RO2qjc+/TEXAEHAFHYKAIEOoTpAMTxfq0sfS6kXStgS4pd9okUAfpHUE6O1nr3muk2+UesLwfdpE4ze4wu5pUVp5FZmFgerTtqrbphXpEUsfh3bMs1I+diADhNSi6/HvNxNbeoAoCV5Z0hGH6uCoHeBtHwBFwBByBBUaAZOMg7RKkS0yZvngkfRpGowVettZINx5LX0oYoy6CvWleSd89xLqrxOmDGtqJr8vARP7LCS0mLlN061RTvPZ2OtZOrvT3GN7klTy0kxEXf5C7GsEBvxXPKVn88+0rdAQcAUcgHwGKqwXp6GQH/gerpTvmt17MT8nhMNrZmBB++B7SFou52qlX1UXiNF6D8dQz2/iAyMC0euOvJn6CsvnNia2mb7CJpCNNkf29WqIunn5aC38EBuG3DfeTJd1i4VfczQKjUfb5bobzURwBR8ARcAR6gwDVmMfSW4JEEjRK8+kUY+vNBOcwkSBtn4QynUexuTlMo29DdpE4TZz63xtaeF0GplsZbeqNG5pH7OZjpsCeLYnEU5fuEGB3/HeG//7dDbvQI1Gf5CjDlFA8F0fAEXAEHIFlQIBwHSustm6nnaJua6WbLcPaJ61xjXTrIB0SPTFUrF708K0JmHSROE1tEJJcm/L2RAamJ0xYW/brAyTNQvua7e9exqpE7P3zs1/6350gsFVShdqT1JuB/N52Xf9pTgUWm1mF9+IIOAKOgCNQDYE10lZBOt6UY7wOb/CaBxtiZ7UtqJBNlWoMLGpa3GbDVkv1VxeJ099ruMpyHQYmqFPZqW5CSDAl5AvD4ftNdOh91EYAOmDOw+mSmvYs1Z7UwA/c2TDdZeDr8Ok7Ao6AI+AIlCEwkh6XhOX8dWj1GsrW1sZ3VKwO0qlmQPD6oDbGGUCf9zXFq03e/DdK+krDWLzdaGBvULFf1neGmqlEHqkt8aiQMO0yPwSuKukYU3a/Or9pLNTI/FbAFNrhZb0vLtQJ9cU4Ao6AI7ARAiNpx4RN6Yih12zYaIEtfbCHdFvzPOCBuDBIz2lpqL5323biNKEQp0j6t4aBgIGJCtLEaleRz8xYtI4x8FJdYMqqU4VWQb39Nlvb+cADUbegYPuzHNYI5CphPEAE0ObGwrBQ8dk6Ao6AI7AICATpbUkM/7dXpGsswrq6WoPVhTgoYkhl6q7G7tE4bSdOX1HSmZLu0vCaUWoOlVSVgemeVrH6mjPMY60pqodJYl0u/UBgdzsvv3a63MZOyKcMU8KYXBwBR8ARcAQWAYEgvTYqvUHaFZalRVhX12ug9sNIWmNYXjpevgTYLhKnvyXp1S2c28jARGhUFcHLUje5FprjS0yhonq2S38QuGniEXpmf6Y16JmwEXWcXfN4D10cAUfAEXAEhowAVKOJ4eCJbTOeTBLLgzQyTCmo96wZuxza4W0nThPigwHRhkzDwLSjhTrVmcdeZjhQ+M6lfwh8ws4P8fq+kdLM+cFIJhwMCteq4YHNjOy9OAKOgCPgCDSHwEh6UaycPJY+e1nzseTNTXZAPVl9jD3NgLh4LD1tQNOfdaptJ04TskToUltKXWRggr6zTDaVdGEN6ti7WQw4ihTx4C79Q+BGRgvMOXL63ObOz+fMgKCInIsj4Ag4Ao7A0BAYSY+MydFj6UtuODR7BneTrhykb5oBceFIuk+zI/S6tzYTp0mWPlUS9RHaksjAdMMJA+wp6cMT2mS//rIpUNDOuvQXgQ/ZeWqKlre/K+1uZhTkO8Fqaty1u2F9JEfAEXAEHIGZEVgtbR7pRcfSN7yGw8yQ5nawj3SVIO1vBsRfx9IkZTS3nwF+2HbiNFSaVXMT6sJXhYHp0ZJOknSlioNcz7wV7Gg/tOIx3mw+CPBbvcgMCPcQNXcOHmuYHiGJOicujoAj4Ag4An1HYDdpkyD90hTao0fStfo+5yHPbyxtGqQ/g/dY+iHF5Ya8nopzbztx+uWS9q04l7rNIgPTmpIOriDpeElPLGmTfkWiN4bDH1qgm03H8ffNIICRyvla1Ux33oshwG8KXKlz4uIIOAKOgCPQdwSCtNYMhzPXSLfr+3wXYX5BunuQzjfcScZcBmkzcXoLi0n/95aBjAxMbyoZh/jtqgnc0H+iNJX1VzKUf9UxAniWOF8U8SPkxqUZBK4r6UTzwm3ZTJfeiyPgCDgCjkArCATplabAQiO6TSuDeKe5CATpeYY9HohlSKBuO3H67x0lHEcGpiLvwq0svOXGuSf+Xx+S84Ii+k9Jk9r+6yh/N08E8Cz9xc7bS+Y5kQUc+8mG6yEtkh8sIGy+JEfAEXAEOkRgrXTLIJ1jCuy7OhzahzIEYLQy/P9BONMSANNm4vRYEonNXQgMTGdLKmJgOqBCDsaupix9vYsJ+xiNIbCTnTcqkLs0i8CKYfu6Zrv13hwBR8ARcAQaQSBI3zXF9VcwATXSqXcyFQJU7Y75D9SCmOrgYTZuM3GaAm0HdghLGQPTdpImsfL80RSlbTucsw81OwK3t/N2saTrzN6d95AgcANJp0g6X9Jtk8/9rSPgCDgCjsC8ERhLzzbDgaJlbVJcznupvR9/LP2XnYvLgvSY3k94tgm2mThNuNAFkkhs7kqKGJiYwxklYVS3MQX0UknX72qyNcehgJfH928IHknxhJzhgXJpFgGqeIPtj5xEoFlgvTdHwBFwBGojYGw/J5vC+tHaHfmBjSEQpFV2Pv7yBemajXXcz47aTJz+s6SHdbjsMgamz0javWAusEOhIB1e8P08P4Zvn+Jdv5D0D0mX2FyhKYWTf63W5+gsA0tY0XngvHL+wMmleQS+afjiqXRxBBwBR8ARmDcCQfqEKarHrZauPu/5+PjSinTdIJ1o54WY6kWWNhOnUere2zF4RQxM95R0jjY0Bilot7WkqBx9sOO5lg13U0k/NKUNxfiLWs++hpFAQvdTJP0t+f5ISXcs63CBv4u74xirLs0jwG/qdPv9bN58996jI+AIOAKOQGUERtJNg3QBSupIenrlA71h6wiMpR3MeDgzLH4sdVuJ08+R9LPWT9bGAxQxMLFOcjGiYCyglJNsjYL+iPjFnF9vKSnmYDCvgwpCRm5k4Vi04R/MQ8sY0kRsPiFnYEAOhEvzCDzf8P1B8117j46AI+AIOAKVERhJn0FBHUv/7zKJXVCXniBA0nqQjjPDjloBiyz/I6kNthp2z6E+nUfoVx4D045mzKBsft6UIdiVUDoJB9qkJyeZomfRIOC1bGPhHZm2i56nU3SKfmU4PLuogX8+MwIUfuR6fNHMPXkHjoAj4Ag4AtMjsFraPEgXmfHw39P34Ee0jUCQtjfvw1mrpOu1Pd4c+28zcfoYzS/x/EOS/mphPhgwcNfDyhM9DShCMTSInf6+CLkN0Xi4UBLnp0gekLTlmP8tarjgn0MNzPq7DpNbcFg3WN7NJZ0l6UxJbAy4OAKOgCPgCHSJwFj6ghkOR7rXoUvkq491gHSlIB1r3of3Vz9ykC3bSpzeTdLOc0LkhhanTUhLTDSOSnl8JZSJ93vPaY55w347MQhQisuEePS4Fl7fWdZ4gb+Dqpf1f22B19iHpb20h7+XPuDic3AEHAFHoF0EiKEP0vmmlD6p3dG891kQGEvPN+/DabtLV52lr54f21biNCE3MAXNSygcR+hUqmCn7yPN57wMnDxc7iEJo+ZgSVvmNUg+gxI3Xc+yMrZRFR4cfptg42+bR4DwWuq3gDX1U1wcAUfAEXAEukBgLL3CFNLjV6QrdjGmj1EPAQyGIJ1mhh6sLossbSROk18w7wJeT0gSalNFm/eEYPC6/UBP7KsyxsPHB7qOWad9J8MBQ/HfZ+3Mjy9FAIP1XEmnSiJp38URcAQcAUegbQSC9EszHt7V9lje/+wIjKRP2vnab/beet1DW4nTv5b0xDmv/PUZJTsaEdEr8cA5z2/a4dkBhjnqpMy6yPNYRqHGRzyn/7mMAHS85lcb3nt1PK4P5wg4Ao7A8iFABWlTRKkmfYvlQ2B4Kx5Jd7JzdmmQFlkxaStx+pOS+DdvIa8jKpjZ1y3mPbmK419D0gskHSbpl2aUpWtZdGawMpioaA4Wdylr5N81gsAVjKENvAkZc3EEHAFHwBFoC4Gx9FlTRKG9cxkIAkE6xM7buwcy5brTbCNxGq8D3ocuhN34+0gqqrgMJW2qbMf3JB73WchJoSYFhe7490YLz7lDZj0kDi+rRC/Mg5cVgI7XTU0NDDbYwTbteGwfzhFwBByB5UAAVqWkcvG2y7HqxVjlSHqJGQ/wyS+ytJE4fR3LeyD/oW2B5x+DAEpJWIteI4mk6VhHhR3TmCQdDQde2dHvm+AJIpQsMkIxT9iXNksmSkG5dB0YFcsqvzcstllWAOawbq63eF3OYXgf0hFwBByBBUdgLN3ZFNCLl6Bq8UKdTULM7Nxdtka68UItbuPFtJE4DeNSWbGzjWdR/5NYuyFVqk+RtKckqCbvlan1QEJ33+Qlks5LDIPfSaKmQ1YwyNJ1LmudB3AhlAssnpUFyf9uDQE8fBH3x7c2infsCDgCjsCyIhCk15oC+rNlxWDI6w7SMXb+njfkdVSYexuJ0x+WRM2HLuQVGYU6Va7j+9OSNmd0MakpxtghmRvzJcSxqFAcn8c18cral1X2NyxeZgBgJOLhdUa7dq+IO0u6yAoyFl2n7c7Ae3cEHAFHYFERCNK+KJ+jfhdyeoxV3T1c0hEl/9hJJiQkhoNw2u4maY0dc6Sk9B+7U+ymDlZG0qft/E0q3DXYNdrEUQDY9Yb+sinhuqLadFtCaBQ1ER4u6U0ZhTpVrvPe98l4oIrv+cn8/yTp6iWg3Sxpy9pgwVlWOcCwiPeZfexvMNyxp6Fpi3KudjKsyctxcQQcAUfAEWgCAasXcB7K51rpfk302VIfGAPw4u8i6c8ZxSQqXn8wlpfsjh786iSspjHaJ0t6gyRc2oPelRpJTzLPw8k7ScTOL7I0nTh9TSvWdtMpQcMoICkYo+A5di19QtKKpB9L+mOibGME/EYSlLrxWs17ZZc0/Zzq06kRPOUUG22Ohyad26T6E+z6pu3f0uhshtUZGx5gEeuxsJmBoR/peE+X9AFJfU+OHxbq62d7ZUnkg4H/o4a4gCHNeSzdEBbAsXTfkfTIID05SM8ZSy/jH+95Xo2lR1ibO62Wusg5GxKMPldHoP8IjKT7m+J55oAKw6HwfT2jnPBwmES7iXFEO4yPhblhrUjXDhIUu+Q93Lr/V91MM2wjcRqmIwwAJDUKqFSLgTnJKPiBebY+aDvJUESSB0DRKnj+o2RDebgW+YdxAVNR/Dt95VrvgxyamR8KcJnEBPG4lmWmamVTAxwelwEMbw6Vt0mi53uMx1WSMLxcmkPg7kaMwH2/L7+n5lbXcU8QrIylLcfSs4lWGEnjIB0WpDNNl7isxusZQfp5kEKQdhpJz9xDGgpNdcdnwIdzBHqAwEh6kf3QUaCGJHgXYjhAVFB4+JYpz+x+koQ6tMJbE89LkI7lPI6lZWB0qZM4jeIePQVZowCWIxS4GJaTegoId5tkFEw8P9Ygy0D0N0kHZ5TyeC3H12k9IlXnMm27v2TmeccJHYwy7T8zoX3R1zdcgPoIeDk5n0X3nWtLep2kExLMyCd5RBEo/vnUCLzfsN116iOX/AC82Wuku42kHcfSXkE6eYJxAPHK6UE6fiT9JkiHBmk/+8f7o/kuSBgMtC0zNv4RpK8E6ZVBussSeNaX/Grz5Q8GgSB91H68Q4wJhV0ILu+oaPFaVKfiqpJOlLSQ1bODtDfncSRRsXjRJU2czjMKPp6EDx1bwSjgmuDawFOwSYvgvcquVWLdmWNWIU+v4/iefIk+SEz6jfPCs1AkFEOLITmxPUxTVeRaxjqFgUdoz4WSQpUDe9wmhqNBzVsmhNiwbnKyIm4U3MMrxncu9RHg/n+0pEslPaR+N8txJEp6kLYO0m5BOiVHwacwKUbAV4P0gZH0gjXSAwlbmhahFelGQXpQkLYfSx8M0teC9LucMTEyMFz+j/Z4QKYdy9s7Ao5AQwiMpO/wIx2v3/lqqNdOuyGOlQdCfNjyGllN0onsbJVHi4p0pW0H934s7Ww3290HN/n8CUej4GGmUBE+FI0CWME457Fyb5mngN3eSUYBoUX0Rbs25WuSYCxi9zN7zabXb/q+aLe6zXnm9f3ezG+M2gV5htZtJRGmAzVrug7OUV77dCx+m/xO09wk+hiy8UCdjogDnqeqgteBjZB4LF4JNgbwUrjUQ4CwVfKIuD4nXYv1Rhj4UUG611j6WJD+mlHeLwrST0fSh9ZIj18lXa/tpY6lTcfSE3m2jaSDg8QcUi/F8fbcIyzNxRFwBLpEIEh/NuNhyOEu70sesjxsz5V0mwTHB0kiKXHz5LOFesuujd1YD+n5wrJGAQpRNAp+JAlPQawjkDUKPpTkFMBYs7pBJeBAS6pvCz52ye4hKRYMi0rhpFcS/fsgxIqTBJ7OF9YzdnFRJGDAwoODJxDKYM5z2pb3/E6zZAZFa3tucjwhUEMVckNYOx6UOhsX4ApJAMfTD+F15EncYqiAzHneHzMcwdBlPU/1lYP0rCAdnlHOLwjS18fSM3brgbG1Il2DPIsgfStIF2bmSr7EtgfU+435deAIOALTILAiXS1IuB8v20Nix3CogkKC4pkqK+xO8zlKz3GLXqApSXxHuZiHNGUUVPEUsL6mE6ffbmEybWOHW/+pSZJses3mvf9I2xOaon8SGDGy8ubJZ4QmpTS62Zwk2pxqRsh/ThiXxPXonSGJeKgCwxLr/vWMC4CJCUYmNkHoj7CwtZJ813U6YPE44HnAA8E9ZGkFog0iDiz/IO7o/zNI+4yk5/J9X8GhmC2hUkYzn+ZN/ClIr/6CJ8b39dT5vBYBgVXSZtF6H0nEGg9ZSCylWi8P1viPBOnPGxPOkNc2ce5rpVvGc9nwLhFGAUpjDB+KnoIvm8FW1VNQ1SiYuNakARSM7FA3IbAj/b2Jjib0sakp2VRmjh6WeL3mvX5nQn/z+BpP3iuNNplEVOoX5BkDhOxwfqhvQSghlbyhtgWDKoLCDSZDzMeK68MbwxqoIt6EgCm1IcibidcLRtpje0Tr28Q62+wDbxmGKTkQV2lzoD72bfTsbw3SWfGZYe8/slaiPsugJEi3CNIngnROsh6Ssd+wzxKe30GdPJ/sMBGACs1+bJcsSPIRBb/ibiUPVpiVUG4Xnp6PGNR446yYtJYaBSS/TjIKeNBSpwD2oRg+hDLYhlFQ9QeVJk5XPaaoHbVACHfrih4wL1cnKoPpK/SSyyoHmYL8uQEDQN0PzmfTRA14Vfn9/TwxIqglQv2NpVOIa1wf/2e4YfwujYykpweJ3fnoafjbWHrj7gOvdcQJXJGuO5beEqQTk/XBQvjkpTnBvlBHoAsERtJ97EdGbPmiCIptqnwRp91b92tToO8mEbe67oGQ1HqApSVrFOCyjzvenPc+GgVVYcEAQuFPQ2WqHpvXjgTVl+d90fBnVGZm3ul1WvQeY3jhjd8CfGPYU12a14JuO/34t3aet21x1AdL+laycQJz2FslXbfFMYfeNb8pDHPCvxY+9GutdI8g/Tg+I2BQGkkvX5HYNFkowbMCrWyQTkvWeyBUrwu1UF+MIzAvBKwCJAonlJGLIiQl/iKjmLH7t/ASJBLcOJ/cJKl3cbakr/TIU9DGOYBd6lMNdQyjE3i1LZEtChrOM+1f6jGLhkRMkiUkZRklVuT+9EAXTyhlPJddkDXcXhJemshChoG6SwcsYgM9PesqTnN++B0uJBUuxgEMSbGIKIxFxqZETtFCi3njdwkSeRw8Fy8eSe9ho22hF+6LcwTaRmAkPYUf1Xg9NWLbw3XV/40s94Fd9fjg5vXFXU1gXuMEiYI6VJmO9J7EisO+BMf5okqTidP3smunTf7wx5tRh6IHEw9eIHIA8ACxexxDdbhm2UHmlQrXyyjfH/j6n2/zh2GrS7mBhUnFHDCSgzGK79PlJAYyFvdIfmPvGMh8K09zJN0hSEeY4ozyvM8a6XaVO1iQhobD9xIcfj5wgpgFOTO+jMEiYLRn3FSIm10U+bqkz1oCIQ+F+A8lbVJV3EFjgAfJjMFYmRaXNAw4sLIssjSVOE0cOZ6AttzbFDWk2vCz7GRQBI3Y67hDHdlfUPL+amEVXL/Esi+jxDoHQ6XV5Pxy/tj9n4fALESiekoP/BNJT5J0hXlMqIdjEvpIpXcK+TUV/jjXZZK/OJZeEaTzTWEmMRr65KWWIL04Sao+d7Se6GGpMfHFOwK1EKAAi91ciMtdBEEpQ+mKOQ6Es0TjgdejGqwLAF6M05uY0RjjOd6QgpBdbfI+3rYIJ7hgDU0mTn9T0qsLxpnlY7wZ35MUaxbc3Lj7qUfyAkl4yjBeovA9il68fjeLXyzR63dt/XDzD00439S84PzhbZqnYCiQNJpeTxgUL5VEgcRlF84P54lNtPQ3ODhcoCi1OghsCvLvx6sXuL7RtCcoSLcJ0iGGDfh8tWF2wmmn5O0dgeEhYOXn+QGx8zJ0IVwJDnl21aIQrpOtVgt16ywCTSVx9lCVYnSRcMcYMJ/MVYjp5Ka4emMPCx4XdtSfMtcJtjd4k4nTGA6EDzUtr7F6I5ESmd10Kk4jeIb2svfpC8Yp4UwoNoTALJtQCJC1f3KAC7+rzZ0d7T4lvOPd+qrVOQBbPGHvlESo0zJL9BKR9zRIgWY1SL80xfifMA+tDNwYauNEUEguSDvF52WQDlsj4RV2cQQcgSoIBOnudqMhsW7oQrhSXrIrivP59iDnYcm/Z9RYLIbIB43TPnAuJmgAACAASURBVCqAdPPopP+50f5Zwb+425RXfZakWxKoibNfRGkqcXorM7Sa3IEkDIrf2P0MeIwCivnd37j5UeColZAnFInjmiWEZ9nk27b2XQe4cO4VnDeSvvsoECqQiB5Zv7hHEu5JLs4yCh5aPEXgMLi8AHuW/82e52dChrKMJ3GaNY+kxwXpbMPsL2PpztMc720dgaVFwFx46xTOgZd1p04BlVfxPuTJq+xBHo0HlOgt8xoWfEZVYFzaGAp5ws4ofcOYc++8Bm1/Rm0HuwleBstEwXj/K+kELeYuS1OJ04SbkGhK8nQTQlgIOQtpQib0uTAuIdBEcu3kFVnje4zfeG3dcv0hS/N/DFtCqR2SwOZykp037k19Fu4V0LrG5HzuYYTu4WFdNnmanTPCuwaTE7JGenyQzrX7/59HC5K70cXFBzPhWDrBsDtrLP1XF+P6GI7AoBFYLd2ggsLZ9zWS5HaOud6L5sqDII33RRk7JsmNKDqOzym49FNJVKsuEnZ56JN/hKd0LrBHxHM5gbsbdpFDFzTWuanEaTxYb2zoJLJrzrUXPRkolhhw/239Mw6FDMsExiyuraYLjZWN2YfvMLpY96o+TGaKOZBfwLzJYxlKTgH3uRcmYXLMn/sECnW8dqeAYLBNCeli7Ww49V6C9ISEitTDb2qcsVXSZgkr1YVB6yh8a/TkhzgCS4KAxf5dhNK5ZpjhLDexZGBc77idy+Qe9lDgwRD//UASBbvKZLWxccBcUiTsesc+58IMww2P8ziS/l40Sft8kRmYmkqchqGG5OZZhURMFMjUY0DhPgr1xZ3N/Y1xqWwsaIa5vo5fMkUuFjNsIwelDO9Zv/uOna8hhlvheXucpAOTe9pxpkxfY1ZgBnB8zJ3jmVLkDezFMtglDxLKLtED+3rib/3TsiJdYywdYFiet0Z6SP3e/EhHYAkQCNJRpnQ+c0DLRQEmQTnymLOTW6bcszSqreKhiEp+fGVXl1h0HppZiRSakwyCqNzRJ4pn52IVNXmIVImxjgxMb+98ou0O2FTiNHHfKA+zMGllaVnjyilIFatYc81SCC5N8o/t0ldybGJsOordMkhq7P9JUppn1Of1w5JFXQXuBUOvXMw5IJn/YlsPoaHkdbFps8iyna0Xwz7vuTD3tY+lhyZUrPuR8zb3SQ18AqulqwfpR2ZAnD3yuigDP6M+/VYRGEt72o9lCCERhAOwqxcVqWgA8MpuLuEND88AtoUkQnVglErbZ9+zq/u+jBEChSbtshzZN5N0z2Sc3ZK+YVnpXIK0m53HqtWWF5WBqanEaa6XWGxv2vOJwpHSssbjqb8BI1g0dMmhQTGL1MKxXd7rF+waI4RukYUcAQrlRZID2MwwsEhmBYNZDLoucMPbwD3j8C4G62gMCBigyyVXjLVxPvidcQ9ZVNnb1rpD3xY4ku4f6xWMpR+i9PZtjkOdD1S3I+lge5aeTiL6UNfi83YEWkUgSO+yH8pKqwM10zmc+K+TtFPBP76DLScVFDN2koqOiZ+/WRIPirQa83vtAZLd7eXBubkNgiJIqBAP1W+kA3f5PkgHcR7H03k+IgPTIt0gm0qcDpkk52lOJ3kv1NbI7pbDmPTupCMUsqrGANd+3AF+TNKHv+0PAoSnQc3KvWCSN6k/s64+Ezx7UJlSS4c18o+k9uyGTfUe+9sSrzP01rCisVnUCzE61n/YM/tnKLu9mNgCTWJFujb0rYbx35zGdYFOri+lOQSCtK39SEg2ddkQgYfaAxK6zCjbZpLpSKTmIXqapNvGRl2/BmndA6VGrOYiMjA1kTi9vcV9T3sqs7Ss8XhoANlNh7krCkULMV6rCkYr19phVQ/wdp0iEL1DeB16Ge7SEBok/ZO7w+8sGhFHSsJrxHeLIi+y9eHtnrvsI10lSIfa8/qPK+tDcec+r0WcwIp0/SD9xbD+8W6LdV0v4inzNXWNwFja0n4g/xxtvFPa9XT6OB7KHfSFhFL8KFOpGZpDdqfIpWDHey5CBVE7hxSIq1PsadEYmJpInCZZ8oIp2XLyaFnjNUFIXVqgkIrRKF7UeqgqeLsWeWe7Kg59bIdniBArzmnWU9nH+TY1J5jmCNGLRgThn3iAq4TiNTWHNvuBVIO1ZUNX2xwzt+8gfd7u8+dBMZrbyD9sDIGRdM8gXWCY79JYx96RI7AICFwm/VuQTuQHMpaeuAhramENKAbEq0NnGIWdRWj9yL/gu7lJkF5sNzgqXteRyMC0R52De3hMU4nTJOpOE5Lxfxla1ggNhgKGCPk3UVBGMDyvFD+o+ErNA5QZKk/3Pf6/4pIWolmk+ISAYRkFzxrMdNG4JdwHjy0J5EMWQtHYHMKzPLcqxGNpB7vH85zue+2QIZ/vDeYepO0j7iPpuRt86X84AsuOQJBG9gNB+XGphgAeiT+rBztASdL7J6pNPbfVojEwNZE4jUeGvJcqkkfLGo+j2jDVklMZS/pa+kHF98Rix8TVd1Y8xpu1i8ATkp33rdsdqve9YyhzvUNRjJGLN4b8oSFXtseTyVq+Pg/0rYbP+faMnuUeP4/pD37MhIzknLUb0m4Pfm2+AEdgJgSwqO3GNKlY1UzjLNDBb5L0Y9ULEWoUhp2kKwTpVM7fWokE6FmEqtvshj91lk56cmwTidMk2sdK0GXLKqJl5RgSGlGkUt5wvFawB9Wl9X2lKTPs8i4y400Z5n35jqR4qKJRLjE2XdYjwHX/attgARv+QSNNsv/Q8kGY7w9tDeS8dSYWGbCODCNIh1CbqbPBfaB1CFB0NSki10T9H0fWEVgMBNZKNzHjgWJxt16MVbW2CihtiV0vChlhZ7gzWSvdw87dhQ1R9i0SA9OsidPsorJzWsZogmKRR8sarwEUqGyCM3S+KFN1f2sUmMOooQ/CZGLBuTimv3aHQKRmPVHSdbobdjAjoew+w34D0YiAKAAa7DQMtO8LInSVooUnS7p+V5MdSS+x+/tFq32joCvYNxqHIrpButjOxdzzXzaaoH/gCMwLgSD92n4Yr53XHHo+LsbC5yS9pGSeJLF16toO0nvtvFUpDlcy9Q2+igxMQy8G1UTi9O9st3QDgJI/imhZaYLiRN5EdrcSukuoXGcRvETw7aOQMQeX7hF4gJEpcA6e0v3wgxsR7xvhexBQgBkU11BkU8BzCMKzkXl3khu2StosSGdyfx9JHqI45ytkLH3QnrWnjjdkzZvzzHx4R2COCATprfbDIBHTZUMEYDAiIZKiXiTjpv9gwLm3pGdJogLr0zY8tL2/VqQrBumv9nCBVrBJgXby51OyDTU5fhN9NZE4/RlJOxdMpoiWNTbHaMB4yIYawOBCYcFZ5R2mzGBEzI3ta9ZFDPR4KHdjuFKd3JWBLruRaUMcgPcWEgGUcRKSKW4Jw1mf5Yrm6WPOrZOLBOmr9kw+itCZPgOzDHOjineQfm/nhDweF0fAEbDQpXVuOSpYOiKXI8DuYloUiQdH0T8SqHnAdCJrpMfbjeycFooF8bAizreTXbYWAZs1cRpj8Bc58yujZY3NCVfaMf5hrxyH0vTfmc/r/AmnfozF5hq9UZ1O/JipEQB3cp64D/ylyzCWqWfa7wMwwN5jVdfBkiKIe9pmTF9nfgfz+OE1aS1MjcrGdm+/dK10v76CsWzzCtLW8bx4GNmynX1fbyECQfqm/TBQuFykFyfc7UUGQ/o54T6dSZC+ZeerrUTNyMDEDvdQZdbEabxOKDVZRaGIljXiRIgGnqhrxA/s9b8K+ss0q/xnugOOQrtIRboqg9BxQ7xR/O4p+nePjsdexOE2kfRySX9INmaoqQOLVR/zed5q8/xSWycjSPtwbx9Le7U1hvdbDwE/N/Vw86MWGIGxtI0po+d4wbh1JxqOcnZ97i6JJFcUBUKU8Mw8SBK0jNQBoFASf/MQ7ERG0k1jAlfLnqJFYGCaNXH6/0l6UnJiy2hZYzNiuz8Q/0he4b4/OPm7ibf3SkJASOB1aQ+BWHUY48F535vFGUMBj1wkAwBjco7IM8Nj1xchDPEIMyAIZW1UxtJ97Tl86ViifoZLjxCw4nGXcY5IpO7R1HwqjsB8EEhj6MN6mr35TMRHnYhAkD5gD5guclSGzsA0a+I03OqftJNSRssazxsx3YQm5SWcY4jA2NW0wF4TvWAkobo0jwA74bGKdLwemh/FewQBNmjIJbnErmtYjqit0xnT0YTTQL4T1wJha9D1NiZB2o97O/V7GuvUO2oUgcTrv3ejHXtnjsBQERhJrzel9KSGqD+HCkVv570iXT9I53CeOqx6SUgWcfV5CnFvsbKJzZo4jdL4a+OnL6NljTiQDJoX0oDhgYJPHk0bQnGuaEA4A1OzCBNuFtmt8Cplk+CbHc17iwhAkYo3DZpUrm1CxQgbu21sMMfXd9ucmE8jEqQH2fP3krGE19elhwgYdes670OQ8Py6OALLjcBu0iZBOtF2Pt643Gj0c/VjaWd7wPwOb1GHsxwyA9MsidMYH+Q9kPsBxWrZTiM5CCg4d8o5L8+RdFbLiucuiQFRtwhdztSX+qOH2jlFeYUp66pLjcZ8Fk/+1dslnWTXN3Sv35D0wPlMZ92okEqwqcBcGqksPpLGdm93Bq85ntgqQ4+k79i5aivnsMo0vI0j0B8EgvQq+1Gc6rkP/TkvzAR+6SCda+cHetguJTIwfXmAVWJnTZz+jYUiTWI+gT1m34KTMjKFp+DrRj6maB1GHoouSk3TFL6NTHJAnTzYqETBkyTeqw9o7os4VQw3iCx+mxjJFEp8apdMdwmw7DqzsXDsrNdGkK4TpPPt3k4l7j4KGynk+pC7xYYM9Scm3RPvKOlVlgPWl8KAhI7OVNMqSE+2c9UG22Efz73PyREoR2B36apj6QT7YRBn6tITBIL0CTsvR+80HyaSITMw1U2cJlnzlJxK0dmrgoT5UyU9IvuFGVtUIYZVpm0h8XScKFeEV2BUuEyHAMZ5rEVw6ASP03Q9e+tZEeB63kbSQcl1jlfwFbMq8TUm9mGbA7lRtSVI/2P39uM79ihXmTNKP7oAXlUS2smrIpwz3meo05EnFE/kmOONeCSvTdlnhAdeT9K1yxqVfHfNAqMyMmZBflFLdpOuHKSTOGdj6YW1OvGDHIFFQ2As7WA3svP36Ed86aJBPPV6jPs71uJ4+tQdNHdAZGDqrCBeQ1OvmzgNLSueh99PmAeGwZEFbbYyBaOrWG0eusybHXP+8ZDvy65fAUS9+pgQmYjd960wZK8m6JO5HIF7SsIbigeAc3aapPdJIseoC2Fz4RhL7p5UIylL3Xz5/IJ0hD1z2yBUuHycGm+oAP5Tw5a8qnQjAs9c/J1ka9e82jCh2Ghag4Z7IUQfGHuwaUHRe5wZGH+T9A/bhIl5LiTNE6KW0mXDZMexEFBQhwfvEwxY9EtfhLeRo0SY6JNz1oxRwUZPXg2fnOb5H42kD9k5w6BycQQcAXa1g3SI/TAOumzDG4YD1DEC7HKMpSPtfJC0O2+JDExD4rln9+rcgnyEIjwjLSvFoWBXuWlBQ3b7eQhuV/D966zadMHXrX1M4nRkrKEOBJ4jl2IECM1bnShEn2s5R6V4Jv7NtAjcUtLHJZ1t5w/lkXj0LhKPIUEgTJBwqrKcmK/mLWqNtJXd2ykKxzr6IqzlcMMzj3o6/a3slkz6Q3YMhkOe14B6NLcyGt6iIqzgiQGSGh7JEOvo01clv9VoxPC6j6RtJ9CnY6TRFrr1WrJGup2dN2hbb1erEz/IEVg0BOCYDtJF9uMgztRlTggE6a12Hs5ZLW0+p2lkhx0iA9M0idNZWtafSCLpOU/YdTuhpEgbBt9n8w7s4DPCCzCaeFBCLdlIcmcH8+56iNtbaBo4obi8vusJ+HiNIEBcPmQf7GJzLvmHMvmwRnov7gT6XsZidz5PUGb5fiPvY5DebPd3dvj7JNyzmDM7+Xlek+iRoE3MryK8ib8xOlJvQdG6oLY+047huPivCg0qmzaERMVj8CaQ/1JFeI7yO8cAqi1BOpxzN5J2rN2JH+gILBoCQXqv3dTOWDtMms7Bn5I9pC2CdEFPb1BDY2CqmjiNaz5Ly0oydB4FK9cYbmu8C3lCWANxv1Ufanl9zPoZhQ7jQ5YH5s4exrQBpDBTxTAJDK1sCMYGjf2PQSCAF+l5FtoSlUsUWnJZmqDazTLdkUxPKA7hU1mPLPeAP5uS+/wsekE60J6zMLr1RQjBiriRS5In3FcIGcPDiZeCxGiO+aXlKuQdk/cZmMSx4useeQ1zPvu6HUvI0mY535d9tL8RItQmQkhqLlUxdsrm4t85AouDAMnTQfqd3di+38NErsUBO2clhv8vzHA4eE5J0jkzu/yjITIwVUmc5mGYpWWFshMFICs8ZImtzXPP05YK5IQOETs8T2EXkMJT8eHMAz6PUnaec+x6bEIi2JWOmBwmDz/o+hx0MR51OshdiecZDxye0zLa5Unzgmko6wXGu8EYxOJzb0TYiCCkJ47NhsvlsiJdI3r4qS59+RfzfxO9CoQVxbWUzYpq29znwLYo1KjoeDwIYBYx4pUw0EnCcZBZkI9WpwYR1wBj1Wa3CtLWph+ds1INp0lr8u8dgcVAgBtavLkFCWYJl44QCNLudmM6eywRVtFHiQxMQ2HmmpQ4TfVYdp+zFITsrMG+Q6xuKnCyQ11YJPxmYOvpi7DLF+PCWc97C0IS+jLfNubBrvFLLWkS5QGlhyRbYrFdFhcBfttrJF1kSiPhMvw+b1ZjyZ82RTl7P4ihPhgXXE8hoxST6Hu5jKVt7B5/eo8251KvA7VjJgl5GoQMsYly50mNC76HPSs1HnhPMnyZECJGgnSd80e/d7Ux+e3XEgyGWLR1LJFA7uIIOAIRgZH0ErvBQUv2jPi5v7aHwFh6WYJ538MohsTAVJY4TXgBzEpF4QMHaENaPirgkph585IrgR1+Qp76JLeWdHDysGZ3kXyOlEmlT/Ntci7sDuN9iorKn+ZcbKzJtXlf1RCA+ACjIcbaQ4ZAHRaMi6oSk4LJdeI+EAVvBiGCGCjUBonXWfp6/dh4JH3S7vNfiZ/14DVNhJ6UUIwhTmI065uFBZB7z1EZvMoMF+pNgHPW+zMNfHguTrfzNM1xG7QdSd/mHI76d5/fYJ7+hyMwFwSC9Dm7yVGkbJqb7FzmO+RB10r3S7w9eSwXfVzekBiYihKnoTclMTobzxzxfpvRnsa/ac/OYpHgvueh+qCiBnP8nIc1Xoi/Jw9sKA/nWbW3TThgQ8FLFJU4vEt4y6jP4bKcCKDoE6JIqE28LqgiTpjTJGGDIR5Dcnb0DEOJDOtT/C7v9Umx85jvMOqmBkwctuyV+H9ytJg3tLeT8kNIFKYtdNCzCvUSUrzOkMSGTlbwjFA3pwkmLQw8jMjaMpL+13Sj79buxA90BBYVgX2kq4ykg+1HcpwnULdzpqmrEaQTDefv9TDPoWzhPIjZxa4Tf1rWb9Pf5SVOR1rWMqpEHloo2wjhWiTZ3s3+znt5toUI9TkcBhYV3PaxIBoPb+KdUXDYmRu6QKNJUiWJ4qyNV0JXimh3h75en//0CKAgPzOhJeU6IQYf47oo3p9QxVTRpT4BjEsotennee8hLFgnQfoH9/oehbzAzhbnzO+kTEhQJlTp5IrMSmV98R2hoeAYx+eVpPdUCBMj94zfdRPyeRuvNo11kB5lz2uMUBdHwBHIIrBK2mwk/Z0fykj6zWrpBtk2/nd9BKBhDdLxdiP646r11TXrdzifI0kIJPE0b8doPjPKHzVNnM7SsuYfsT6G+RxJ0AtSSAy2jjLB/f+tsgY9+g6jaSVRsnlwU/zqJQM4l1kYMXoI9YMFK1VE2GW8V7ax/+0IJAhAjEASfTQ28Sq8KUc5JrwxvbameU/IIFv1m9q9/rIePUupbRLXwj2OKAPq3BCalWUloo4GbZukKY31F+IcUvpaDH4SqZ+YnK9Z30LJzFi17wurpJvH8/gFiQJ0Lo6AI5BFYCxtGaST7cfyy5X5s8hkpzjIv9dKNwvScYbr8T2q5zAtnpGBCUW0zzH0MXGaOWZpWcvWjGuahyU7ZJNYOvBSFNEclo0xz+8I74EdJoYu8GAlLpgdOvIFikK65jnnODYJkMSyR1pa5k4yNOFKeI1cHIGqCBASw0ZI9MixafAJi7HHsxqV2zqv5ENcbY30QLvfwxg0D2FXn5ws2IrwGBMmxO+laE1pSCN5XqyDnKEmq9djIMRq4XEesMKxUUkRvh0aBirSxOJ5riUU0Q3S2ZzL0eQk71pj+EGOwEIgQM5DkE6zG99hK8U0lQux3rYXsUa6cZCOMTz/FjZMwGt7+Db6HwIDU0ycRtnM0rKWYcJOFXzxJPeVGUc88Hj4xVjosj77+B0PaxhjCEmID3FeMYhQogj96kNYE/iyQ4pikc6TkDJyUtJk1j7i7HPqNwLkLcFIBpsQ1xeKLexp6bVW5/1DxtIO3PPH0g/nBAGbASjjGBEQoVCrJq6F3C9Cg9iRxyjHmEpDuD5lbamR0rSkuUnMBw/uEZaj1PRYT7F1bDdLx0E61IwHErldHAFHoAgBLOwgnWkK7xGENBW19c+LEYCCNUjHGo4n9piStXgR+d9EBqZZGDjye27u029IgmklS8taNgIPUxSI7csaGY/8IsTAEof8ZKsREQupRQWDnUqKI1HRFwxT5WICPLW+xliBChKvEZ6tNNmbOXFeSHjl3FSpbltrEn7QUiJAyA5exGMTBTv+Duq8viVIH7X7Pl69PsjLk7WRv1YkYIEnhoTqbChT0THTfE5tnCymeEPbkEfZWDMZQUEa2bnE0HRxBByBMgTG0gOCdBY/mrF0grMwlaG18XdrpIckHpx/rJbuuHGrQX9CWA81BSbxdc9jkeRkwBFOeM40+RnE2xIPPSlGdl8L9ZnH2toak3heduiICY9c+elDHuOCGOVVkmCmYjeTc0+BvDIvTXa+JHFjJGC04OmBOx+aXMKn0vF4z7lgTBS7aYtTZcf1vx2BSQi8OOcazF6TVf7+TpC+yLNz1fo6MdPcgybNse736Y4/eQ5FQpVu1tgWEyD3CkKpUhzBvQ2BWYtxXjRL50HaxYyHXWfpx491BJYGgbF05yD92X44Z4+kxy3N4mdY6Eh6bkLHenSQ/nOG7vp8aGRg6ptnKtKywqoyjauZEAOSJct25titR5Hus9dl1msGilPCHghtQrFPcyTSh358j5KPIUkCKoWyfqH14RqEgBxteQp4MrLxzvH4+Mr38MrDdgMzzLwrd8+Kox8/HAS4h3GNxmtxltczd5B+tKV02RXXG+KE3s1TyGWKxvkkj+l3DIM2N7tem8EZgos2BGIFziMGUW0ZS+9DBxqtZ3Kr3Y8f6AgsFQIr0o2CdIgZEBePpNcPjGK0s/N1gHSleKMxvPbbXfqPziYwn4H6xsCU0rLGxOkqyOBtwF3/5gksShRWIvHwelU6XZA2hCyRB0EC4vslfdXoLicZFUUKGOFksD19W9JHrSI0TDjOZrIgF8zAlkHIHNdi0fVa+/MrrDeYJ9VTaBsu7m1xDXj6ioTfH79NNlDaEu4lkFhExqs4rzYqOFMck/4vr71RZ1Ej6U32PIcW2sURcASqIrAiXW0s7Wk/IMKYDoBBqOrxy9BujXTrpFYGGH1ht/X0n4u+fB4GB1mc+jThK23gkqVljYnTJDhPEuLs4XInpIbCQkXMQ1SfZXfcZX24Eju2hEGgoOCtwGPATh+hAoRB8eB+hBkf7GbeokJxKsfWEegKATZ3WjEcUFyvJs2LbSnFDzraqKQTLlgkRBbQ7t1FDWb8HCNtT2N8IwQozonXNqpwsxFE3/eZZd4U+TPdh5wrF0fAEZgGASjLxtIbk3CcM0bri+9M081Cth1JLwrSOXaDOXe0nj9/IddasKjIwESYy7wEwyWPlrWo4nQ6z80lXWhUjfQDC9G90wbJe5hBKLzm4gg4AsNGAOKHbPx9qtDO/P420jd7ABFKL2vBq0Dl7SKJ1bO3Lmow4+d4PciZ4h67VcZ4IGSx6eKO3PtZ9w1nmXeQnmPP9kNm6cePdQSWGoG10l2DdFT0QgRpD+hIlxEUKyDzzQSLn6+R4NJfRpk3AxN5Cnm0rHkVp7PnB3pSPA9R2B2DZSgrUJzibn9I9gv/2xFwBAaFALlLFC1DmcXzQNFBQumgbS2rhzCVQfEAaZc5o0KdhhheOIk2Fo/qujoVLcz5g5K+nPHoooyneDbNZvRjC0WdaTlB2s6e8eRwuTgCjkBdBHaXrhqkTwTpUvtRnY1XYp9mC8rUnV7rx62Wrh6kdwXpPFv/JUF675KEKZXhCwMTeQNdMzBRKfXcElrWtOJ0dv7QfjLnlGHppebFyLYlHIe2bdOWZsf1vx0BR6A7BCC4IL49VWxrvX/C+rop3c1845HwIsS5E75UJmdZnYuyNnW+g1UN2ucrZw5+QTI35khxzqboYRmLZ8LMIaZJ2NJ+mfn7n46AI1AHgbH0iCD9Ltl5P3Y0Y3JSnXl0dYxVm9zOqGsvs3UfsXa6WgJdTXde4+ABgHWnKwYmaBBJ8HtHyYLLEqd5oGZ35ChOxoMnayR8yR6CJUP5V46AI7AgCFBI7bCMghsV8UqvL5i/8fCeZP4UhCsSogdYE0XbmhRyn/AwwOCWFQwF8stSLHfKNqr5N2Gn9Ese20xi4do87z1heiYk/WBHIEGA3faRtGOQTo9GxEj6SZCesCisTCvSFUfS04P0i7jGIJ00ll64KGtMTmkTbyMDU94Do4n+0z4iLWtRgjNtixKnMQ4wdGBoyspfJT0w8yGfvSrzmf/pCDgCi4sAYT8xZyBVciu9f1MDyuuM0BKOxVxPnFCPBbYj2jVJK/tUqw5//ZI1fDpjPLBpc5OS9lW/wtvBeqhHM5NEBkWnap0JRj/YEchHYJV0PSum8s9EwcYr8WLCnPKP6venFp70yiAdl6zpPP4kCQAAIABJREFUwpH0oVF54lm/F9b+7HAZw8BE7kCbDEwpLeukVeUlTkM9Sl2CvDmOMt4MmIJ4GG0xaSD/3hFwBBYKAQobEu/O73+qfztLKMfzEjZNSJJmzuR2lAmsaLSD3rQJgbmJEM8ybwfjwISUxZR79axysOWnzZyEHaRP2fPfi8TNelb8eEegCAEShoP0+SBdkCjcJ42k94zWUzoWHdqbz6mmjYGQVIjGZXkuxtFqCWYel8kItM3AFGlZnzl5Kuta8JCiUFKs9orB8GtJOxQcv72kA5PvXm3FzpKP/K0j4AgsAQKEYNYKX9pdItRxXhKLpKGcT9qBj5WloVqeVR4p6YKKXgzuwxSuSw0IEtZnyZuDDpr+8LrMLCNpjC6DB2JSZ7i/obO6kdZXhmXHiWS6+5kbG6YNCtrAXU3568ea2/uJkjhZT7PXR0uqwi8+aT7+vSMwOATG0g0xGIJ0amJEoIT/Kkhv3kO6VZ8WhWEzkt6ZyeGgquTfme+KV7utc7oiA9O2dQ4uOYYHTh4ta8kh675KE6e5P5OgV+QVi/St0dig8uoXJw3g3zsCjsBCIfBCU4RT5bbS+6tKPO9g/JmXED7KXKsUtSQ3gbaz0rSiH59nrE14PqrIxzLGA/MgnBQjoI7AlEcfbPjMLEE6zHSY5xV1BpVUNnmDCcR/8NDiuvqWpCCJWFtOzr6Sjiqg9+pDgZCi9frnjkDrCOwmbRKkl1oeRGRn4qbKv8PG0gdH0uO6rsS8Il2f5O6x9LEg/Tpj4MCetN9Ieu7KxkmzrWO2YAO0wcBURMs6Cbo0cRrmjLIka/o6ThIVpYl7Jha3aSNo0nz9e0fAEZgPAng22aCI+t/Ur5uuf8ZB/TovQQFn3lXqE7zS2t5/hsmiXGM4MOZJGVrWom4pHLdXAc5Ha/pNO6p548kgXGtm0g4jSVlXw2ltce2fdWsjVhdecJT+9GLBcsMNXyYkefBQ+23m2LrWU9lY/p0jMDgEgnSLIL1hLB2ZUdYxJC7h85H0SZT2sXTf8eTfXCUM8IKskR4YpO1H0mdG0m9yxmcOh5D8vax1KyqBWa9RkwxMk2hZy2YYE6dJ5OMhN+mejqcB7nE8zdR3mNS+bGz/zhFwBIaBAKGQKP3ogNR/uZskPJUwAVEHIdUNC9/fcr3xcNlqifowXQv3yTi3KsU7o+eBkKNpBC8wkTnkVMTx4uv/lnh2ocOFqnVSdW8Kdr5lCiOCDR7Gb4Q1ymo5rdvsrJrnSLxrBIBXWDaqCm5wvBLxeBJRhiJcCC6OQOsI7CFtEaTXjqVvBOmUAmWeH+1pptQTd7grnoogvdUYnjAGngnrUZBeHaS3Wa7CrhSvM3fjmUV9E5I0lvYM0iv7FkbV+gnofoDPS/pFAWVf1dlUoWWd1BfJeGzwcI+eJM+2uNkP2NwntffvHQFHYLgIoOTHXXCUVjYZUiE6Jep1E1+3kC7i2TOWYDLqWvCqxjmyIT5JyImgPaH3VQSPATSoeBjiOLyy0Z4aWOSZpQU32aD/rqQTJP1J0rFGWgHd9v+TdITll+At4XlBXhpVwGnLfbhMmNORttFDyOzMEqRH2TlkvpUESyoFpIrbJ9vxjtZHk9RX2TGa/pudNjcgmkbV+ytFANcgOQdjaQfo0IJ0eJDOKlL6a34OlezPg/TFsfT8IN2mdFL+ZdMINMHAVIWWddK8SQjk3l4lHw1vMu5vHkjvn9Sxf+8IOAKDRYBcVQwG7g1f1cbegndndMJUP8x9f2fpZHtWUXSya/mlzZc1ldFYx3nhcWAdeCCqCqFdt5Z0Q8sTztbF4Z5PLQdeu5DtkvPXyHi2Kckm5verdggvbXpBQDtYR/aQxL8hCEnilDF3cQR6gQDu3pF0f8KYgvRu2I7G0peC9JUgfZdkNKu98KOR9B3zIuwOtRrJz2Pp2SPpPk2FP/UClGFPIjIwvavGMqahZS3rfmfLbXtuWaPkuz/YThahSy6OgCOwWAhwTyI0CX2PUKU8ViJynthQvoMR55D/eqGk3YyONNUVL3+/lXSUGQ9d64Ao9HEeeHyrCGFEHPOhKo172AavNLkO6LCNMSJSGM7O4SSvxwaQwFEbT0DdstTwA79ig177+weWN0mBLo6AI+AItIVAHQamaWlZi+bOBgmkGB+V9NOiRpnP2XHCDY8C4eIIOAKLg8CTk7CbbxjDZtnq2MH/iemFMbyH2PqoJ27wepv1m1zsWp/ScTHRNyRzghG0irA2DKKhVlGOjE1V8juq4KEDpCsFaV3Y80h6WKWDrNHfkxNA1n2ZdOWWKZvDLN9BS0tMmRsPs6DoxzoCjkAVBCIDE7t5k6QuLWtev6+1HIaYOF0ldOkAMzjy+vPPHAFHYHgIXFfS2PQ7YvIJd6kiMY+AWH+ETQ0UbuhYY4J1ZBu6bBPprUFaVzR1NFvdAhuu8gt5Ahgy5OpOo5sSnnlM5VH605CcEggtmHuk1p55dkaygvF33j5Tbh6lhSvg+C4SdrMayewuGqDlzzEcSEzhYqOwh4sj4Ag4Am0jEBmYJlUArUvLmp0/D9Hjk4TAvIrT2WP4G7pDkgBROFwcAUdg2AgQ/hg3hveWRF5TFSHpmHAlasVELyRFw9CbtrGkYPSnOydsnS8I0o8IexmvZwyqMs6sbSiuFj0gsBRNI7vYsRhFQxHOH/d1wpVgmGpMLFQa44EE76mEWNd4EqCTKhKKw03dedIZ7iJKeMNBzj8u0mmsJxJS4CKHY/dNFiYFSwB5G2XCjt6LrepqXCc/DvqBQoviKHwP9VX64CRG8PbJP0Kz8oR2t0vacQwcvFnhMxQIivGxdhJ3rpNpRD/Mix1LMuonyTUNE7L8YUxh7KqJ4LSDIYsbA/U8SJR8VHL8NOdm0jz9e0dgmRGYxMA0Cy1rFlfuAzB7xPtHtuJ0tj1/E+PMvZEdrSGx5uWtxT9zBJYZgf9I6ETPkPT8KcBgg/iPpqCipyDoXacZcxs6A3/jzUAIcUGXeiLMgGY8/NC+m/Ul3r+K+olMn2fVoJZ+ut3vqDY9BEH3PNzm/JKmJxykQzl3IwnK2akE6qioVBMPlyco/jAxfTPvywqfkWfABfhls14fKImYLXa74Bouk00kEefFD4ELm4QOTj6vWGHslu1akGnPvKsWQMEddA+bCLt3sA4w54gNcYN58hxJqQFG+2xVYbweYMd8Y3+8xvgyaG8/kynAR3hV1riI47Mj8GlJZ1sBKAqesCvwNTtPKANlgpFCIUCwwYAiiYiKix8xBYLEpzVlHfh3joAjUBkB7ieQUXwlMc7jwRjp3IMnFXKL7Se9QgH48kyjtOJ05qt1f8KYh+v/45I+ldfAP3MEHIHeI0CNBqg20S0o6jvJ25ldEM98jmVzNwrv+WyH+IExDsU/qW78oCDd3RJuL1kr3Sx+WeOVJGhyb2FPQrfKE/SpGDb1+rwGEz5jwxmjZwg6Droe55Jz8LkJ65r6a6jbg7SuqO1Ympr2NVJdMTm4f7OCYoniy/dQe00jUFpFF1GexYTSC0UgD1UU/aygVPPQZWz+Zd01GCHxu7XZg+1vLOVbWgEUDCDa43ZjRw4lmx8YFnfejv2Hk/7Lqq5yLNy9cS5FJwGqrxgzSNunWHERLo4DDQfmFvvBw5IVzsdhlgCVNw4sAsQnUsMjT8CDioYoC+CblVhEZZ7l5rNz8r8dgaEjgIcSjwCbEqk0Qcsa+8Mzy/2FDZdUUADKEqcJa/iSJOhdiSN2cQQcgeEggP7yBdMb2ImfhoY0rjLWP+BeEIXdfzZG/1GgK8R26/SIoMtZl94Wv6jxyqZo1H8YO09i0jCbIlna1Lz2eZ+hc2GAkBfWV2FtnA/wIDpkkjdm6nUE6b1m9OHZmFp+npwsYuQwIEaS9jFXFcp9PJlFCnreoCjU7IRzbJnRERV0qhpmJXKV00eRO2x/GwN2kUlCH/TFj6GKkHgY1z6J8jCeZNpHD0beGClrAT9ydvpSw4oQqjhmdhcQQ+dE+z6Pao3x2OX8nRkQd8+ZADsF9E+4UpH8SNJRRV/6546AI1ALATYr8KDG325TtKxxMuSsvSf+kbyWJU7zgIJxDw8wIQ/syLHJ4eIIOAL9R+ARRt3JM/0Hkm5RY8ocw30J3SKtEk20Bf3m6WYbDTOWXmOK6B+pabRRg2ofsMkR9Z+8SBc2nGGFIyokG+FRbYT1rQgPZ5yXTXNQh23R44gEYo7oz3mh8DNNZ0W64lg6gXM2rolDerJg3GBHnmQUHmwAiwspnsxpEqajksqx7PwXCeEytOGhlWUlIdwpjp2tghj7I2QptiEHoEzYsactO4BV5JVJ35OseVxKcR4PKOk8Ws20xeDAwMoKY3EusiwpeAM4DoOvTKK3h4qF2YuOkCT6KKPlfazdkMrG8O8cAUdgegQiAxOvuOYnhW1WHYEYZcIiixT/osRp7r+EbEalgXtLmZe16ny8nSPgCLSHAHHwhDrzLMf4R1ero7AT8RH1CsKeUoGulXtKvDek3230fkW6fvhXtem69WLwWrAm/mVDOQm3JtSd+yY66ixCuCh95elIs/TbxLHMLW68U2Mjq8M1MQaujMeYsXf+7us3jqbu9+DkZBV5Fog942TiGqsiuM3Z3ecYTk6ZROOBttndcKwvHnq49osAZLeNY/nHxVUmhOvQDqquKsIPMvadxgHmHRs9KLQnfKBI0h8H4UVVrWeSmeNcJlWBjcYD7e+WmQjnOPZDCEVeYjQ3IYpMuTgCjkDzCJCYRnhiXpho3dG4T5YVSipKnOaeS55EFMIeeWC5OAKOQD8RQDE/zp7jhDsTylxX3m79RFrW2A/3C/SEz8YPqrxaYVOSb2NSdZXD0jboeRD3MDbKPbonm7EwKmEk4V2ZZb3pWDGfY5qk8vT4Nt5vZmHp5PKSi9aajKW9zHgg0qiW8OCIymRZJxQRqpqwEd1d9FtmcECVFS8U2nJhTCN4NNKwqsgQUNRHpKWtGs+fhhBBpVgmFGSKOGIQFUla2KRs9z97fORrZozsDkFsi9K/lbkg41yyJeNTg4g2uCoJzyIXwsURcATaR4B7CbHJ5Jtl8xPqjM59FGNkiwkH5yVO4439YHIcxZYmbfgkzf2tI+AIdIQAz2g2BvEUUquKyIg63oY4XQwE9CfyNbP5j+ShMs6ke0rsa93rWHqEKaQXB+k2G3w53R8Up0MfxfsByyf6FTmuTQrJyOQSsPHSB2EjF9yJSMEz3ZqQHB2kSzhX1HmoOxCx7VHRJGmuSMhqr2o8pKFEPCT/bCw+JONRawHXOGxCjMsFygVMEZOy3Ih0XmTbY4myi56yKU3yPJxiYxISVEVIOo7Y5CUvp31guce2xOUVSZpHMc0O30lJ/7xn5+G3xscMniS8RHYorFa8GiRFYwClwg0oVo+M8+UVbDBsmlBm0vH8vSPgCPwLgUjL+qASBqZ/ta72Dk9kGc127AUWpjRxmiRu7hWpp5T7AzHFszCmxPH81RFwBJpBgPsF4dY8q9n8hJVoFiHEm/4IS8puurKzTxh5lXvKRnMYST+ZdUd7o079g0YRiB6iUB6+PnFMdpmiElnmJSC8JlKLTur0W0mf75WEK4ZY3OtZdjsPKKy+PIalor7JNCcWn7LiJPdE6rA012BSCFCk98KLUkVIko7YTEoaSg2mbO5GOlaaC5JlXknbpe/BKs6DV4wTioYQi0htCtgWUPpJfqyyE0ECJYZi6rWJ/eMqxFvReGZ/uiB/7wgsIQLsLKW0rEUMTNNAQ+wzGy8PqXBQNnEaymvuidxfUmFzoYgmMW3n7x0BR6BdBLhnQKHMJiuKPl7LJp7NkbjlFTnTjxuhZREUOYet/yhIW5vxcMkeU3ouCjv1LxpDIEh3ifSsa6X7zdIxXoGoOH5xlo6SYyOrEf1OyhVIDst9y4+HxJkYcrSnpJsnLeOFzljp50mTy99iTdOuarE7iohEbIgFLpPUiMlSyqbH8WONfWYTgtJ26Xt4ieMxvDZVGZEdBuKk2WlM++c9Rp+LI+AINIdAHi1rloFp2tFeZTGyVY9LE6fZLMq7F7KpUeaFrjqWt3MEHIH6CKDYUbiR5/HPKuR0Vh0JQgT6hFEzK9SWIregFnVn7CxI+2NAjNbX9oof+2sPEBhL3zDjLu/8TzXDSP3JxUT8VxOSeh4o5lZX2BHj4cbcCMPJ2w1Dqed7/pUp1VjrsV1VdxzVVuMxxBqWSayFQfu8+gvxWEIHYp9vjh9OeMWjEI/htYwKdkJXuV+TO0LBFHY30nEmFZvL7cw/dAQcgY0QKKNljQxMZR7LjTo0zy3hi9OwI6WJ02zI5FUVZceRTSUXR8AR6B4B8g8gYCGkkFwmQsanidIom3GkZSX0OY+Z7Y2mA8xUfXkk3d8U1EtHszMjla3Hv5sCgbH0ADsvl1HYb4pDc5vGOHmUxqo5B7kdJR/C1BOVUMKM6gqJfLGfPPca/VILIbYhPKpI+EHGdhSeqyKwGsRjykK66CvSwNK+LFEo9TyQY1BVIrsC/W9X9aBMO+IcKUxXJCRLptcDydUujoAjMBsCbGpMomUlnJE6O9NUhSXsiNyxIia6olmTOB2VhCwdNMdwryREYlIYaFH//rkj4AjUQ+DeVsSV5/yhVsi2Xk8bH4UBQg0n+s5LyIXdkjzJ461e1MY9TPFJkPYxRfVXu62vPzXF0d60aQT2ka4SpKM5JzAtNdF/WtG46o78pHFTpRsLlxyHOkKxMy505lj0gEypRzcvGYTjseTpD3aBKsIOP+35V0RjSz+EFaU4ltW1IGYx9knSd1VJKy+uqnpQph1MTOwoFmFJc5ic4vzqlH7PDOl/OgJLjQA5SJA64NmbJIQQEi5QlbQA5aIOnR/eTzYjyG8qEopvTqptU3Ssf+4IOALTIUCUBcQHhFYTZUFUQlPehjiTt9qzPVt8Nn4fKflfFz+Y5XW1tHmQzjEDgrFd5ojASHqPnYszR9NtUuXOmmTbqCjyWjWROLez5EMemNRSiH1XTQxOE4HYgYvHs2uXlwhMex6AsV3eLloyrcurM5NgWKZAx2PIoYh9Q6tYJHhaqHAd22ZrK6THoZDHdpOSsNPjYJKKxg+vZWPE41I8+ez2NvYkz0XML6F6pYsj4AjUR4DNgj8aqcGkXtj5wyuKBzjvfpceD/sK9zESpqcVEqdRUvIquMa+eNjX5WqPffirI+AITEaA8BGYKNEL2DyYpMdM7nHjFng0imhZY2t0NtgxuT80IiNpR1NYLxiv1z8a6dc7mQ6BsXTnWMBvJL1kuqPzW5PYGxVZXknKaUqIrY278bjAedgVCeE0hAURFxyFh2Iag5/HRfsRc6/HNcANXCaxkiLtYW7KCrkFqfAAJ3ko9p+nTFMhlkqPzD+2ozJ2kZCIHNsR1ziNpMcSJoXHo0i4AaGIpLuYeGYYG2OsLD8EbxEKT12PUdGc/HNHYJkQiLSs0zBaRAam90wACsW/bj4ZRgokCXhEigRGN8KoXBwBR6AdBPgdsrGKUs/vEQKVKpua084G/eoPpo8VGSbQNaMbfGzazsva7yRdIUg/MwPix/xd1t6/ax6BFemKQfq5nYMDL5u8MVVpElysUZHlFWUdC7Up2UbSqTYGPxBc7LAnReGHQpgMcbt5OQVp9Wi8IpHbGKWZSs3EbVEhNa5hUjjP85K2VMBmB57deOo58CDN25F/V3IMFaoxUHAnQpPKDw2KVv4m5CDOg2PyBGMkTaxmTZN2GNN+aEuxlGhUEYKEUZX2AW0rLk92EJ6YHmyUuXGOGFIoKllhfexKltWqyB7jfzsCjsCGCGRpWTf8tvyvyMDExkSecM9iYwa65jryYLuHQHmd3o/TvlBs2Dhx0oQUFX/vCDSDABsLRDPwPOa1jKFx1hFhTmMcisoVCboWz30SqhuVkXSHIF2I8kroTKOde2cTERhLO5vhcN6af+nQE4/La4DlR7IMSiwXS1Qm4yvxdnzH7nkTMXc84NJCbhgRuObwcsAxTojMs/Mmasoucb1xboTr4FrjOOIDecChIKffY1CQaJ1n4eJZ+EbSPh7HQ7LohwUGVPyLbXlFMac+RspyklLGotxjyERPBsr9M5KbRdoXvO+PLFh/0cfsEpyQzImQKcrUUzQOjPA45DE+4Y6kDfUrqGTIGohrZjeCm9c7bY6Ug3dxBByB+ghAy4qBXvceGhmY8jZzPmv3l7qzw4OJwpJXcTrtE4WC/AgXR8ARaAYBNkzfbp4GdCE8D+gxbQmkCugb/JbTTcZ0PHQF2nw5/bDJ92PpFabAXjreeFOzyaG8rwSBkfR0wx3DbeYcNhRIFGUqD0PHhfJNOA4KLLvO7M7zPV6JSXUTkmmWvuWi5QIlIecTkqiszA+IcfOU/LQzjkVZho2EHXV+DP+RNrAKicRxsR4eunkUZPEQxnuqeQ1Q+CmIlrcDH9vHV3br8JzAQMT77Lz5G6pFwrX4l2VNgYEpfpe+3rOmq5IdQ7wD8Lzj9aCQDLSLt40TLnhNdxrJecGQIPwBbMEu/b6gC//YEXAEShAoo2UtOWyjr/IYmPB4EgZaFH6wUSc5H7AhQ8hktuJ0tin5WU0x8GX77vPfPHOosA1lLc9J6MCpL8QmGBW6Idwg4Zzwz3PNu44X+ChJh0j6gaSv2bOOOkew2OE1byMkpc84+tw2RIDf7C9MUSfHYWaqzA273+gv9DfyoopoWeMBMeR6WqroeHyl15G0xhTZM9dI5HC6tIjAaumOScI6dchcHAFHwBFwBHqKQBVa1mmmHhmYYv4RIZH7TtNBpi0bBngn2bhhIwnlt8gQgW2OsNOiHctM14P983qSnmAhoT/P5NGlXuJZ37PTjKeZzTM2ujBQXBYfAbyPbM4R1UG0B1ET2aruTaPAZiYRCFyzefmdcbwbWQgkFK6tyop0tSAdgQExkn7zBYlcDJcWENhd+o8g/d6MtUOgaW1hGO/SEXAEHAFHoAEEULLZna5Cy1p1OEIaIgMTBsQppvhXPT7bjnBUPBfUckDSitP20eUvKCDsXLYZj335YB2+wQOApx36a7wIMYcsaxxgOOFJoHgqIZ145F9gnmty9QjvhPWOhPjouceTi7cBtqovSvphhhEwOwYeDEJc8ain5BYdwuFDtYjAFlavgfNOzmSru/vJOqCBZ8xJxW0Jm6IdxnPrsla6ZZBONaX2oN38mm8cc4yyJEn9pCZoWRufpHfoCDgCjoAjcDkC09CyXn5QhTfsjB9rccvkfM0iuK8xcKIQQomBUBSuSI4Y6xq6YAg9xJjxCDfKKvEwS62Y4o+Cd52GF4zhR52d55tRAftNdg54gfaQ9KTEuGt4Gt5dRwhwvRH2B7EBnj7CBKPB3vYUuH7xchEaVTYmxiqbEcfkhGG3NseR9LAgXWAGxPd8V7w5qFdLVx9LPzRsz1m7fmOjuQG8J0fAEXAEHIFGEWB3HuXvvo32+q/O7mhKCOxuswix+a/NdFCWOE1OVVPFQzPDdvInYRkw8qX1gFDaOVckiMK0Rz7aPAQyEUg3oPqG/S81JiDBwNBj59plWAiQd0huDOcTxXwaquZZVwrFfaRlvfOEzsjfZI7kfXYqI+lxSd2Bb3sF6tnht7Cw/c1wOH8sUazZxRFwBBwBR6CnCLBrTyw7JBNtCbvR7BLCDJfHwFRlXJIUURbYAU+lLHGafAgU2bqsUek4Xb6HYpZEUOLMo1IOl/63JEGBG3NIupxT2ViEUpFYTQgTbH5xzoRUMWdIOlz6jQDeBkgOYIPkvEHlXuTRa2slhCFy7WD0lwlzxbDhnjKXcLmR9KQg/dOU3a+u/Iudsmze/l0OAmY47GtYXjhefy/JaekfOQKOgCPgCPQFgVlpWaus4yeSXmfKCSE2dZJticU/MScBuixxmjwOdsXrGixV1tZkG4qRQq2d5jFg2MHGR7L4EIRQExgBY8JrNCRI5iZnZdET2IdwjrJzhE2LpGPOFTv/eUVts8c0/TfXBuN/t8I1EinuyXmYm4ylpwXpYlN6D1wZzm90bphlBx5LNwzSIYbhRaGj/JXsPPxvR8ARcAQcgeoINEXLWjYioVDsRqPkIzAwHVFj95z6PUXJ3CT3fsr6z76QC/DG7Ic9+xvl7evJjj1K1H5GPz1kZRvGq7UWw54aEV6Lpx8XINfWKywMDoOVBOV5eLXYTCB3CUOfUL1JgqFDPkYZrf2kPhr5PkhPDdL5pvweE+YXRtjIerrsZCxtGaQ/GXbnuuHQJfo+liPQUwRgolgj3XgP6bZrpLsF6UFBegw32zXS44O09Ui65x7SFmulm0HP1tOlLOq0mqZlLcKJWgsfSb6MDEwUxKyqGHMMBgi1dvKkLHGaXfs0yTrv+Hl9hkFFMmoankQuw6IxRMHZTy2fdJ0YdbecF/A+rjaXdIAZrLBmURdkHkIIEkViMS4fV2ECJFTTlrC+XgiJvUE62ZTgU8cepjfxvIylRwTpDMPsRHSBiQd5A0fAEVgcBDAOqLo5kl4fpM8F6aAg/c1uCpdN+XpmkH4+ksZB2ilIz1or3cMT0hq/XlDam6ZlzZskO+rsEGYLdkYGJqpFVxHCKFAYMHiKhKrTUI1mhVwJEoz/PfvFnP/eLpNoDK1ql8mp81g+1wMF6KIXAtpdcm28AF13Z4PfPgb12XYeSHgnUXleQg0Jrgeoh6sIxjXtKdzbG9lDulWQfmfPuwtH0v9eVn1zpDfraHsiO0lXGEtvTPJFjoICt+1xvX9HwBGYIwL88NdIW42lVwTpK0E6qaJxcF6Q/hGkY4P0qyDh3sXAODtIl1boA5fmfkF6Bx4LEqzmCMMiDE019z9KulbLi0EhGBeMQVLwGVZwrKDJ5R8T2wyrUpmUJU7/dU5x3HnzhUY1KkAoQcdLevYUXpi8Pof2Gbvc0PZGI+LgObJGDQ27WeaLEf99wx3mMootzlPYbYaWlermVe7pKJkUqvvOPCddNDY5D0E6MHme7Y9XvahvBh0iAAAgAElEQVT9sn2OkZBQsbKx+P2Vf4WzLhscvl5HYLEROEC6UpAeNZa+FKTTkhtj9Cqg/FMNcp8gfSJI/0N7dmIIRVqZwHTD7syKdI1V0mZj6QFj6flj6X1jac+xdGTCqR3H4/XCIMHO8Dy/+Ux9/bVNyxonhHeBHX8KkRUJxcpgYCLsqEzYlU9Dn/LaliVOkyvRJptU3nzyPnuYGQtRaca4mgtbTN7kOv6McBWM2BjKxHXw4o7nsEzDvTBhwiLvqO2Ng0nY4u34vXkmJ9Gyxr5ggOK38/D4Qd9eed4F6W3JzvrpY+kZfZtn1/MZSc8NEpEFPL8vwvvAZmTX8/DxHAFHoEUEUOjXSA8cSZ82j0GquF80kg4O0ofH0jah+YJUG6yMIjwYFSPpTSPpO8kNKM7pgrG0F8wX7pHYALq8P7qgZY3jvk3S/vGPklfoIcsYmNipp1DVo0r6iF8VJU5TWRn2n3kJYTk7JyxKrPcx85pMz8ZFcaRSdjSooHZtushdz5bc6XRuajv14HuCUep2OoGCwfitMqcdC77PfszmAHlPsxaazPbbyt9Bupd52Nc9p0bSl5fRC2Hehr2STcejyYFsBXTv1BFwBOaDAEnOI+nlQfpD8mPn5kd40YjiOLSZz+zWj8rODslVGC9B+ktmnuxsfHgZb9IVz0kXtKxM5SqSTppCQaagWBED01Nsd7JKWENR4jThDuxwV+mjIpSVm7HDS35JVI6J+d+08tHL0ZDr5aOJcXW0tC6hdzlW394qn2ehgVx7X1J/SCmg8mVOVWhZIzpQPXNMEWlCbNebV6uY/NnkGUX47rvxtPdmki1NZCRdK0gfyEQO7OIbfC0B7t06AvNAYEW60Uh6T5BOTW50FwTpa33e0Y8ekiDtmvGQULwn+A7HBldTF7SscUBCJIhjnoZNCcaVPAam3ST9IHZc4bUocZocj67DHYgxj7vqFHnbocL8l7kJ5+dUUxIxPodSn6Nv5wxiATw4KNtUJ6/CYtTVGvCEnDYFLSvzgm2N3CByl3g/KKFacpB+GZ+tI+nvI+kFixi2w+beWNohkw95OJEMgzppPllHwBEoRmAsbWqhSRgKMQyIJOi3rZKIWR+MkJsxlp5teRJxLbx+Pywe9eW056UrWlbmhcHAzjGhQtNIEQMTNJKvn6KjosRpqB3fN0U/sza9u4VjocDBYf/QWTtckuNva7Hw4Ea14/9eknU3tcxnmXIOfqOeFRckxj3Sw24zxYJZE+vpe72WwiUlSjXEIfH59Pux9LJ5e/MLJz3FF3hZgvTKIP0xrm+RjaQpoPGmjsDiIAD1aZBeHaTT4w+d+Ex2DHaXqBA7aBlJjwzSD5K1XTKWPrtausGgF1Zv8l3RssbZsctJTD+hKNNKloHpNqY03HWKjooSp1FAfjZFP7M0hcWGZHEUnmMl3X6WzpbwWAzJWPGY4mVUF3cpR4CCaZEGl0rsVGHum6D885vYdcqJHW7ECoPPhYHgYyztHCRCmKIRcQrhTFRbnhKXuTenlhMEJxkylXNG0vu/IF1z7hP0CTgCjkAzCJC3kPBRc/Miv+Gpi+hCXSvdNUjfS27SZ46l1630j/O/mZOb30tXtKxxdMKP4G6vKzAwoXiTv/Ayy52oGv4Ux8xLnL6J0UK2/UDDPR8NB4yV68dJ+etUCGB8BlM2MSAIhXPJR+Dpkk4xrPZQP73GVBsndK8qLWtcKbS+GByfjB8switef6MeTz0RRAB8dSQ9pc+5AZYb+fQgfd2YD6MRdOJYeguUtYtwjnwNjoAjsJ5s/4ZB2nsZFekcgwl38X2X4MLoipY1QomCAOXmrDuEMDCxe7qvKZCx/6qvRYnTv5X02Kqd1GhH9VsYYVB2qF3QtqFSY4qDOoQwF2h2wRPGLbxHLv9CAMN0T8PnZEkkIvdRri7pGCM+2GrKCe5ttR3+c8rjBtEcIyFILzW686iE83pWkFYH6TF9KJLKhps9R0OQzkn0COb625H0IpgRBwG6T9IRcASqIWA/+rjDsZQhPDmhWhez80MsajUUB9eqS1rWCA67nk3tEJKjQEGouknGeYnThEtAmdqGYKiRCIqi+4seMdu0sdYu++T3uWK4cj08ucvBezwWuSD/MFy+qn6HZFJXgt8FmwLTyBbGwPWVaQ4aYls8/2PpEWPpC5kQIJTzWCR1J5Kvu8iRsByGhwfpXWPpgEyYFXM6hVDgkfQwr6Q9xCvO5+wIlCDAroYlRPNj59+flp31gGJ0aSjTSPrJ6sWkheyKljVegZEOdfP4wYyvDzaFg2qy04YtMXRe4jS0r8RPNy2wKsEOhIIEu9KgyAaaBqOF/mDY+YbhS+jLg1oYYyhdcm1RtZ1rDWaqvhcgw8hhrngRp/0dQ+HMsZOKSA7l3FWaZ9zlH0lrzAMRn9/x9aIgHRKk3QkTghERZkHoUSsNkDQiByNIdw/StkF6qxWDPTQpchfH5PUMvh9Jj+6DNyRZhr91BByBphBYI906SEcl7sXVdW4uTc2nT/2wUxKkVwXpfMPnzLXthrN0vfwuaVnj2j5uO8Tx71lf32msTSQc12FJykucpr4Cu9dNxuRCMICnASWHuQ4u6XHWE9XR8YRE7Gc4Y6hB+blswu8aMgKuNYypG/UcgEjLSkgVjG/TCOQW50v6yTQHLVpblPS10v2oyBykfXKKpKbKPe+pyfQ3K1B3eJAOsnDlvcfSD4PEZ8fAhJQTfpTt64yR9O2R9PqRdB83GBbt6vL1OAIZBPAu4FY0xZjaDX2Nhc3MvNs/x9KWQTrCcLoEg6LbGbQyWpe0rHEB/yHpbEnE/DclJBt/TFJkYHp2jY7zEqcJZ3pSjb6KDlltyhxJ0lRLdmkPAXbdqdeB8nxoTUav9mbXXs/kEMXrjNC47dobqrGeyVehwjznCqNnWmHzgGM9TC1BjjBbPAVQvI6ljwXpW0E6OpO4nDUCJv19wUj6TZC+GaSPjqSXQDayiCQqCZT+1hFwBFIEqHWQ3EiO3kO6Vfq9v98QAahpg7SSeGh2pWbEhq0G81fXtKwRGCgYodZsSjBG8BDAvISkDEz2UaWXvMRpDJJPVTp6cqNXmoKDkrPt5ObeogEESLiNbFYYh4suj7HiaFxjJA/DGjYEeYP9NgifnFbI18JbgScPI8RlAgIo+mulW46kewZp6zXS40fSM4P04rH0Gv7Z+2eMpW1oY21v4UbCBHD9a0dg0REI0k6JErzf7hJKmMsEBAhjgpc6wW7fgYZ4dU3LCrL/bsrNEybAPM3X7DZeKGmT5KAdjYGJ/IJpJJs4zS7or6fpoKAtbF3/NAXpwwVt/ON2EHhaYrQtKoUrYXcYRxgNZ0h6fjtQttIrBRLJTfmNJAyBaQWSBNbt9T2mRc7bOwKOgCMwDQIj6UOJ8vs5j0+cBr31bYO0fZBIRrvMEqmhGByKdE3LGnF5rqTf1UiGjMfnvX7GQh6y35FAeaSkac5LNnEapQyvxiy5CRhM8NWj4BCasaiMXVn8+/T3hwz/MyVt1qeJNTCXR0r6i63vuwPL7+C3yf0A45970rSC9xRKZcKzpvmdTzuOt3cEHAFHYLkRgE4tMRzeutxozLZ66PISWrr9B1Jxex60rBHoX81Apxr7yL4SrkAoVFZg3aEIHZV0qzK35CVOEy8/S5hRjMempsUtspP0vztBAAOOnW0MOJKHF0GoC7KbrYl6IS8a4KIiQ9Jras59G1t/HZKEmkP6YY6AI+AILBkCQXpzYjjstGTLb2W5I+mRQaLaJ4lm+wygInXXtKwR90cZ1zyMQ00JOToohHcr6JCk2WkZmLKJ0x80Ja1giNKP72ghGcxxERLsSxfb8y/vb3UAOBeEMg1ZHirpT3bt/2CgRinhhpyL701h3GfPGZsDeC2mZWfK9uN/OwKOgCPgCOQhYElQ65gUxhIKkUtDCEDdGhPPx9JePQ4DI9eAmGjqLHQt35f0joYHfaklS5Z5FqZlYMomTmP0/L7GvEnepHI0ChJsUJ7MWQPEhg/BcOZ8UJG8SQrehqdZ2B2hOZ82IwhPFtd/2bVf2NGcvyB0jLoTdWhZ49TJleBcfil+4K+OgCPgCDgCDSIAm0KQLrXd8U802LV3ZQiMpScmxXJ26SEw86BljTDAenOeJGonNCl7SVpbocPIwETichVJE6dR2EjovFmVA5M2JK2i3LAzumXyub+dHwIUxvqrnZeh3QcphIgXjWuKHfemCix2fTYwdmINjlmIE2LxO6c87voM+niOgCPw/9k7D6hZimptv796DVdFzFlMBFEwYc6YFa+KETHngBkD5gwmDFwDqMTp7+AxiznhVVEBI6hgBEVEkoqCkoR/PVKlRZ+Z6Z7p3PPutc6Z+XqqKzzd07OraofxEzhQ2ixJFrPe6eGbu+bBifpfuzsTCefgvgg/2JgHHNBRh2h3mTCM87qL4/EikWUWicCUd5z+lqTHzutM7jP8LY4Jip6jK+XgdPznjuG6nDkQ52KiiDHROS+EnSXk7xB3G+Jlf3HgT6CDZYUoakQv45lmMQETMAETqJPAeukyMXP0mnTk/o5IUSfeqXVl0vvCDs8/Dphtiz/13AYPdhGWNQ6HzLEoapvGAzW93j4oIYtkDy4bgSnvOP26Bc0jnh76RjK8undbasK3stVgPkb4XVbwqyiwbQDET+MXoa/kRrlhG4022Aa+SeziHZULrbxok28LTDAptJiACdREACfBzSXdpqOtzW2CouDQaTVd0GWrWZM+EhTZPx8w/B+eZTG0eh7+DoRuDdyP3U/i+9ildBWWNY6ZlXciHtUt+E8QQWcRiRGYPlli9TZ1nL5rCIdZpq1LSDouKDevL3OCy7RO4CHh+qDI9tH8h6ACKMj/lPQPSUQjGrrPDDsohFXFjO/mFa44pmeE3D2yQh0+1QRMQNJlJD01/EDHHy1WVfi3Q8uE+HHmYRfbx0aTqD59fEC3jKbd5sgQGRTYf07+k3233U6saGsHSFfPpD/AHwfqDjF0GZaVYRNOEtMiVlDrlkMkvXOJSmMEpl0Lzk0dp5kQ8Fwrk4H92eH592c58WIB4s4+xuznh+E69S3zNIt+rMzzG4qjPQuBY5C9wpjYBa0inA+bISXCqzJen2sCtRNAUX+lJGI8R2WdV7bKD5f0xWDTyYNyj7BFyzbtrH9kapwm/PDPOicej45PxDHHmYvEL2mfWG140rTKfax+AvtJ10z8HN5YfwuusYhAJt05OqlPpIcWlW/o867CssbhsGKKAlS3YFaEzfP9l6w4RmB6TMH5qeM0Tp5lYulHxe9VBXX7424JkD2c3ygmhRt325V/tc4EdbeQlBAzP3wDxpJQ8MGBNRHXqvhrXEzSbyWdELLV9+CyuQsmMCwCKOn8sKUK+g8ksb2ef+DwYMyXTc/jPduAs35IcfwkLFz+nPg3IddoNy+Eg5zkztslX8h/108gkw4Kuw5HfU7iR8nSAYFMem+4Dn9c335oyC7DskKbH3oy32IiUrc8KJg/VDGNLBOBKXWcfnmJyE4stPBcZGJTJSt13bxc34YEMAOKuRK4zl0Kpr7RD4OkhExuxyLXkHRK+Mf7KoIlBd8vvosWEzCBBQmwjZmaJ/FDRbznIpvIGOM6Kv3xlZVBzAvmyWa5SUA892MlzmVbOJZnB4K6LA0RWJN2CArreZNmzEUa6vn4qv2QdNlMOi5cj/1aHGGXYVnjMB8VQksWPZdi+UVe3yvp4EVOmFGWCEwnSiJ6yzRJHadx0CY/wDzZJzzrujRVm9c/f3ZhAuwO8duECVMXQubrN4TJJr+NL5uy+NdFv+pqk10GktjBmAl/VfleiDg1xBwdVcfu802gEgGU/F8lyjhfylk7BvmGWIH+fe5czi9rO4gNL+XjP+Is53c58m3y9+XDzkY8jwmHpQEC+0gbZ9LJQVntY66BBkbd7yon0nbhehDC9R4t9JYf7C7DssYhshO6U/yj5leegShadUiMwITv2DSJjtPspGASOmtVGEfOM8Lz8X7TKvKx3hEgdwdOyfw2kXSsTSGQQbQI+L6krdpsvKW2XhTY7llDe+S54DqRJM9iAiawIAHipUclnFd++BaR5+bOp44yKwLxixvbZtUPn4uywoQhnssPrE1pypJboFwmvS4oqr8jTOsCp7pogwQyaV24Loc22EysusuwrLEP24YMskRYqVsIvsCzBFOPOqQoAlPqOP25ORMifMboF6ZaTey21DFW17Ehgc+G61Z3HpINW7rgCPcbkcKI9MQ/dj+YmI5NiKjEbkrVsKyRy6fDRG/o4WrjePxqAq0RwK8gKuC84jTEtvoiwnYfzlhpPWzdzxN2F3DAjufgDM1uwiJCYpt4Pq93X+Rkly0mgE19dJKeSE8sPsMl2iKwTrpuJp3NBIKdiAbb7TosaxwaSjbmGE0ISjo21HUq6EURmKLjNCups3ZOCVDBs83hWZu46s3VGcO2YpJWxZm3TA/ZXWBHjvuEe4rv6xiFRQMmDUweqoRljWww1SZJns0BIxG/msACBMhymirgz1/g3LTogbl6PpV+OOU9CZJiu/xoLzPzf2RSB3URScJSI4GJtGtY3f7VweNcyaqRVvtVTaT3h+vzg4ayfHcdljVCvXGIYNOUwzDK+4djYzW+3iiElZ1mBhodpzFtIUBEXskkLv/fwzOOnQrLcAhgCozfIL9LN22o2+ws4OSLMk1bTDAX2blvqFuNVYuZEjx3rqkFojpSXxMhn2vqoqsxgX4SuFf48vAF4t/JFTI0Yo8b6+EVO14ct6bJfRKbUB58d55WqMQx6knbfEuJc1ykJIH10pUz6fSwsk10LEvPCKyTrp1JZ4VrROjCuqXrsKxxPPgIfDD+UfMru6D4XjUV9pnnFGaVOEenEh2nUS5pP79iHJ/PfFbGDyytu433OIQ/QNIzJb1J0juCz8iTR5RHoApHsjfz+9TEohY+MnHnnohKbftWVOGyzLmYQcMSR+n8JHuZ+sjQzsT8u8uc3KNzri+JhVgWPnD8ZqeLKJa/kcT9x+Ryix71110ZCQF2B1Llm8RrywqrICfl6iPmdV6wLf5TUq6sY3W+Hv4mjXza/74l5pnW58Ecy6S3hlXtn6/vp/IyGJZNdnQivSdcpyNqbqfrsKxxOFcLuw6s4jchrOrzHJkVHamONmdFYIqO02SnJn9FFFaQyQZMv/pmVoHvCb8dOAVjrrouKDCsDHMPxmcymbofFge0gq8x6hIKb13CJJLJCNzPlURSwrH7+tUZljVeh3hthnp/stDA9457ANNGcv6QbJKJFbte7KbsHz7n+4hvhycR8er7tRKBayY3VnzYL2M6lHbi3ckPB3USOSkVTCB+lJSpulPAFyb2ndePpI35/fIEyOOQSaeGFW37OiyPsvEzw+7DuVyrNemONTXYh7CscSgkJPxM/KOBVxSJoxuoN18l2XCxSU+DDkTHaZ6FcYwEknh6MGXiuUbI7L4IK5nxmcsKZz5TMT4jOO7GMrzu3pfOt9wPdpoYP4p+HU7+sCYEOnVi+3/rlsfTRXMowySBY8x17axiDkgo5WN6uqNXxBnzNHhg3cEu3zzBquMPoTymbV3nHpnXV382EAKvCDcUNyH/6ojYwsMs1scrPy7pQzON6sTKVVXnRJTatL19B8K+993MpEeG1ezT9rzwNeyq71eWxIonu1lsYc/6hxkFjqp5YVWGlfT8eTgaEw5z0DKRPhMmD3V8B/jB7kNYVq4JCdvYqZyWMLKua8b2PgsfTUsagSl99v00mBuQVJMVRV5/kTzbNm26YyXrj5Gf4jMXc4lZ8vWk/5TfelbBER9nN/4vgUOVcMrcK+xKkbWa3Z63SkIBXgUhyhv3DxPvugSFmzqJEjkkYYcpC33H0bts6GZ2bP8azmPcTQWdWITlWHNqoEuMMcrZha5tjAXNzVTnF4moSbFOXh8RWn12cpzdh3T17UIdW+CPlyZ10pZzECwAb17RTPpy2HXAqawPwsSUpEs8NNP7K/+eMkwqU7tYVncJdZkvi5JGlBJstgcta9KDwmTvjEn1yVAfwrLG68FzA1vepoSHPStyTUarSvvOxJZ8EiSkw5TpVpK+Fu5N/L9ifoB4r7K62BfBPjz2i9dbzOnY9rmyTfmTzOlCLz6KycyWVVSxBohBTfhtzfvN9GKQDXUihmVlVzBdhKzSHL8LmNPhR1SHDlKlL4ucywQy7sDw3WO3dBGJ0b/i95edzS6FUMb4nYxNMCNkkXO0gm1vvIni6yY1jfaVubqx5cX+jtjTtIVDT122xTH6QhzDol+omoY8rmpCCNDzUEbX1Rf3vi5I7EDwQ4yiFa97fJ03eeRHY5fkHFZNRxOZhEhYE+mEMIF4agXYrHzj3Hu7CnXUdSr23Tj+EVWtKWE3imdTm4rEo8Mq8i+T+zHew/nXw5oa+BL1Hpf0l52RdIKer47oWOlYMHdaRdkjcFg0oRlsCUXOd5EJJc7omP2uisSwrHw3501SF+URA7u8edETOy4fE+Pxnfr1kuZWcSJLHZjS1ZXTZlE0+GTw+73xoicOoDwTXcxORyvYvaUPdrbN6xK8/9O6uUnJHcExtl3rDDkYY6DH9qo4X9c1/sHXk0mvDkooq/h9FVbgYhjLeP25j+dFpSEPCGVHmU00CauLXfQygnKCLTU2630QnBmPbXgbmAnn/7U8WKLQ8d2K9+28V5we+yLRyZT+FuXxuUpufLv1ZRAt9yP+1n5jgXYJKhLNvtilutMC546lKFHeuM9QmuuUr4bFAnw+hyI3Ccp+fE4su1N+m9x3sg5T9WUY7hj6Uddu0jJ9aOIc8q1wjerUcZvoZ6U6ccyLNyKvVR2X8505JFd/bOtR+YIV/07tgmmjil1pxa6M5/RMOpzJw1r9D+66IWEKEe+t+DpvO5atUsIajnIFbyJtFSZ9560ttyXcl7Cs8T7hx61ISY1ll33lGYL/V5tCiFbMluI9O++V3bK+CBNzzB8IPVsk7Dan43pX0Qkj/TwuWJDLqEjYbcA5Hl9BzDPZtcDnZ9UEvzbuHRT9ebtbi3LBDIp68b0cksSJJH3H1LbK7xcmW+n3Eh/BNoUdyegH1OZub9NjxBw1muyP1rSQHwBuwPQGulvNZHkApvXzfp5z3TLNM2slTFnaTl3mUMv0ZxTnoHRm0j/D5GEITo6T3D2AY9h1p1wMVgPY+RrCmKZ0v9yhTDqeazf5j69RuRMvcCbnoT6NXdk66izHaiv9YYu7KWGsPD/aiFqDErSTpC/knBfT59e09zj4D01w5k1NJBjX24c2iJr6S5jReF3n2XhjNhyZEQWo7t/kmobTeDUxyhtJE+veHYi/Ffl8Ko0PqkIDODvH+4fXGJFt2SoJx19nfYv0gwWF1Pdw8IFKwuAJaIF5aeQ62p1C7AfjIHnF9qzuyA1Etknb4P20nA+L3Hj5sthkp23gWFjnKkW+vZX4O4myRHi3IQirF3HGH+8HVmrSaDZMNCmDDfGoJZP2CbsPiyRUiz/Yde8MVmFNNLam7ZKfEsKhpvdKlT4XnYvySACC/KJHvG+nvdZp713Uv6qf8/xlJRNfDjJ2p+PBkXAVBSYxyMOsOPvchzEaDvfHmFZkF7nmsCLKG/cNDvd1yrWCuRK7GUOSd+a+RwSzqCIx8WT8buJTk+p/7GoQ5IYd/PjvqjMaRKcjAlssx+u0SEPstHJfx+9BbJtQ/phlMqnj/QcksTuE8BwhwtaB4VlCnop8ZnEiNuGzhsVJ0SIT99b9c30l0eI0Idx5flzTGOAziS8Xi5JxTLyyQJSOa78FImNN609vjj0/N1DCFNYp7GzkfREAur7ORkKEnPSC9cmxsOahtlddVD7XpDpCfrbVcTL05r/A6UMWu3ZMlkYvyeTvtyUHG3+w+7SVv1mw8a175TGPhLwwbeWGSSco7H4dnHsOp8+y9D0+ZH0XdnBY0cQ/hfj5O0jiO5mO47V9H0SD/Ys7/dicp4JCi6IBJ76v90w/XMH3hKOFBUpk3YJpNnWXDW9ad/vL1nd87ntU9R5B4U6/l7xPzWz4PUAhxyk7liNXxDRhxxalP40QN80JGuWZwBfsJKcTCBauTw5t4QOG7xnPDYSwtEyqOS/2I+66kDSUyFOE8Gbyw+f0ATNX/ENmCQvOqUk9kfymCYvf6AyYD8a2pzlBY+7KQgm7ZCkDFofoG89DkmaiY9c9GZ7W78aPfSIBAhgSMNUpQI/A01eUuzq3qVhZTesfkrJbJ+9a64pmL2sXKAC11t1wZax6pPcDjvrYV/KwxWEfB87Ry37SFaPZ2YESSniR9Cksa+wrq1T84DQpKPM84PmBakN4PhF5jt2v+AOH/wAmKul9m38/LWdJG/0taoNVN/rPQhEKAeFuiQjEKiPCVn46llWNtgSLaKqRKn4E94i23/yW1fnbeMEVGNb/mBKhTLJDXLefB6vSsCagBsrxUAQO6XeI9zjlVpX8ziff47ykkSzT+zZfjr9TBZ9d7HkSTccYSxmHaX6fIoOPh4kOExbMubiWBJ/ATCgmH0bhj+kBpvUjBjCgznSBcVpZntex7XtPK5AcS6NhjdZhOkY+Kgsl4VP4Nr0wxM9nJhjb4bXOaEjfz9XdtGNl4eCHXmB/6SrB5AVn6WnbdH0fIluc6f3GA4Uf7jIOnn0fW+n+ZdIPw3V8bMFJfQrLGrtKKF6iaDXtmxITWtYVojr2f9brtUNG2Hh/skK/Luygvi23yhXL8Nq3cMJMDt6URNCjj9jq500A2DVKx/HiWWBW4DhBGmDxUEn4QMSAJb9ftWfTjGuNqQyOvIRlveWMMlUOoxvAvygbc5U2mjiXZ2D6HeI9u1VVhUWTtF4W3vLCdzyWKcqBE/OQUJ5IYfMkLl4zgSkjmNLGfrDQQk6c1Mwq1sGOR7qrgHnWNCHsd6zvZdMKJMeIyhjLshszT1JfEhYtRyfT8jtcvqZRcrHijJatKNpKE8NxEeqyNzqfmfYAACAASURBVOQHlVWKeGF5He1sr6brU1jNmnSXoHRy/YYorN4R2jC9L3jYrJRMpAO4joRunTNwVn0Iy9q33Cg8hFnNblrYcibSUptCFuv03kzfo0jm710mUX0SJgSpfxG7DbPCRvK7ko5vlRd3olJDdDjMGODCTtQ0E48+Xe+2+hIjjzUxwcSMGqWTyTqmMEOSfGhV7pu4a1llHHHHK34/CZ2aFwLcxM+LTG4+nJRlR2CeRJN2+lBGCBwQ+8HrfeechE9RNIsi38K0hRd2WWJ9RaaU7JbGskW5hsj6HsuOMnAPcdPjAHllu6kO4YaJNyQ/KHcNlWKbltqC8b4OO+ZpTt9DezDUwb3WOibS01E616RFYpLX2ocaKuPewGQpvc+LVk5qaLY/VWTSy8IkkG3XWdK3sKz0kxVIJq5F2+SzxrTIce5xTCzbFJwA0/uy6D1ZcPsimHlhuxv7zI/0vB9ydpBiWV5HH6xgzoWKmYFZTCP77Eo9j+Zw4aP4nWCRJ/ULKjit9McPD/dh3xZJygxgWuCZqFuVOX9WmbjIG7+f0zIipzld8GGaJ5iYxrqiz8Ks8nGXgoSTZYREdrFufAiK7hECbcTy+NDkheh18fN5i2ucF31wKP+YfEW5v+MEmLJ1Lcjnmuj2T7bHIzhe63AWxCY3XTHL/0jkHQPzHvPLEMnvaCybFGuZtkd7zkR6d1ixxuZ8yILjVXqfE2O9ju3eQTBZkx4UJg+zVtbZgmWy35ewrJEr2+c/jn80+IoNNCYSdUeAY/KDgzPROlBayIROxCic0THtYTUsvS+L3vdp5yFdsaPfRdG88j4PTawqN3iL1Fr1t8N1f2KttQ6/MhYXWSxoIixrpIPpNN+jeWFyY9m+vWIimH9G8FypIuhr+TqnLehi0hPLPa6gwdSPIW++mD81JsfkWVhG0skDE4MiSRfIeebmhYl7HNfu+Q9zf/PMimWLJlDsJMay+GGMTvKKfNUERGwLpYraNCfHvCMrduhVJd0m44LhqGepSCCTvhyUzvwEsGLNrZ7OFiwrFB9NvszcI9ynbGGPXnCUDtfx3M9tuFXfx7CsXBNWlJjsFK3w1HH9WO1kh7QovF9sa9akgHB8/EBhr80uAfcZgSHY0WWFjcUZkqO9VBL+J4QKjD8wZV+nbb3HfrX5Gu30Y7+LHAiJThLL8oo52qpK9HmY5pi6qkxwdo0mLE1xYRLPvccu61AlH1ABX4QqEpMWxu/mrMWalyTf36cWNJj6GrJoME94xtM234kykk4eyixq4jMTx4Z/b17wf4yfF+08ox/HskX3KM/6WLZodyTfp0H8zQpsHCCvRT8ARYP6UFLf4TMcWdi+zm+TVbXbIwdBOo4im7yicfhzSZl0XFA6q94XXfFkJYtVLB4QrNowiUjvkyIbx676XWu766WLZtI5XMvJhR1Z+cEmjnqfwrLGsbOdjN1/G8oymXsxwUknBaxYxZ2COCkgOkuZSQFxxnGSK9quJuJXej+Wed+XFVNCEqb9LVISUrMHziNU5qoKJhowaMMcbyiMY8j4oh2sKuPBORfzujJR56q00+S5e+e+d1X9RlOFmHtyVvLeNMpR0WJiulBXFIAiRh4ru4icTgbKLEDwvEyfU4SmTYVndfy86N57ZVK2aJf6oFCW+210wopjhBZfUeyXlTQ0Fc5IRBOZJdHmM7a726yCJY5jFhDr4ZWLlb9BSlTjInkCmXR6UDhvlf9sIH9j458qxmS0TCeu+NxUtRnFGeoNIYEND0C2YYma06tkXpl0Ktdy7QITmnj5+hiWNfaNlXqeKXXItEkBz5w4KSDYQswLEncKcGrN7xSg7JWZFJTtc1wJTZ9fRe+xe+6DMJFK+zor9jt9Zds+dazmPBSMRYQFAL5nTHZZHeXaFP2AL1J/m2VjArg2Mpm3Oa5l28IuHr+0JsKyxj4xueV5X8bUJZ7Tx1cWRtPvHfdSlZXtNBMyiXVnhTBnwhDbZRdinqS7kkQTmyd/DPV+b16h5DMiAsZ+sINbJDx7Ynle8zouv//xc0K+zpM04lRRxMa4i8aO9ugkn1mQGeCywkM8OkKjvM8KixXrJyJHvGC8kvhkWRMSwq2ldaG8WSoSeI10kbDrcP4B0uYVq+vidMyVTpKUj4ufhlCL994yq7lkzmQ1FfOnGGub3Q1Wq/kO8I/V615IJh0TJoLRqbWPYVkjKyKl8aMIz3kSJwVMCuNOQTopmLZTkJ8UxBVPQgAW7RTM68syn+XDS6fPsfx77ieO9WVSygQ57SMOgrOEyCP5yQaRvcoI9teYmRCZiBVjrjmJvbCNp30mIVWUpzJ9qLMMfY3XclaG6Trb63tdXE/uDXyOMElpSmKYzXmT3KbarrNe7h/MItPvHuaPywjfp7SeWbsO1I1/TixbtGOfPteKfltjmFgsVcoIv7WxH68vccINk/JMUPPPitQMip2pebJPUhfmXvPk66Es9/XoBCUnXgRelw2HyKoBM9ZYF+nTiwTlIJaPr8tmeky3yKiryOmlqG/+/IL88BvFycO6C2KRD4lLNFdCIcwLk9QYKjHee2R1zT9U8ufl/yZpDhPVac5Q0ZeoNyFuM+mIsPOAg11fw7JGxiT/YQt52qSAXcsykwJ8CsrsFLD4gCnSsosXsc+LvnK/McFFOSZoBE6c8X6c9hojhvVltR22UQmmvywe5b9vTMawS2ZVkQh8+XEV7Wg+OMRx5/uclxiVhzrLrEDmz+/qb3bkI4f8wkZXfeqy3ajUF61mV+kjnMk8XFZBrdJWG+emTsDcS8uGH2dXPt6L/JYxkZsl5CSJZVkMmCdYnsSyRQtAMWszZpBlBAfsWPfbS5zAcyqW53c+L2kghyIdOLWYIRHdPIlBEWh7Htd5dfT2szQOLQNcxomILalov0kd7F6UCZF6mdwPD+d+bAlSrP6eltwc1BNXVpeozqdEAvtJ14yThw+VdySNp3f5ilLGQwIFfpawGpFX1jCJKCskN+ReI739NNkpuSfbXs2e1h9NpEPC9WQFt6uwrCTzwcwwTgrYCo87BXFSEEM8oyzjaBx3CsiJEB2N46SgDvNEgi0sakIzlXHFg6wepso491f6j100/m5SyVp0CESOSvvIe1bc8CHhec6zGVMA8hfwrMb/KC2PwkC+B+6DvLkEJl2YNMxSsPHXifVhejEUicoM13PVJUa64Vm96OLNIuzI4cJ9VxSbf5E6uy6b931YdEcS34FoLYLva1GkvXjfwnGeYzE7O+l3HF1vnkR/Vb7LZQQriFh/GYfpODnlnGmRqUh+G+vD722WUC7NJXb7WQXD8c8n9Y4usmN+23lR+2Iik6TbU1yAohlpyjv+GMYLh21YkdNdej7v8zcqs9gyk5d8Pf47R2BN2iIom+edf0Ha91yJ3v4ZFRoedvMERTTee7yiuLHSWUZ4MHCvzfrBi8m/yKreC5lIn+d6bn/Bin7dYVmZFJBJdN6kIG5P530K8pOCrEVlnuvHj9bTOr5ITKjY3k7vx/z76DMwLYJdl90naRMrn/H60m+UfvqZjxdP5CyixfAjzPMf0yV8W5i4XzoZBIoMnxeFcz0yMGOSMhSJYcUxd1xlYTeJa8x906RyhT5AlJ3fhgnsWJjzzP1u8sxgIp6fgM8aK7sBMeABEweSzxVJunOI2RST97ywC48DdxoRqsg5nd2g+Ps7z082tpXuFHw6Hpzxyj0WfdmYGEzrM78BcVeX3/RZC1JM1lJzMXZi5kkaPGhZq5p59Xf6GSEF0x+ootBTaWdZSSKXQno+78v+CKce82kdi64Asm2Vno+5g6UGAmvSjcPkAQfjIQgrm9GhqcwWKMpK3DKN9xBKzSNKDJYfImzyo6kL9zMhiBGO0T7cehP1ayJ95j3S+Re/YMx585LQ9Q1eZk0KUAzjTkFUGnkA86NRZaeABzfXZNFVtA06XvIAZjNceyY+XQlmS/EHLt6H015jQraxmF7M481uBfcT998s4Uc/fn/LxoifVVebx+NKaJlV0zb71WZbKHHsDnOfFylhVfsVbfWnJQirWnfX5/MbRlCQ+LxgsWrWTl3sK8/YaI/P87qsPyNR79Ld+rz5JN9VzKA4niZmK1KcP5D0P+/DQJv534J0EsO4Z0WCZNIY2fxaEjsHsyRdBGeXKhXuVfwkiUqVZtkuSmuQWh/Qj3TiwvtBB0tIbbK4CGwTlxFCKGJOEG/Y9JWYvdiizhJuBnwtYniu9Nz4npXHMjsQ/HjgaB3P47Uoecmsfvl4jsB+0nXC5OH8PS+wkc+V6MWf3AOsmpA2/ojkXmAXgVjUs5RCwsfldx7ifcRWLhFdnjLnQRyzRzJ5fXQoH+0ayTGCfW2vtsgn0je2ks7f5ILVqnRSwI93NB+KkwJibhdNCviu1Wk+xA3FdVzWfneZG5LER2UmmsvUXeYcVgpTf7F4D057RaHmOOXTH6Iy7QypDN9pfIWm7dqlq5ipEkFc+aEIK7NcR75zqyrR35LV2aaFZxk7Uxs13VBH9fN9IWpeDCHNK6aN8fcodotdARKbkcAXKw98U1kEXkT4TY3PJn4fCLeMwzG+WyxuxIlCDFNKWUwY4yLbtLbwmY118spzjoU4fN7YMSKUaipbJ+VZwCOcd97KgN99fkfQA/BNLLr26L4woX0WLbgvMUtC1/2cJCYCCDuksa/4R8wzyaJN+hfL871n15HEzOi/sc5Q9bBeeDjHgfHKRSkSbsCi7XVWZWdJ3swobT99/4xZFSTH2RJPz+EBkW59J0X9dlECmXT5OHlYmz9rX7TqOsvjaIqint4H6Xs+y2cwx1k/zYCelk/fc58zGZ62ksMqBrsc/DARgYEyPMQxmWIruczkt04OhXW9QTrq4tL5F/sPr1k7BU1MCgr7F8wNMXeJP0BlzqlahhW4eVGCqtY/73x8YaLNfnrfzXqf/nCVXS2c135fP4vRUQjFmgqmXalfHr4SkVUZs4u0rq7es3jG7xT9zpt0ddWntttFz+DZw7O16d/rmAAMhW3swo4C0f8IToDSzO8XZjaY9rBQzKSC3z0U/ipRvvjd4/rF7x67f/hApCZHrw67qZTjHxMCfh9nCbtDqT8BdbMYOC1qZxodiQkQkw8WvTB/5HlOLifOZRcEk8qyQh/ighntM5lgUYL6o2CVwIQgjovf+nmJRQkDm8+lho8wQToGLfmIM0XJPPo22DRsFheb7WBLTQQOli4WJw9ZD5XhmoZZVzWsQLBVyyoIDrhsfTZpx7twvzPp1y+Xzn+SRJjkWXadC9db4wk4chNFqa1VdRQXfmBZXWpbuF/YSucHigkEO6jpD3L8YU5fWY0jjwjHBr1qVQCbBSp2V9IdIVYusTmOO4nwixFd8N0bisS8Hpip5VeGhzKGKv1kx5MFF753TYZljX3EtJLvWKrYxs/G/EouA/iyEIMZESYydTJgVR1TXRYxmBDXISzA0V8iSTHBnPU7QJCS+FzMh4zl2VHF55X7k1CwtF/X95NnFZMITIUxk6WPg5d0a4mLUefN1TQcojzlf2xjrP2m216Z+jPpH0wgDtjQ7nBlGJQYKN8bIsuwdcvqCuYURH9h1+PxJc5vpUgmncS1XJPu0kqDizXCDwUTB1Z/2hKiG6FYFIUSrLs//CgRXYaV9fx2PmY5KFasHMYfyPjKqherhvw99ERXRUwJs4v54PqQKBDn4jSsKyubcMBUoq4f+aI+1fE5yg79xixyFYUVasbfRmhdFEDaYtXbMh4CqfXKGP1YBnGlyK7Klyv+I2nUUMSO0i1cqUw6EYVzIhUlRGmhN71tgkkDeRNSwQ+C7xVbsZ1PaomWlUlnhZ2kPn7PUeSxb62yapTyL/P+XcG5u0zZusqwSocN7WdnrNjFhJdErcNWN4ZS5F7CrpfvIe/ZOidAwJiFFcY3hhW79PvFaic7E5jdtj3xq8o7BhnBRn3VhO84927TYVkjV0xZaI8Vcst4COADwXXlH7vVlg4IEAYvXgReZ3mtd9C1uU0SnSRG2aDf/MCSOMRSM4FM+laYPMRIQjW3MNrqCBEXv1tEauhU1knXDROH83uaswPnNpyX2xTChLKC3Zawy8BuA8oT2+PThEAUROmKn2ObHG2BmfQxuYo+PmUDXExrZ6jHMJfgun2mhBNk38bIRIdry3Oh8wWFluHgI4aZGTblbZhzYpnADh428JZxESCcevxtbTpS17jI1TgafoziReC1cyWn5Nhi+K3Yd1YQLQ0QyKQPBKXTjBfji6NXvD9ZQe5UJtJ9w3XEWatvwsogiwFt+mGgwHB9ZiX5q5sRZlmshOJghw3sNGGiQJ+IypEKuw2YMbFogrBzQTkcF1dJmDjg+ElQgnnOl31lQoIqrhtJsVZJuPfjPduWsrdrYD0v8uMqXYMxjZWAHnyP+NeFv9qYWC49Fr7UaXZovPT7LmnsXG4eHAjbNHXoO59a+5dJzw9K56ra6E7jeZMSMZpjvgnuURJjdSpr0gvCdSS8XN8Em2QSxbUp+FaQKC/vc9BUHwjmwLNqXrZxrg33C7baeXlW4mgXs5vjZN1W//P9aftvuOH3gDngLOn7hCLmNVi1hRhC0nJf4/DehhAIgR0Ocn+g41jGRSDeT9xT854H4xp1D0eDYsNFiP86V3RmMOKHgZsmdSQkJFeMvjHjNB+uQmBNuk+PV6yrDG3Zcx8YviuYysWV4Gl1/TiUI6rK1acVaPNYsoNEaLs+yXVC4APCcLYpROhpK6EkK+UoMvOyvxKBA+fteWGuIx+Uoxg/fBVWVrk3WLyYZ7uOD8EiYRkjy7ZeiWQY/VemTQ7b6kfb7WCeRWATImfN2nGru08xg3fZhLV1t+/6miWQJmorE9K/2d6scO3MzGPSGiYQ2Neyut+ncFJE2SB6TZzg8IrdK4qHpUECmbRJmDz01Va+wdFPrXr3cB9idx7t0vMFUejivdqLlZGJdAjXca18Bvj8mJr6G575eP5NtRXr5ZlHErI2/HheGbJuz5to0q+4U0UY3TISs7KOPeoSiZqItX6lGVBwQCcrLeE/+ywxytIqZAeP14Hn45FhUpxGyoqfN/HKThwhkE+a83xuol3X2R6Bzye/ryRktXRIgC85WZ2jwsMrCUUI5cqPVNtRPViZIbvgJ8IPb9ovVjFIljRLcesQ4/iaDlF6/oLiid38+Ea48IhQZnB6JPHLtOQwxNeO2dexu+1c1kuXyqQzwzVs60e8zLhxIGUFve0EX6xg80y5QZlOVihDEjNMi8rsqpDr4e8LtAUzxsC9iHPoGIUsxDi9ooBi8pX++3kuoVOfky6xax7Ng1dpNRxTRO7RNgMhPCS0ORT/zTF+b5saE89RdhjTEP08HwiHbtP1pqiXrBfnE5yRuSBRYWe7vW0hS2Jsn1d+VEloR0zfadl+2+7fSrW3Jn087D70zeSlq+uAwxY7D6SwT3e/mFhgrkTm1N5ELktMz059Tb8cTYn2Rpz+toUY86xONikos0SXIedHkcQsuITOXkRYbef5yDb+mASzLHaj0t+Aee/7vsq8fRgLzwycvldBSPbFNSPaUZu+KDjUYyo6z0RwFfiPbYwEtiCXEglY8ZHjWUkG6Y+GyGt72b+lH5ecBxy2isTTvVMHXbpD8KInygj9aHvno4Mh97dJTF3CqjWp7i0XECD0IEobu2PYzvNAI4EXWSR7tQqSSbtz/dbaNw+ad69gbkI2bnxI2hbCwr6/wUZ3CFmjb16yDVbU8eWaZZozq5qnBgXttJYjVc3qT13HSbpIhnYml88Pq42830USZmCsKmOqhKkX5kDb1dVwA/VgIndEuE7vbaD+PlaJ4s7EGeuFNhPPsnjDhAVF0mICJmACJtAlgf2l64Wdh/PXtftj0OWwR9N2Jv00XD+Uzb4IGYQxPWk7GgrJxvDrYjW4CWEyhNJUNgQsihYTBxKeLSpMwI4JClMvTOQWHcAKlCcrOAotphZt5DfoA1ISIDLmh7XcGVam+S6V2e1ruWtuzgRMwARWkEAm/SIooM7oOKDrP5GuFSd+TAJ71HXMu7qw/8ZvBz+BjRtgQQZowr9uu0Ddk6BokRdkGSHkLIoaeTJsqrEMwebOwXkXs1+uT9uhiJsb1fyaY6SjfeYXq/1T7OGJZkXyQIsJmIAJmEAfCGTSHkEJdb6HPlyQkn1I8jvgh9EXQcnuyk6d6BzfaQAE2Z7ZcVjUhAb7bJzvlxVMOgmDiYLqyCPLUmzmvJjMCp+9zsM1NzPEC9VK/hvu5zbDssYO7BG+A30O1xv76lcTMAETWA0CmXTrMHk4b5103dUY9fBHGU2W1iSCEPRFSIb26o4689NgJ19n80RvIikVGYQXERK/ofQTPa6KEA6YesgTcdMqFfnc2giQ1O6EcF3eVlut/a2I6If4dnAP3rrlbsKanbdlTP9a7qqbMwETMIEVI5BJR4QJxNiiu4zySq6Tbh+u1z975KtCGGZWYhd1Dq7jGpFrASWbgAx1yY1DzgiyPi8qJIRD2aoaEAK/EaJWMTbyCKxK1ulFebdZnlDjXA9C9RKSeOxC1mzG+/IOBoojPW3v2EHbbtIETMAETGAegUx6blBGj+tZyM953V7ZzzJpb67XRCKpTl9kP0nv66gzxAMnMlFVZT12/4aS/iAJO+9FhUkUCs8XFj1xRvktkvjnO88o48PtELhrcNzl+hL+fOyCHxGOyv/XclhWuJLMlu8geTQIIGAxARMwARPoE4H10hVisrFMIo63pacEJtJGmXQ6k4c1icRJfRBW/ok6s2lHnSGcLnls6hDye7BzwKrnMkK4WJTLzZY5ecY5hDelTnZ2mk6AN6MLK38Y8x38i7gOxKAfu+Ck/8fg75PmvGlr3NGv5EVtNeh2TMAETMAEFiSQSVnYfWCVydJTAhNpl3Cd/rhnf1bk3hzyYnRBDdMenLSfWUPjVwsKInkGlhEUTCI+1Z2ojpXXmFMAM6a6dliWGeOqnkMiTSYOOM9zn4xdiG7EeBf196mLC1HbyFK/CqZhdTFzPSZgAibQLoE16caZ9M+wor1ISMp2O7rCrX1IumwmnRomDyTZ6oNcNoQxrdPfYJFxkbANJafqrscVJB1ZMfQmDrT0hTCrdcs2ks4O9a9KeNC6GS5bX3Rc59qSx2TsslO4z/btaKBEbYO1o4x1dAHcrAmYgAmUJjCR1oJi+q3SJ7lgawQy6RXh+hy/j8Qqdx+EScx3O+zIS0JCtSpd2Cg4JO9dMbkdq9JnVOlIwblPD0rVqiixBTha+ZiIW4QphXmT2ctbGUyJRggUwHh/JekyJco3UQR/IXbwNmmictdpAiZgAiZQI4EDpc0y6VwU1Im0bHKrGnvkqiKB9dLlMulPXJu1ekx0YtVVXjGfOVbSQ6tUUvHcr0jas0IdZKb+hqQPV3QKJQM1CuaHKvSlzKkfCO2g4KHYWpojgN3/7wLvQ4ITb3OtdV/zJSRhLkSksNt01B1ySvA94vtoMQETMAETGAKBTNonrG4f7shL/blimfTGcF1+u/6CSCR96Nwjg33/RTrqDIo/jtrLTl6I6EJuioNqiOiCyRORaZrIcJ3iRcFjpwcFC8fua6Qf+n1tBC4VJpVwJurPKiSDi34dOOh3Jez+wbztnBJdjdftmoAJmMDwCWTS9TPprKCoPnf4Ixr+CCbSVpl0drgmT+rRiL4nCfvoruQ+kv4piWRSiwq7Jp+Q9FVVNwFDsWTicOiinViyPNGtUGhRso6SxAq5pT4CTCoJgwxfJqe3q6/q3tZ073APswvX1WIAjuhnhdwmvQXljpmACZiACUwhQNbioKie7qzTUwC1eGi9dNFMOixcj2+dLxFdqA9CzPtTJbH635W8fUl/C5SjiaRvS7p0DZ3HxAJF8y411FW2ipjEjnaJxHTFsie63FwCTCoJ+wtXHNS3m1t6HB9eOWTNxmeni7CskSIZ2eGOCaDFBEzABExgSAQIAZpkncasw9IRgTXpBWHicOYB0uYddWNas4Ry5Me+S8FU6PVLdAAfiR/UGAaS1ekTl+hH1VOINIXCh8L1/RZMpqr2t+/nk8E7TgRx2F3WHK7v48z3D7M97qFH5D9o8W8WIViMIJdGVzsfLQ7XTZmACZjACAmsk7ZJnKdJ2GNpmUAwITuDyQP5HVpufl5zNwoRWa46r1DDn2EqhMJzpwXbYbfiZ5KutOB5s4q/MPTjlbMKNHz8tpL+FvqAGdkq2OY3gRQfB5K/cU9hgvaYJhrpYZ3kR2HMZIjvUp4V+vGMLjvhtk3ABEzABCoSmEhvCavef12TtqhYnU9fgMDnpEsk5ko/OLhficE+KIl/XQrx9kkiRQK1svLa4OBdp5Px8cG8pcvVUsylYIESSHSgrcoCcbl/EWASHJ3Q2XF4yopw2TJkLSepIflauhK+O7+UdErHZpBdjd/tmoAJmMB4CKyXLpVJPwwTiKMnEvHwLS0QyKS9A/fTSeDXQpNlm0DRIkwouw9dCj4Ln16gAztLOk7SdRc4p6jorYLCvkg/iupc9nMmDERfYgLBRAJncksxARToYwI3dnDuX3zKKEoQtetHISwru1ddyoMD/2VMELvst9s2ARMwAROYRgCH6ZjVeE36VI8cdqd1dxTHyOMQJg7kdHh4zwaFnwP+Dl0KTuN/XCDSE8nVKF+3z8g3g9JzvS5hJG0Trebw0CdW0B0tLYEz5S0Thb8EXkwsbzalzFgP7R7G3ZW5XcqVpKT4DXVpBpn2x+9NwARMwASqEiBhXCb9E4WWSExV6/P5swmsSXdMwrK+dXbJTj6JTo1EWupSbhoUn81KdALbdcwhOKdOIfsuYWJ/XmelNdTFNfp44MMuxOckMamw/IcAjN6bMMLZvE5Ttv+01M93JADFr4PJL07iXQrJ6LhPm06u2OUY3bYJmIAJrCYBHHbDavh5mYS9uaVmAhNpy0w6KXD+KmFaa26ianU4NeKU27W8KJjoFPVj+xCNqIlsuXsEpedRE6D1awAAIABJREFURZ3o4HNsyFlRJlMwitnJkjANsUjbSDo6mThg/lZHuN6hsCVQwAlhx2WTHnR6fbgWfTLN7AEWd8EETMAERkIgkyZBsT23h+Y0g6Z8oLTZRDoh8P3JWn3RgOrigkL6K0lkle5avizpAwWdwOYfk5SmdklOC1GOCrrR6cdMmrhmTCD4R/beZRLqdTqImhon8Vs6oeLe2KGmuodUDf453At9+B7jf4R5HQn5LCZgAiZgAmMkQMSfTPpoUHDPyZzMp5bLfKB0gzXp94HrL9b308zkIZKOVfdRnwipicP2w+bAJ/oQyuF955Sp8hFto4C9r0olLZ2LedU+yQQCEy7CYfZtV6tJHP8TovnESdTXO06G1uRY59XNdYfB/vMKtfjZO0N/7tFim27KBEzABEygbQIhgdxBQdE9a9Kcgtb20Dppb3/pepn028DzmHXStTvpSHGj35H0/OJijZfAXhtfgyvMaOnWwVSJyU5TclToA4r5UAQTLiZ/UYEmwd7dh9L5JfuJKcyXkjGzW/SCFU1CRnS0v4dQxV2GZY2XcuOwc0fEJ4sJmIAJmMDYCYQcBF8MCu/Za9KTxz7mJsY3kW4VTZXCzsP1m2inhjrvEFby+6B0vE3SYTPGtHVwjm7SJwc7cRTwb8/oQ58PX1LSyyWdnijUn5V05z53eom+oSjjgItJDNeKyeZekq6yRF1jOAWTrb6EZY08XxyuTZPf1diWX03ABEzABPpAIOSA+GyYQJAB+S0O41r+ymTS9pn0r+zRmXTMAfWHES3fmeKSn5D05uJirZT4sSTCxeaFMKyEYyVjbpMCCxTSrmPjVxkjkYX2DRF34k7EocEUbMjmTJirEUaYSEJxXF+VxKRylYWs6vDoS6Q8Ejv+XhIJFhdJ8rjK19BjNwETMIFxECAaUCa9N04g1qSP7ykRBtEyh0Am7RxD306k7+7f7xXRTUMM9mvOGVJbHxFyFCUIJTEVHC+J089qZpOC0/jZkv7QZCMt1n1LSR8LK/NR2Sbb8PMGFHMf0zHC8bIbFcfAK2FIVyXh27xb5p5hMkUuhb5MDB8drtVL53Xcn5mACZiACYyYwER6YVSGM+kHPV9F7+xKfEi67Jq0bzLZ+gg7OJ11qFzDOAXvV65o46VQEskCnK5WsopORKHXNd66tEtQepqepLQwlAs1cUNJ75F0RqKAY/JDVKsnSsI+vU9CduQHSfpwsOOPkwb6/BFJTYTm7dP4y/aFsKxMdAke0IewrLHfPwymc6sa+Sty8KsJmIAJrDaBnBnOGWRJXm0iFx79RLpDJv06ThwyabcBmHmhfKBQ9sXsgygxByVk6d9PJb0jOdbkW+LjnzVih9srSnqFpF8kkwgUc8b8KUnk+dhKEhm+2xb8gR4fzK3+nOsf5mrcA331GWqbVWyPa8b161NIWpz06dO7Yyf9agImYAImsMIE1qQtMun7iYL8uZ6GHW3tKhGdaiK9IZPODVxOYaLVWgeqNYSN9BerVVHr2Sjvzwk1Xk7SD0rke6irA7cPSg9mPqsgmDThnI45WFzZj69/kkS+gJ2Ds/XVawZCJC12Dwgtuhbs42Pb8ZUJxAclEeazL+Y4NWOoVN3Tw3U7oFIt9Z9MxnN2iDzRq5+tazQBEzCBYRIIoVx3S8yYTs6kHQewyl478HXSNpl0eDKZ+uIBUt2KVu39DhUSmeckSdhM90HY/UBx3CJkBD4kKJb4IbQhhKql/b6G0m2KAbsMRGNiInF4EsEoKvHxlQhOOLMzuXqLpJeEnQqi6ZDdmvuICdi2uiA/zI6SUHDJFo4DPJME/BaYmMQ686+EyN1TEnkbiCBkmU6A7whhWX8jaaPpRTo5umXwv/hoJ627URMwARMwgX4TyKQ7J/kLzs+kQ9ddoDz0u+M19G4/6ZqZtH8mnRcmDv/IpOcMbAL11KAM1kCklipeKOl3krB3/4qkT7aYsA4FjHCfmEituhCu996S3iTp/ySdOEfZzyv/i/yNnT6TiXdJImfHqoZZXfR+Y1KFTwGr+7db9OSGy7NTxD0w5EhlDSNy9SZgAiaw4gTWS5fJpDdm0plx9X0ifXidRHSc0QmRpjLpNUkIViZNnyCD9MAGy2rz0SGKTV+6jvkUmZIxlyHxF5OItoTVbpSeoZibtcUltoMJ2a0ksZvwWkmYynCdvhZ2K9gxwPzp1BCe8+eSvh8mH4RWXSdpt+CcfUdPFCLWpV7ZIeJeffVSZzd30lVD1DZ2DC0mYAImYAImMJ8AWZQJ4xonEJl0VibtvSaRAXbwsiZdKZNemUknJmP8yWS4GXwxCyEOexrVqMvrhAkVZhgkZiMEZ9vhgDHJYSXcYgJ9JoD/Bzku+hSWNfIiGpon4JGGX03ABEzABMoRWJO2zaQfJwo2yeU+P1QlO5M2DXku/p6MCR+PnciBUY5KL0t9I9ii96VzMVY9WXLbtuEmPCxKzzv7AsP9MIEpBIiURdK109S/nV3CUZ8siRwibfkoTUHkQyZgAiZgAoMkgN3/RLpvJn0lUbjPX5OOzKSXZP2KR74BY3I1ZNJjmfQkTuGYJ/0ik54xgiR5t5b0V0mYovRFMHFh5wEFqW35ZfB3aHu3o+1xur1hE4iZzx/Vw2HEyE879bBv7pIJmIAJmMCQCGTSzSbSAZl0djKROG8iHcLqfV8yL+8jXXJNekgmfTSTcH5mshD/fXNNetBrxrOitl7S7j26j94YbKW7iAtPdm12HXAMtphAXwk8Ldynkx52EP8pfFyIonXpHvbPXTIBEzABExgigYl0rUx6Rdh9iEo5r/8MeSPeifLe1mQiOD7fLZNeHXZIzkgmC/Trj5n0v5nEKv2Y5HpBUb9OTwZFRmdMMbDjvlsHfcKZl8nDzTto202aQBkChGUlkWPfwrLGvuM/xXeI6FwWEzABEzABE6ifwETaMpNel0k/zynscVJx9Jq0bya9bE16+AHSLSZL2sGvly5OYruJtN1Eel6YEHw7txMS2z1lTdoL/4yB+zPMu2is7hNvvw+CiQNJ4QjRisNy23H9LybpnBAlqA883AcTyBPgO0GiRMKykkOjj8KuHRnKh5Lfpo8M3ScTMAETMIGyBA6UbrQmPS2Tskw6bsZkIir3J2XSUZl0WCZ9bU36FOeh8JNzIUR7+lImfSfscPwu57MQ64mvfw3O3LuQn4Lkd2X7PdBylw9K+i160P8nSDpF0laS9pP02Q769JqwYhozWnfQBTdpAnMJvDXco9yrfZRtQv/27WPn3CcTMAETMIEVIJBJ18+kx69J78ikgzLp6BD2NSr8y7ySyI2JxNcyac+wA3HLEe8uzLpTMBEiLn/X8nBJfw55A+jLHyQ9r4NOkV37zA7adZMmUIbA3YM5H3kT+hrZjfwdmCyRHd5iAiZgAiZgAv0ggKMySecIAzuRHkwkpDXpmRPpxcH86e1r0psm0i5r0rPXpCdk0sPWpPtgIoUzdD9G0mkvMH9ASb9fp72Qtgv5FO4U+nGToHxs2XK/8K9A6UH5sZhA3wikYVnxU+qj4DeF2R8JHS0mYAImYAImYAIjI4CZ0E8lERmlK9k2xKi/d9KBF4RkdcmhVt4eHlZ1yYprMYG+Efh4mNyS0buv8vbQx/T73Ne+ul8mYAImYAImYAILEGDC8BNJT1zgnLqL3i7sODw4V/HnJe2TO9b0n1cIE4cfN92Q6zeBJQg8JSjl2RLntnUKiRzJFXNkWw26HRMwARMwARMwgfYI3DdENbpEe01eqCXCoJ4qKb+KSn8IQbnDhUo3/8feQTm7f/NNuQUTWIjA5uE7cUwHmdYX6ejO4TvEjqbFBEzABEzABExgZAS+KullHY3pRpJwTCbJVV6iQ+iV8x80/DcTFhJaWUygTwSI9kamdcKy3qFPHcv1hRDHvwsLEm2HV851xX+agAmYgAmYgAnUTYBVf3IoYKrTtlw/JIAjj8M02S3EsJ/2WVPHnhxWTN/SVAOu1wSWJPDmcG++dsnz2zrtUaGfL2+rQbdjAiZgAiZgAibQHgHspvdor7l/t3QtSZhevPrfRzZ8Q/IrJhBtCll6Wdn1immb1N1WEQGCCZBl/ds9Dssax8DuCLt3XSxIxD741QRMwARMwARMoAEC1w55DNgBaFOuIuloSW+b0yimSihLKE1tyRZhxfQrbTXodkygBAGU8N+HSGR9Dcsah3HX8B16TzzgVxMwARMwARMwgfEQQHn/SMvDIYv1jyS9v6BdnKRZvWzTiZt49OR2ILeExQT6QuBj4b58dF86NKcfB0n6p6Qbzinjj0zABEzABEzABAZIgFCKp0m6TYt9v4yk70o6QNJFCtolPCthWtsSzJRIaHVsWw26HRMoQSD64KyVKNt1EXbu2C0kB4XFBEzABEzABExgZAQIpfjNFsd0KUkHB8XioiXaxUzj+SXK1VVk17C6+/S6KnQ9JlCRwGYhmAET2stVrKuN0/cM36E+R4Jqg4PbMAETMAETMIHRESDk43GSHtjSyFjV/5ykL5R0RN6yA/Mh8kz8vSUebsYEigjwHf1ecN6/Y1HhHnyOj9I/ws5iD7rjLpiACZiACZiACdRJANvpn0sis3TTwi7DRyX9nyR2H8rI80II1zJl6yhznzBZ2a+OylyHCdRAgChj+N+8roa62qiCqGn092FtNOY2TMAETMAETMAE2iXwwxlJ2eruBZMTFPLDJF12gcrZpdh3gfJVi+LAja32lapW5PNNoAYCdwtOx9+RRMK1vsslQ6JHQi+XMUns+3jcPxMwARMwARMwgYTAPcIPPT/4Tct7JR2xYLx3TJxIWrdj050L9RM2lokDsektJtA1AcKyYlL4V0lth1BeduxPCbsOz122Ap9nAiZgAiZgAibQXwL4HcxLzFZXz8nQjGnUVReskFVXlHmU+jZkEhSfe7bRmNswgQICmPhh/vOYgnJ9+ZjdxaMk/VkS0dQsJmACJmACJmACIyJA/gJyJzRtnvPKEPKUJHSLypskYVbVluDkeXJbjbkdE5hD4Elh4rBuTpm+fXT/0Oc3961j7o8JmIAJmIAJmEB1AuROeF/1aubWQHjVP1RIEkWEGXYt2pBnBcXn9W005jZMYA6BTQcWljUOhfDLZ0u6ZjzgVxMwARMwARMwgXEQuEYIpUjs+KYE22dW8W+8ZAPsiGCyhF9GG/LbkBhuCE6pbfBwG90QICzr4QMKyxop3SJMvkn6aDEBEzABEzABExgZAZKgfbLBMT1K0p8k3bJCG48IuRbacOa+WVB8iOxkMYEuCcQEhUPbAcvCd4jvksUETMAETMAETGBEBHBkxKGxqWRTJJv7i6SqmWU/JOmLLXH/WlB8mtyJaWkobmbABO4awrJ+dyBhWSNq/JnOkfTVeMCvJmACJmACJmAC4yFACEWUkyaEKEWn1WRqRIjKFzbRyVyd7GycK+lXueP+0wTaJHD5AYZljXzeGibf94sH/GoCJmACJmACJjAOAiRtInnTQxsYDjsZ7Dj8Tw11bxGUka1rqKuoireFtp5QVNCfm0CDBD4S7sPHNthGE1WT8JHv/U9bylLfxBhcpwmYgAmYgAmYwAwC+BH8WtJFZny+7OFtgo/DDstWkDvvOZJOyB1r6k9MuEhEZzGBrggwcSWfw4FddaBCu0RUo+9PrlCHTzUBEzABEzABE+gpgcMk7VRz38gXQVSlOpWHz0jav+Z+TqsO/wwUnw9O+9DHTKAFAjeU9DdJRPvauIX26myCncxjJZ0o6RJ1Vuy6TMAETMAETMAEuidwF0mnSvrvGruC4sMOwfNqrJNQlewEtJFV9ychHOzQlLYacbuqDgkQFpgJ/T8l3anDfizbNDuZTL5ftWwFPs8ETMAETMAETKC/BD4t6Q01du86YbX0FTXWSVVMclBIrlZzvfnqrh4mDk05j+fb898mkCfwxnCv1/m9zLfR5N9MfP7eQpb6Jsfguk3ABEzABEzABKYQwAH5HzUq5Cj2v5D05iltVT2EQvXjqpWUOH99UNzuXKKsi5hA3QSYJLPjMLSwrJEDOyVM8pvOUh/b86sJmIAJmIAJmECLBPaq0a7/ipKOlPSehvrPaiYRkJqWMyX9selGXL8JTCGAmdzvgq/DDaZ8PoRDJJkkA7xzowzharmPJmACJmACJrAAgasE04ItFzhnVtGNJB0uad+GwjJeIazG3mtWB2o6Tv4IVk3rNrmqqXuuZuQEPhzuv8cNdJybhu/ppwbaf3fbBEzABEzABExgDoHXSSJ6UVXB0fobkohHT5SVJuThwbzqUk1UntR5vKSzGwhZmzThtyYwlcDjw8SBCcRQ5b1hDDb5G+oVdL9NwARMwARMYAYBFP5TJN11xudlDxOG8YuSPiuJaEhNyQckfbmpykO9twqKj1dNGwbt6jcggInSUMOyxsFgtoiTNDuQFhMwARMwARMwgZEReKak71UcE+EkPyHpYEmXrFhX0enEun9RUaGKn38zTB6uV7Een24CixDge3RoMPcZ8or9K8P355GLDN5lTcAETMAETMAE+k+ALNK/lFQl6zN1ZCEizGUaHvLmQSm5aYPtMAYi3Py8wTZctQlMI0A4VvxsiCY2VGEHkiADTPKZDFlMwARMwARMwARGRGD7Gn7kidL0I0mXb4ELma9RTP5fg23tERS4KhOqBrvnqkdKgJ0GJq3sPAxZ6X5S+P68YKTXycMyARMwARMwgZUmcIik51cgsLukoyURrakNIYndpOGGTpP014bbcPUmkBIgLCsr9fg6kJF9qMKk/qeS+A4Rdc1iAiZgAiZgAiYwIgK3k/QXSZddckyvlfQbSddc8vxFT8MJG6X+sYueuED5h4VVUyLFWEygLQIHhvuOKEtDlvuGcbSRg2XInNx3EzABEzABExgkgY9VyP6MwzKhTK/f4shjttqrN9jmUcF0pGnfjQaH4KoHRoA8Dvg5kM186PIVSedIuvbQB+L+m4AJmIAJmIAJXJgAphH/WHLX4BmSTpJ0owtX2fhfrw9Zq5tqaJOgxGHKZTGBNggQlpXdNDJJt+Ez1OSYCGLAJGityUZctwmYgAmYgAmYQDcE3iNpvyWafoykUyXdfIlzq56CI+nbq1Yy53xCzaL83GZOGX9kAnURwCn6u2Gn6y51VdphPfuH788tO+yDmzYBEzABEzABE2iAAAmczpC09YJ1PyT4SOAr0bawKkskmvs01DDhZskmjSmWxQTaIMBOGpPVN7XRWMNt4PfE9+frDbfj6k3ABEzABEzABDogQAInMkEvIjhCEkFl20VOqrHsQyWdKYls2E3Iy4Iit3MTlbtOE8gRwH/nXEmHDTwsaxzWbuH784B4wK8mYAImYAImYALjIED25xMl3XOB4WBSwcRhuwXOqbsouSRwxmxKyB1xVlOVu14TSAhcTtKxIwjLGodEcIE/h5DNTeZfie351QRMwARMwARMoEUCT5H04wXau3VQDB6+wDlNFD1G0kuaqFjS7cOq6Ucaqt/VmkBKYF24356QHhzw++eE8TxtwGNw103ABEzABEzABKYQYFWQUKQ4PZcRfCJwju5aydk0KCdNOWl/R9J5S0aeKsPRZUwgEiBHCX4OY5moXjTkeiH6GruaFhMwARMwARMwgRERwOzo95JItlYkm0vClOfZRQVb+PxZITRsEyYRZMHFEZusuBYTaJIAOVEIy3rcCMKyRk74IjEZek084FcTMAETMAETMIHxECASyotLDOe6QcHZpUTZNop8ssHY8XsG5edBbQzEbawsAcKyssPFRPWuI6JAqFnyxVxlRGPyUEzABEzABEzABCRtE1Y9cdacJ9eQ9GtJb5xXqMXPULpw1n58Q22eHsLPNlS9qzWBfxF4XZik7joiHncIYyKYgcUETMAETMAETGBkBA6UtHvBmK4k6WeS3l1Qrs2P7xgUFOLI1y34fmBy8Y66K17x+ginu3HBvzImaBcvqIM2ypjgkcOjqD+XavCacQ8TlvXwkv1tsCu1Vv3x4CvUdqb5WgfhykzABEzABEzABDYkgBkSpgXX2fCjfx9hR+IHkj4kqYxi9+8TG37z2gb9EX4ZzEiayh3RMJreVj8JkzImZrP+lZkMPnXO+bHeHUpQ2KJEPe8rUc8yRWJYVna4cPwfi9wgfHc+M5YBeRwmYAImYAImYAL/IfDOAp+BS0v6tiR2J1il7ZNgJ97EzkCM4OSMuPVfbU8e/sN0LUxcnvifQ6N4979hXHcbxWg8CBMwARMwARMwgX8TwFzjb5Ju8e8jF35DeMWvSjqohyYV9B1zj/tduMu1/MWKKavXTYV/raWTA63Ek4cLLtyjwz320YFex1ndvoKkM8JO5awyPm4CJmACJmACJjBQAi+V9LUZfcdenEkDk4c+xmjfPmR9ZmekTsEJ+5wQUarOel3XBQQ8eZCuHRz9xxSWNd7fLwuToh3jAb+agAmYgAmYgAmMgwAOp8fPWLnHPOnDwVypbuW8LnrvnzPxqdIGMenZdehDDosq4+jruZ48XGD+93JJYzPr4ZnyhzDxLuOs3td71P0yARMwARMwAROYQuBxwdk47wDN33sHs4Oi0K1Tqm3t0G8kNZFrgmy4OJBbmiHgyUMzXPtQKyGTmXi/qA+dcR9MwARMwARMwATqJXCEpGmOmoRiJSQroVn7KkRzQUm5Zc0dZCWYenFktTRDwJOHZrj2oVaeKWTJ7vOiQx84uQ8mYAImYAImMDgC95Z0gqRL5Hr+ppAEjmRwfZZnSDq5gbCxxNo/T9JV+zz4gffNk4eBX8AZ3b9XmHg3Ef1sRpM+bAImYAImYAIm0BaBL0vCsTEVTIBw4CTvQ9/lEyF0bJ39JEoME4cf1Vmp69qAgCcPGyAZxYEvhuhnm4xiNB6ECZiACZiACZjAvwncVBJJqVCWo+AcfKKkzeOBHr9eVNJfZphcVen2vmHltInQr1X6NbZzPXkY2xWVtgrfHYIsWEzABEzABEzABEZG4ABJeyRjeoKkUyUxqRiC3D4oKoS7rFP+HjjUWafrMoFVILBP+E7eehUG6zGagAmYgAmYwCoRuFaIJHT9MOiHh1X82wwIAqFUj6q5v08Jys9uNdfr6kxg7ASuHvKtfHPsA/X4TMAETMAETGAVCbxV0kfCwLcLiaruOjAQh0h6V819PibYaxOn3mICJlCeAEEWiFD2wPKnuKQJmIAJmIAJmMAQCGyU7DJsGyYO9x1Cx5M+EgLyXEn3T45VfbtlUH5wIreYgAmUJ0ACSUwef6ELEt+VP9MlTcAETMAETMAEek/gBZIwLbhdmEQ8pPc93rCDD5Z0tqTLbPjR0ke+FCYPTCIsJmAC5QnsFL47hE62mIAJmIAJmIAJjIjAxST9TtLzJf1J0mMHOrb3Svp6jX3HTImdDMyWLCZgAuUJXETSrySdIum/y5/mkiZgAiZgAiZgAkMgQHhTJg4nSXrmEDo8o48oK/n8FDOKljq8a1g5fVqp0i5kAiYQCWwfvjuvjwf8agImYAImYAImMB4C/0/SDyW9eMBDIkIUjpm3qnEM2GsTotViAiawGAECF5zpbOyLQXNpEzABEzABExgSgTcOKJfDNK7sDqDsYy5Rh9wnTEZIDmcxARMoT+C24bvzofKnuKQJmIAJmIAJmMCQCFxC0mcl/VPS3pKuMaTOh75+TFKdGWx/JOk8SVcaIAt32QS6JEC4Z3YBb9xlJ9y2CZiACZiACZhA8wTuHsyXzpD0upqjFjXZe3w2/izpyTU1cpUwcfheTfW5GhNYFQLXC0EGPr8qA/Y4TcAETMAETGDVCWD283hJv5d0giSyK6Oc91mimcR1aurkJKycMpmymIAJlCdAgkZ2He5R/hSXNAETMAETMIHhEyBEJ2Yr8/69p+QwUUTn1fOdkvUQDWlePXxWZy4Cwiu+UtLfJB0pCR+AvsqrJB1dY+f+IenkGutzVSawCgQ2Ds8LnkUWEzABEzABE1gpApcMq2esoM36V3Zb/rA5dVA3JkJl5K0F9VDXNmUqWrDM1STtFUwRSJi29YLnt1H8W5L2qKmhZwXOr62pPldjAqtC4CXhuzPUPDGrcp08ThMwARMwgQYIePKwIVScH5kw4VRNFJW+OFVvJOkcSQ/YsMtLHfltqI/EeRYTMIFyBP5L0vHhH+8tJmACJmACJrBSBDx5mH257ynpx5JOl/QaSZeeXbSVTx4o6WxJl62htZuFlVMiT1lMwATKE3hM+O68tPwpLmkCJmACJmAC4yHgycP8a4lT9RPDKuMfJD2pxvwK81ve8FN8T76x4eGljhwcFKBNlzrbJ5nA6hLAz4EFhcuvLgKP3ARMwARMYJUJePJQ7uqz6/DqoDQcIene5U6rtdQvJL2ihhq55udK+lUNdbkKE1glAkRWwufq3as0aI/VBEzABEzABFICnjykNIrfX13SB4M/xBckbVV8Si0lrhuUllvXUNvuoa7H1VCXqzCBVSKALxQT7+uv0qA9VhMwARMwARNICXjykNIo/55JA5MHnKo/IIlJRZNCDoo/1WQyRZI5zC4sJmAC5QkQSIFM7B8tf4pLmoAJmIAJmMD4CHjyUO2aYr6EGRPKOGZNTTlVf0QS/6oKTteYXTDhsZiACZQnQOQ1vjskarSYgAmYgAmYwMoS8OSh+qXHqfrJknCoJoQjDtYcq0uoi10Hdh+qyk/CbglJriwmYALlCFxV0pmSDilX3KVMwARMwARMYLwEUEzvWvCvrF3/LQrquVNJjNgTF/WpjnClJbtTuhi7DoR0JRkeIV4J9VqH4OfAiid+D1XkmsHsomym7ypt+VwTGBOB14fv4PZjGpTHYgImYAImYAIm0A8CJJXDxAF/CBwsb1KxW0RYItJSVVkfFKA7Vq3I57dK4BKSrihpk3AvYTZD1B8m2GRa30ISE8PLSbpoqz1bjcb+W9Ipkn5d847iatDzKE3ABEzABEzABEoT2FrSl0J0lr0kXa30mRcuSG4HcjxVo1+uAAAgAElEQVRUFcwu/li1Ep/fCAEUVCYFJCB7raRM0qHBXI1dp7L/cOglc/hXJe0paWdJD5K0paT/10jPx1/pMwL/ncY/VI/QBEzABEzABEygDwTuIwlfg79JeqUkFMWygnkWWaVxdK4iLwwK0MuqVOJzayOwkaT7SdpN0rfDNS4zQSBM6F8kHSfphOCoz4ShzLmnSvqUJO4Fdiy8S1F8OTHrZNcPn6OmgiEU98IlTMAETMAETMAEVo4AihoOzyh8v5f0+JImEA+QdI4klM0qgiM3k5A6Hbmr9GcVz8WXZxdJ3wsmbXmFH18ZshcTCnTX4HiPnxDnXUXSpWZA45oyycRcbnNJ95LEKvm7gtkcyQCZdOTb+2uYTOwo6TIz6l71wzE62ZtWHYTHbwImYAImYAIm0A0BlLTXBadqFEVs1+fJHpK+Na9Aic9uFRTHT5Yo6yL1Erh2WOk/bIryfrKkj0t6vqRbNrwTwOSTHTCU4G+GyEHpZOLvYdLy0DmTlHrJDKM2TAbPaiGPyzBouJcmYAImYAImYAKdEcDBdZ+wAv1ZSSSgmiZHS3rVtA8WOIayiKKIw62lHQJ3D0kE8yZFTCIwG7pRO92Y2Qohmu8SdicIMZxOJNiReKfvF8VJ974zKfoDEzABEzABEzABE2iZwM0kfSWYleDgSjz5KNcJSl2VpFTsdBD1iUmIpVkCF5O0g6Qf5JRxwvZiroT5UR8lhmt+nyR2Q+JEAnO5NUk372OnW+jTgYEFgQ8sJmACJmACJmACJtArAjjP/jQ4VROaFft2Es/9uaI5C2ZPKIOP6NVox9UZ/FmIyHNsTvE+QNJNBzZUJkAPl3R4MhbuHya4txvYWKp0l106/ESIlmYxARMwARMwARMwgV4SQAl9WginilM1oTqxia8ip0nCDMXSDAGck4mkFVfrYf12Sfg6DF3II/G5ZGyMkZ2IMYyt6Nq8I4z73kUF/bkJmIAJmIAJmIAJdE2AyDlvDNmgfydp2yU7xG4DCt//Lnm+T5tNYDNJByWK9enBN2Xj2acM9hOSHDKJjRMknKvJRbFIyOEhDZ5ke0wCjxxSp91XEzABEzABEzCB1SYQnTVR2vBZ+MwSTrb4OXCuw3DWdy+xO4QDO2FvUaZxiN4vhEmtr5V+1nS3EEo2TiKqTGz7OcILevWicG2f0OdOum8mYAImYAImYAImkBIgmRvx+REcVskYjA02Tq3E/C8SbLZR8qqGeS1qZ5U+v0FI6BaVZ9gyyVslwbmafCUnJpOnt0m6xEgg4PMRE/BdfCRj8jBMwARMwARMwARWgMDXJb03N87tJP0smFQwuZiVNIzTyOmAkrtqym0OWW1/sgpNhnCY/kPSs2ureZgVXSHkhYgTKSJKYd40dCFhHmN6+dAH4v6bgAmYgAmYgAmsDgHMjDCLefCUIbMySmQfVn5ZIX2spP+XK8fqMOeTVdpSjcClJX0kKJQolSjJs3JyVGtpmGfnJ1VPHeYw/t1rwuyS6ZvJkcUETMAETMAETMAEBkHg/sFECcfNWRKdqnFe/b4k7NGjsCuBoksyMsvyBK4R2MIS3waiKI3FPGd5KhueiTnXd5IJFpyYwA5N+A5xrd8ztI67vyZgAiZgAiZgAqtN4F2SDimJgLCZ+wfllug/W4RQr2eWPN/FphMgPwM7OyiTrERP2wWafuZqHmVHbK9kAoHZ3NCiMRGUgAADN1zNS+hRm4AJmIAJmIAJDJXAUZJes2DnbyHp4LBjgcL7qQXPd/H/ECBhX/RvOMF+I/8BU+LdzkEB5x78nqSrlzinD0WYdLO7VDWvSh/G4j6YgAmYgAmYgAmsEAF2ElC8br/kmAnPyvnEqd9F0iWXrGdVT2PicFZgSJz/66wqiArjfpAk8l5wH+LgXyY6WIXmajk17prcoZbaXIkJmIAJmIAJmIAJtETgiZL+IgkzkEVlo7Dq+1NJz5R0kiRi8T96ilP1onWvQvm7h0hKKL3s4sDTshwBdsJODhOIIyRdcblqWjmLyQ0RtL7bSmtuxARMwARMwARMwARqJHCgpE8sWd+eQVl7YDgf5XfXoBhhQnLXJetdhdPuFHwbmDh8UxJRlizVCJCf5M/hniSK0eWrVdfY2ZgIct0f1lgLrtgETMAETMAETMAEGiBAyFVWawnFuoxgKoKylhdMbybBphtfiM3zBVb879sGMy8USKIGEcnKUg+BWydsD+vhbg5mfezQHSOJ7OEWEzABEzABEzABExgMgVuGFVBCXy4qjwnn7j7nxG0k/Z+kcyT9r6Qrzym7Kh8xsYrmNYdLmhced1WY1D3OOyY+EERhyuclqbu9ReojLwWTxucucpLLmoAJmIAJmIAJmEAfCODg/JslO/LLEGmpjIM0Zk0/l3SapJeusFM1rDDnQnmER1/Napa8JXp12r2SSGCv6EnPmMQQYIDdOhIzWkzABEzABEzABExgUAS+Jun9S/R406AA4+RbVnDI3imsuv9W0o49WxEuO44q5fYO3AjLumWVinxuKQIvCrzJpXDfUmc0W+gBoT9vbrYZ124CJmACJmACJmAC9RPAQZcQodsvUTXJrVg9v9kS52Kmg/JEUjnMdu68RB1DPAW/Epjx76FDHMBA+7w+MP+TpOt3PIavSzpb0jU77oebNwETMAETMAETMIGFCZBf4FxJGy94JjsI+DAQkrWKbCJpLThVY5e+WZXKen4ukyyURiYOXnVu92JhHvSTwJ4ITMuEJK6jx9G/6IA6KnMdJmACJmACJmACJtA2gXeESD+LtvvaoIg9a9ETZ5S/laRvhAnJHpKuNKPcUA8TUef7gRnjdISd9q8k0b7+Hq4BPjddCBPlZXfruuiv2zQBEzABEzABEzCBCxEgsRsTgUWFSEEkuKpbHizpFyFh3YslXaLuBjqqj7GgNMIMXxFLNwR2Tq5D27tcZHFnt+6r3QzdrZqACZiACZiACZhANQLYXKPQEtJyEblbOI8cDk3If0l6jqRTJB0raYeBO1XfMFnxZhJh6Y4AOz7kfeC+ZweozfCtbwvtYipoMQETMAETMAETMIHBEXh8CJu6qP03YUbPk3SVhkeMH8Zbg1M1Ch/ZmIcoRLNCWYWbzZW6v4JbJb4n5FtoQ8i6TohidvranLC0MTa3YQImYAImYAImsCIEsL8m8/MicoUwcfjRIidVLHtdSetCux8fmNkPeQaYOGCusnVFDj69PgLRZ+f4lvKNvCDcB0+ubwiuyQRMwARMwARMwATaI8Dq50mSFnV43jcoQfdpr6v/buk2kr4VVo3fJemK//6kv28ODbz26m8XV7Jn/y3pj+HaPL9hAuzskdPkxBH58DSMzNWbgAmYgAmYgAn0jcDNg+K0qPMu0WpO7XgwD5FEZmsy9JIArK9O1TEZGHk0CElr6RcBJg3sCqHUk++kKXlkaOdVTTXgek3ABEzABEzABEygaQIvkXTMgo08JShBuy54XhPFcap+bpjIMA4UtD7ZktOXHwZe72sCgOusTOCSkv4QrlGToVtJgsike2zhhytfAFdgAiZgAiZgAiYwHAKEi1zUlAYlnYRyF+/RMHGqJooNq/uYCC0aOaqpobA7wqo2GbSv1VQjrrcygWeH68Ru2mUr17ZhBWRO5z7wBHJDNj5iAiZgAiZgAiYwEALYe6PUPnSB/m4ZlKAvLXBOm0WvJ+nDwan6Y5IIj9qlxAhLe3bZCbddSACTN8yWUPCbiLxEQAIik7WdU6Jw4C5gAiZgAiZgAiZgAmUJ4Oz8T0mXL3uCJCYNKFhMIvost5V0SHCqfqckokO1LTcICiO8btl2425vYQKEA+ZaEQ64TmHCwMRh0YhmdfbBdZmACZiACZiACZhAZQK7BxOfshVhpoS50qI+EmXrb6Icuyq/Ck7VL2zZ1OqNQRnF58HSfwJbhOvFBIIcEHUJpkrUiemSxQRMwARMwARMwAQGS+BISa9foPc4SKME4TA9JGHSQ0SdP0n6jaRHtNB5ksD9PvDaqYX23EQ9BAgBzD3OblUdgnM0TtI4S1tMwARMwARMwARMYLAErrHEaijOpGcMdsQXmGex24JT9Xck3b7Bsdw38P3HgmZhDXbJVZcgQLZ1Jg+nSCKSV1UhLCv1EQXMYgImYAImYAImYAKDJfA4SX9bQEHCPwIlaO/Bjvg/HccX4SPBDp1X/i6SlxUVyH3+nsCL+ocg15FEPopnSnqTpHdIYsxkQt58CAOoqY/keWDCx71+l4p1RidsEsORIM5iAiZgAiZgAiZgAoMlMJH06QV6/6OgbHfheLxANxcqys4DOxDsRKAszxobuRpweH3CArX/IiigT1zgnC6KbhsceXGcJ/LWOkmvk0R0qCPCGFCkfybpYV10sIM2vxzGjc9KFWHiBbsXVKnE55qACZiACZiACZhA1wRQhglLSWz7MnKVoDyP1W774cEXAp8IFL18/gpC2qIEni0JZbtIyCJNef71ObfDy5N+nj5lh+Eikl6dlGE8mH2NXXYOY/5ehYHyHWPCdZqkjSrU41NNwARMwARMwARMoHMCNwvKUVlzlLVQ/m6d97y5DjBhIBrTnyX9OrfKftdEgebzGxV0I644ozz2VZ6WjIlJAbsNs+TrubJbzyo4kuOMDybsNi2bDfp+oQ4SF1pMwARMwARMwARMYNAEXiQJO+yygg34SWULD7wcpktE2mGX4duSbidp35zyTMQmdmNmCUnqUD4xheqrfDc3plvM6ej2ubJPmlN2LB/9IYx5hyUHROb2cyRde8nzfZoJmIAJmIAJmIAJ9IYANt0fLNkbTJtQhF9TsvxYipGZ+qNh9RklEAbpP3wlLjljsL8LZbeb8XkfDh+XjAf/DMxsZsmNk7IwwNxp7IJPEGN9yxIDjTt77NhZTMAETMAETMAETGDQBC4Voslg519GUIRRnlc1WkzeZCedQBBJKa90XyZMOCiH70NfJYYQpZ/PK+gkuyzpuHcrKD+Gj18SxnzQEoM5IJzrrOJLwPMpJmACJmACJmAC/SJwL0lE1rliiW7FFdTPlCg7xiKYd6VK87T3eUV6m3AO+TDyE4s+MSKJ3UMkEYK3SO6Q4/CuohNG8Pn/hDGTnXwRuWYweWPSaTEBEzABEzABEzCBwRPAgbNs1KSDgwK16eBHvdgAiM+PuQqTrGkThvwxHKSjPDac84N4YOCvmGZ9Jcfh7QMfU5nubxbGzD0wyzxtWj1vDueRM8NiAiZgAiZgAiZgAoMnQOz+MvHrUZjOlfTLwY94sQFgdvSxYKqVnyTM+htO9wzN7BqUx2yxZntXml0TFGCuPzzSsTPGsQs7M+T/YNw3LTlY7h2icR3d812nksNxMRMwARMwARMwgVUncLWgDJXJnEs8fxSnx6wotP+StIWkB0l6aYi4hJM0ymGqSMf3RGcilO0nw+evHCi36wbn+GNDLhCiDaE8x3Hy+tqBjm3Rbv80jPuRJU98bihPGFyLCZiACZiACZiACQyeABMBkoHlk6BNGxhKMmUtGxK4qiQmYE8NSdOYVBDOlvC3hwYFks+GIkyU8H/4YhJdijCzlwsDwGwtnTysQrQlhv61MO6dSlxIdiqOCSGNFzFzKlG1i5iACZiACZiACZhANwSIAlPG+ZnVdpTFPbvp5mBbRWn8SWC3bH6ANgfP5OBNkk5IJgf4N2yZ6wROwOnk4cW5z8f656fCuHcpMUCil8Fo1UIal0DjIiZgAiZgAiZgAkMlgJL4nBKdRwHGUXSjEmVd5MIESCCHEnn/Cx/u3V9MCH6eTAoIx/vMGb28fFKOsRWFdmVSspWkm8yobyiHY8hVJlhFwo4Tu0/zkgcW1eHPTcAETMAETMAETKA3BLYOCuCNCnqEUnmeJExxLMUEcCxOzcDIxI2CfefiUzsrcRFJ30wmBFzv+87pzZWTsoxt2gSUCFX7STotKUum7SHLe8NY3l0wiDuGcnsVlPPHJmACJmACJmACJjAYAi+URFbhIlkfFKHbFxVcwc9Rupl8PVoSiiI+Dt+WRJSdKKw+o2CTI6Ovgn8DfYz/irKN530eZpktsVP1oaTeoUecIocHjPYpuJCfCBPuool5QTX+2ARMwARMwARMwAT6QwBnWBS7IiE8JeZNqy5k1Mb05nGSWHn+VnAgjwo3r5j63CoHirCtfHbj3PE+/YnfSzqOexd0DufwtPw8u/7rJWX3Lqi37x+/PoxlMqejNwwmfmV8ieZU449MwARMwARMwARMoD8EcOT9u6SikJPsTqAklnEQ7c/oqveEaEPsFDxJ0nskfTfwShXm/HtMfab5NcRQrret3q3GaiB3QzqeoiSAr8qVJ4HeLCHqEJMq6seMacjyzjCO980ZBPcLYyVMr8UETMAETMAETMAERkHgHsGs4koFozleEvkKMM9ZJcEhGDMkJgSpUj3v/StmAPpdqONeMz7vw+GYvyCOb55/Bv4cqWM153y0YBCELKXc0M2W2DlhHLMmS1eQdIaksWQTL7is/tgETMAETMAETGBVCKD8fK9gsJjfoChhv72qcofgFwKHef9ghKP0NImK+UOnfdiTY+ty48MxeJa8VVIcU2Ry1KzC4fjPQv0HFpTr+8dMkhjzrIR/5Lvg8x37PhD3zwRMwARMwARMwAQWIfAjSbsWnIBNP4rQJgXlxv4x2ZT/FlhEZTl9RTG+7BwImDxR/glzynT90T1zuyyE5X1UrlPsxrw/TDpxBE4Z8D7v65GefkQoX7RDkZ7Tx/f4CTHWaaFp2ZHBN4ggBJi9WUzABEzABEzABExgFATIhow5zjybbKIFoUAWrSiPAkjBIFCaPzdFWUaJJAzp5gXnfymc+/yCcl1//OYpY/y6pD0kfSyMdU3SxpJwHj81Vx6/CZRqwrbmcxtgxgOvT3Y9yIrtx2zh+MLkhckhY3xR/gP/bQImYAImYAImYAJDJoBJBXbZaS6C/Hj+NyhCD8t/sEJ/Y4ZEZCXyNBwt6fs5ZZkJ2ANK8MC5FqVynilQiWpaKcKE8muS/pSM9Y/B0XnbXA8eIwlfBqJxwYiJJrtVb5B06VzZw0J9B+WOE73qGWHC8azwfidJd82V68ufkQvRpvJypKS/SiIhnsUETMAETMAETMAERkOAiDespM8TlCBW1VdVyIT8jRBh6WVhopXPhTAvPGnK7dlBcUYpH5LgTE9UrjqE3BdMoD6bq4xEcvCNuTCYgOA30EdTOXZTGAP/SJKXCqFtOf6O9KDfm4AJmIAJmIAJmMAYCPxhhs12HNsjgiKEucqqCeZabwuhRT8t6boJAEx1YthVPpvlIJ2c8q+3RLZCsVzlXBlMxGCQnzwAiAhFJ0oid8K83bA817b/jrktTpnSMKZp5PPo46RnSnd9yARMwARMwARMwATKEWBFHSVuXsIyTHTwd/jvclWOphQmWr8PpjizzJGIMkSYUjInl5VrBuZwx19gFYVdl1mTB7I1v3EAUJ4exvDNXF+3Dsc/nDvuP03ABEzABEzABExg8AReEBTkWQNh5RQlL68gzSo/huMkRCOKDrb7KLGXmjMoVs6JNLSoYAIG19steuJIyken8fzOA34OQ5g4cBneFa7hnrlrsm84fuvccf9pAiZgAiZgAiZgAoMn8HlJrPTOEqLhoOTOC7s569yhHcee/7WSzpT0lRJRkxgfuwjLSDTbWdVIPDFaVTp5IEs1E7btlgHawTnRYZ5oUlHYScJfY5Um23HsfjUBEzABEzCBfhNYL130QOkGE+m+mfScTHpXJu23Jn08k76USd/OpCMy6dcT6WeZdGgmfXVN+lQmZRPp/RNplzXpIWvS1nuunlkOzql/nxK/P154skiTTRrTnbHL/ST9WhL+H49sYbAoykzKvtxCW31sAh8Rxs/kAR+HT4W/Oca/B/ax00mfcJCO2caJEJXKDSXdLD3g9yZgAiZgAiZgAi0TYKKwTtpmTXpBmBwcnUlnZ9L5Nf47L5OOy6SvZNLr16R77r9hiMmWR95oc3cPClA+UkxslKg3KHJ9z0cQ+7vM63UkfTw4t75zQd+FZdqL52CuBFt2OeaZRcXyY3uFOePHX4RdiJsHp30mqxzHCbnP/iAkzKOfx4/twng8JmACJmACJjBYAmvSFmvSSyfS5zPpr3MmCcdn0tcz6QOZtNua9HJ2IibSEzPpYZl0v0zaPpMeO5GeFep8QybtkUmfzaRfZtI5M+rn+KET6S2ZdLfXSKzGj0V2k0SyrllCPH+U2zEKGX9fIul0SYQNJWt0m3JRSX8JCuh92my4J22tD2Pn/kvDv5IrAqWcf1yfvkr0a+DVYgImYAImYAIm0BWBTNpkIr04k344RZn/lyKfSW+fSI/IpJutlwilWVn2lP7rQGmzibRdJr0ik76QSadN6cMf1qR3ZNIYnCFR3MgiPE3uGBS4MUaMIeEYUZJY3SYzcNkQq9M4VTn2icB4FXMBrAtjx+cmL4eHz47Nf9CjvzFvY4KzQ4/65K6YgAmYgAmYwGoQ2Ee65ER6ykQ6JJMwHUpNkQ5bk161Jm3btk9CMJW6+Zr07OAncVaub7/GvGmddI0BXqlos43p0jT5TjBpuvq0Dwd67KohdwBhZ/cKtvZdDoVMyiigv9W4drTKMCWHA2M/eErhyIXP54UQnnJqK4fuEPpOHgcS51lMwARMwARMwATaILBeunImvSaTTsop5T/OpJfhDN1GP8q2sY+08Zr0hLArkZo5nbUm7TuR8o6TZavuohwrpjhL4zSdF2zNUbCPzH8w0L8xEdopmAmx23LbnowDxZPoQijJ9+pJn9rqRvR5OHRKg0wYYMK/nad83vWhvUPf0khRXffJ7ZuACZiACZjAeAkwKcikPTPpH8mk4eTgpLzFEEa+Jl1pIj19TToyGQM7Jl+cSLNW8/s0NMKzfmFGh4hbj+LW94g3M7p/ocO3kURITfIqPFsSE4k+SbT953WVhEkc99jJUwaNGdlfw+dEwCKTd1/kssFPhr5v35dOuR8mYAImYAImMEoC66XLrUlvy6TU/OdXa9Iz1w844kwIFfu13CTiswdIm/f4QhJ+lQRx0wQn4j9P+2BAxwj/ySSIHZRM0tV62vd7ByWZHYhVMYHBnybuuKCEv3DKpI4kfXzGP/xytuzJ9XtK6NOJknC6t5iACZiACZiACdRNAN+BNelpOfOkw4mENKboRYSSnUgfTvw2MG16ZyZdvm6mFetDEUMpu8mUeh4XPnvblM+GcIhV6yeEFe2fSbpbzztN9C58HrgeYw6JGy8DDur4OXw9+cffz4wFwismi19NylCeBH5dC2ZWXKuhfj+65uf2TcAETMAETGA+gXXS7TMJH4boBE0ehR3P7y7CzfwO1/Apk4hM+mYy5lMy6ak1VF1XFc8LydCm1ferkPMgDZ85rVwfj20t6VuSzpD00gGtDL86KKTHDKjPfbz+TfcpRiAjOdwgzCubBuL6TcAETMAETKA2AgdLF5tI5FI4NyjRZ2TSq9uOmFTbgJaoaE16eCYdm0wiPrcmEfGnayEp135TOrFpUGK/NuWzPh/CDn13SedI+qQkEr8NSdiZijkf+jTJHBLDNvrK94JdhzGGL26Dn9swARMwARMwgekEyJeQSZglxd2GgybStaaXHvdRwtBm0uuSSdRJB0j/0+GoLx5W5nec0geix6AcsYI/FHlEyPL7G0n3H0qnp/TzVYE9JkxcI0u/CJAbhO8GPjQ36lfX3BsTMAETMAETGDABzHMyiV0GJg6n98xcpzOyE+m2IZP1vyZUa9JeTCw66BA+AJhd5HdAiGjDyj3K6xBkM0lfDhmwX68BO9wH2BtJOjUoqHn7/yFcj7H38Rvh2hww9oF6fCZgAiZgAibQCgHMlEL41bjbcGgmYQZjCQT2ly7NpCHuyEyk73ZgxrSrpB9NuSg4o7Ky2nfF9VKS3hCi9XxJEpOIschLwjUgEtalxzKoEYzjPuG6MLm+4QjG4yGYgAmYgAmYQLcECMGaSV+KSvGa9GYmE932qr+tT6QHZ9LfAq9j958e9aipAXxP0lumVE68/X9MOd6nQ9tJwjzpeEkP71PHauoLEwZCgDKJe1dNdbqaagS4JtxzXJMPVqvKZ5uACZiACZiACRBAf5NM+klQhAlNSihGSwGBTLrZmvT7wO20NYnVzaaFPAKYLN0z1xBJ7VCO+mqSsUlwhGbl9+2ScJAeq5D5m2uBbf3txzrIAY3rHeF6nCLpygPqt7tqAiZgAiZgAv0jsCbdOJP+GBTgv2TSPfrXy/72aD/pmpn0w8Dv3IlEjoUm5ZFhdyHva8FuBJOKqzTZ+BJ14zi8S3DwJgTrVkvUMcRTPhMUVvJUXGKIAxhJn28bJnFM5h49kjF5GCZgAiZgAibQDQEiKk2kE4LieywTiW56MuxW10uXmUifSSYQRA9qSj4kicy9qZCJmYnDD9ODPXi/raSjJJ0Ukr6R/G1VhMhkfw0TCPw7LO0TYOL603ANCG1sMQETMAETMAETWJZAJl0/Mbn5zaqGYV2WX/48/EPWpI+HCcQ5DYZyPU7Szrn29w0K0r1yx7v68+qS1sKK7/vVv+zcbXF5Rrgu5w4gS3ZbTNps5z2B/98GmDekTU5uywRMwARMwATmE9hPuk6S+Oy366Trzj/Dn5YhsKf0X5l0UJhAnDmR6lbmiU2P+UU+h8P/b+9OoCypygOO/x0c2QKCgsEFFxRF0OCCKCoiSFAxKm5xQQVFYwLiEiUmKjAaUVFIPBiRkZDJTNetJq0oio4eCAIuKBKMCy6IAUVBhAhhGIRhmcn5nFvH8tnv9evut9b733PmvO56VXXv/VXDubfu8v0WiPncw06bAG8CbgIuAfYcdoGGnH+MtJyVn1mMvuw45PJMUvYxfTD+W4l/r5qkiltXBRRQQAEFeiqQYNsEP4kGbow8nA4P7WkGE36z1bBpgi/lDsRvC3hKD0miYf6rlvu9PjeQ3t9yfNC/xtzymDYVUZaPAJYMulSyD7IAABfZSURBVAAjmt89gcvzM/qW6x8G8pQel9cFRcfhpIHkaCYKKKCAAgo0UWAZLEmwOjdsr5+CRzSxnsOu0wxsnuCC7HzNFMQ0nl6kWITbupvSlTkw3LAiGt8bODVPUYqytQau60W9x/0ejwLW5g6EW4X292nG3+PPsvVXgaX9zc67K6CAAgoo0GCBBO/NDdrYFSi29jT1SWAGtk9wVXgX8PWY0rTIrKJzEA3Q+hSMXXMjqXUB9SKz6urymJLzujxdKhal7tPVVZN7UsS0qKbRHD25DH2teWz/+43sHHFEduhrbt5cAQUUUECBJgvEAt4E66MxW8JRTa7rqNStgCckuC13IGLx5mJSNM6j8VlvEEV05ji2y2JuvIBrHwNcmDszf+fb3a4FY9elqgMRkahNvRPYArgg+8YaoL16d2vvpIACCiigwIQJxM5KCW7Kow4zE1b9oVY3Au5l9w0JDl5EYY4Dvle7PkYiYhefiJw7qLQ18JGc7xkuAF4QexWwLDoRb13QHbyoVSBinpyTOw63zRJAsfV8f1dAAQUUUECBTgIJzs0N2EsjJkGnc/2u9wIFnJL9bygXvibgYuCEWuk+mBtLMXVoECmiJl8D/BR49iAybHAeH6+NQMTictPCBaITXQXkWwccuPBbeaUCCiiggAIKUHvzfUeCmG5iGrDACtistsPVJxeQfSwCvQt4Zu3a3+SozbVDffkxpkSdC8Qb3fcArZGt+5Jpw28a60VW1DoQyxpe335Vb1vg/Ox4O/D8fmXkfRVQQAEFFJgIgdjlJ8GN8da7hGFv5TkR5u0qWcI+tTUnB7U7r83xWGx7K7B5/j7ersa0l4g23a8Uc8jjbybe5n4JeFi/MprQ+8ZWtrE7VbUGYhUwrB2zxvERxBbTl2W/+Bt98ThWwjIroIACCigwUgIJzsjTZS6Lt98jVbgJLEyC5fl5XD0Dsf9/tym294w53VX6DrAeuFd1oMefz8vbXUY0axtlPcat3S5GIN5b60CcN8HRuGssc/4YsVOuz24xAve0Oa/wBAUUUEABBRToLJBg39xQXT8Fe3c+228HIRAdhgRX55Gg4+eR58+B2NUoUsRRiI5DBBzrdYpI45/LcSM+jOtjeu3b7n6vziM8MQrxo1kiiLe7bhKPR1DEmEIXVj8Bdp5EBOusgAIKKKBAzwUSfC03Uv+95zf3hgsWSPCy3Km7pcvF0xHILxpK1XqVMv/ey7gKMV3mXUBscfkVIIKamQYrEG/P4y16POtoHL8NiJEJ00aB7YHPZp8wim1Z+zXyprkCCiiggAKTJZDgmbmBGoukd5qs2o92bTfA3Ur4fu7Yxbadc6UjgV/XGpKx9uG6uS6ax/f757njkUe8ATcNT2BHIKYuReM4/n3Z7XB/9zCeA1ybTWJ74n8E7j68x2TOCiiggAIKNEwgwbdy5yHmyptGTKCAF+fnc+tKuP8cxYtpRCmfEx2JaFQeO8c13Xx9P+D0vIvTycA23VzkOX0XiIXUMUUtFgHHs74R+Csgjk9aitGG+H9Y1ZmKmCax3sGkgAIKKKCAAr0SyJGkIyDZ7dMQc9hNIyaQRx++kzsQ0XBvl5YCNwOH5BOuAmJLysW8dd0EeAuwBojYEXu0y9zjQxWIaWo/qDWcY5H8vkMt0eAyj2l0MW3r/2r1j+mXWw2uCOakgAIKKKDAhAgkuDA3SpdPSJXHspoFvCA/p3UlbNemEjEPPt66xihBNCbj57PanNvN4ScD381vs/9mQt9md+M0KufEDmkRWyPWolRv3z8NxDalTU2x09fltfrGz89tamWtlwIKKKCAAkMVKGDX3CCNuA67DbUwZt5RYBksSfCz/Lze2ubkmNt9af6umgu/kIZjdE4iJkQEmlsJ3KdNfh4eTYFYC1EtlI9ORIw+RYyIPxvN4s67VDEaFrFMYgexqpMUow4x+mDsi3lzeoECCiiggAJdCpRwQm6MfqPLSzxtiAIJjs3Pq+ogtJbmIuCfclTnWCgaW1POJ8VuPTFfPnbx+T5u2Tsfu1E8dy8g/iaqBnZ8RgC/Z4xiYbsoUwQiPAL4n1qd4u/8FCDWO5gUUEABBRRQoF8Cy2FpguuiMVrAa/uVj/ftncA07JjgrvzMntRy523zSMGzcgciGoqvbDmn06+PBb6Z10y8fZHrJDrl43eDFYgOYew+VI1EVR2J/wZiBGuuBfiDLe3suT0RiJ3G/rfWaYipWR8HHj77JR5VQAEFFFBAgZ4KlPCi/BZ7zSrYsqc392Z9E0iwOj+3U1syicjOsd9/vJ2NHXdi4XQ3KSJXnwTEG9xPAg/o5iLPGUuBx+WduO6oNcIjgGDE6jh8xKanRWf2g8CVtbJGxye2CD6G9ut+xvLBWGgFFFBAAQVGXiDBTG6Euj3ryD+t3xewtm3rDTMQc7+r9AngXOCg3NiKqRxzpYOBX+UFp8+c62S/b4xArIl4d8vuTNEwjw5kTHOKaOGx6DhGswaVHsbGEdDYJam1wxCdndXAq/KUvEGVyXwUUEABBRRQIATy4tsbcufh+aqMj8BpsFVsq5uf3Z61kkeD6x15wXQsdN669l3rj4/M01gigFy8xd209QR/nxiBWET9fiBiIlRTmqrPGJWI3bZielBs13sgEI38xWz9+ydAjCq8NHdg/gO4pk3eERX6rx1lmJi/RSuqgAIKKDCqAtPwxNz4vKPo3Mgc1SpMdLkSXBDPr4R3ZYidc+Mr1jtEg+/CNkAxpSmmgsTuO/EmdyE7MbW5tYcbIBAdiTcCM3lEqupEtH7G389lebpT/B1FByBGMD+Sozl/APiXvFPXGcDZQGzKMFsnobp3/N3GIv24LnZS2qEBnlZBAQUUUECBZggkODo3PmOu8yilWBj53rzgNxoi7f6dmKdVxGLQKsV2ooflhZWt153QpIBZCd6ZO3/n58rHDjTXAZ/KnYjWxdRxWkxn+jkQgeNeWKH5qUAHgViM/Lq8m1FMiYu/nxjVqhr8C/2MEa/YMexM4ENAjH7eq0M5/EoBBRRQQAEFhimQ4Gu58RnznkcpRXyB2FUlGhbtGibrcqdil5aC7wQUeaFwdW28zfxi7oxEx6QRaRr2yM/v9rzY/bN5X/+wiTUM9RQuX8ijDcfj4vi6jT/PXyCmuMW0twjO9oYcW2EZEB30WGcT/w3GuoUYQYhRrhgde3NezxARr2O9Rb3TP/8SeIUCCiiggAIKDE4gb9F6RzQ+C3jC4HKed067t5mHHYHQOqVY6Bmdh9jKcVz3s+9Uv2rNyvXxDE+DZwNr8tSRqHese4gUjbyjgXjLGyMUu+bjfiiggAIKKKCAAgoo0J1ALar07ectbuFjdxku7qwYiYipEtVIQnzGXu+xvWi7FDuyxHnxVrSxqYAvRufhNfDRXN9rgRh5WAIckAPExbH5xHporJcVU0ABBRRQQAEFFFiAQG2rzx8s4PJhXBLz9+v70kfHINY0tEvfAz7T7sumHE9wYnQe9oZv10ZoYopWLHaNLTdj2kinTlZTKKyHAgoooIACCiigQL8ESjgmGp3lxoBg/cqm1/eNiMf10YdYy/D0WTI5FLgauPcs3zXqUAmvi+f4wI1TlqLO4bM279MfwcBMCiiggAIKKKCAAgosTiDBdDQ608ZdjRZ3s8FdHQssP9/SgfhZSyyDB+bIyvsNrljDy2kannwqbFiysdMQW2DG9pkxVSumLZkUUEABBRRQQAEFFFi8QILv5c7DyxZ/t4HeIUYTftHSgViRSxCdiy/n3V0GWqhhZbYCtnkLbLg7bNgdIjr09sMqi/kqoIACCiiggAIKNFQgwe8iSxfwlDGs4lNnWf8Qe8RH9NuLgaVjWKcFF/nfYO2xG0eR6pGmF3w/L1RAAQUUUEABBRRQ4A8EEvxum9YSIprsOKZ/aBl9uB6IfxFleaJSgmtiFKlo6Ja0E/UwrawCCiiggAIKKDBqAitgszxlacM0PHjUytdleWKK0pdaOhDfnMS5/gl+HM+z3Bg9uks+T1NAAQUUUEABBRRQoAuBGdi+6jysHO8diWJ+f7XDULULU0SynaiU4OL8PCO2hUkBBRRQQAEFFFBAgd4JJNip6jxEpOne3Xngd7oHcGnL6EPENhjHdRwLxktwbh55OHzBN/FCBRRQQAEFFFBAAQVmEyjg0bnzENt6jnM6DrgAeGdLB+IqYNtxrth8yp7gc7nzcNR8rvNcBRRQQAEFFFBAAQXmFEiwczXyMAObzHnBaJ6wB3Az8PC8zuG8lg5E46NLV48lwTm583BkdcxPBRRQQAEFFFBAAQV6IjADO1Sdh4gT0JObDvYm1XSlGHGo0gOA37R0IN5YfdnkzwK+mZ9nRNY2KaCAAgoooIACCijQO4FVsGXVeVgJEZF53FJMV/oOcPeWgr+wpfNwG/CYlnMa92sBP8wjDy9qXOWskAIKKKCAAgoooMDwBRLcFQ3OVfCo4ZdmXiWI6UrRKYjP2dKpLR2InzKeoyuz1W3WYyX8Mp5lAQfMeoIHFVBAAQUUUEABBRRYjECCm/Lb6r0Wc58BXxuLoKMzsKJDvlsDv2jpQHwBiLgQjUxj+iwb+SyslAIKKKCAAgoo0EiBKrBYgpeMSQVjYffZwHrgkXOUOepUxX2oPo/vcE1MfzoLuAm4BYjtXrfK528JvB24GLgG+DrwUUYkPkYBW0cnMP6NccC/Do/GrxRQQAEFFFBAAQWGLlDCp/PIwzFDL8zcBXgQ8JXcIbi8i1GEWFC9dpYOxMeAzdpkFx2IlbVrHs/G9SBnArGL0W5ArKm4Ip/zo/x9m9sN5nCCPXPn4ZYNDR5dGYymuSiggAIKKKCAAgrMKpDguNzonJ71hOEfjIXc7wDOyWscqhGE+EzAa4CIMF1PmwKvBj5f6wTUr4uf1+TrZ1sfEIurq/MPy3k/pJ4BsEOtPFMt3w381wIOyc/xkoFnboYKKKCAAgoooIACkyGQ4OA88hC7Fo1iejkQaxXOb/MvvjukpeDR+D+tzfn1+8T0p+g03bvl+ti2tuo83Ag8q+X76teZfF5MYxpqSvDBeI4FDL0jM1QIM1dAAQUUUEABBRTon8AUPC6/sb51GSzpX05jdeeY7lR1Hn6Vg8/NVoGYxhTnDT1Cdwmfzc+xHvNitjJ7TAEFFFBAAQUUUECBhQkshy1yozPeWu+6sLs08qqq8/DPHWr3ilonI6ZKDS0l+Hk8xxIOGlohzFgBBRRQQAEFFFCg+QIJvps7EG9ufm27qmGMwFSdh04B12I6U3VejFYMJU3BI/LzW1/CdkMphJkqoIACCiiggAIKTIZAAR/Kjc9YP2CCGEWoOgVP7wCyT+28oU35KuHI/PxcLN3hYfmVAgoooIACCiigQA8ECnhGbnzeMgNDe4Peg6r06hYR06HqPDy6w033z+dFzImhpQI+H8+vgA8MrRBmrIACCiiggAIKKDAZAqth0wS3RAO0hP0mo9Yda3nPWufhfh3OfHY+b12Hc/r6VXT2Eqz12fWV2ZsroIACCiiggAIK1AUSfCGPPpxYPz6hP0fciGrkIbZtbZdicXKcF9Goh5JK+PP83G6JTuBQCmGmCiiggAIKKKCAApMlUMDrcyP02vMgoixPcnpsrfPw8A4Qr62NPAxlzUOClJ/bGR3K6VcKKKCAAgoooIACCvRO4DTYqjb9ZdK3+3xprfMQi6LbpYh8XY1QPKjdSf06vgK2SXBr7jwc2K98vK8CCiiggAIKKKCAAn8kkGBFboie9UdfTs6B3YGv1ToFZwI7tVQ/FpW/GLiydl5Edv7TlvP6+msBR8TzKuGXM7BJXzPz5goooIACCiiggAIK1AVKeGruPNw5BfetfzchP28BRITmd+V/y4Dj2LiL0dKaQSyiPgJ4PfBK4NXAW4DDauf0/ccEl8TzKuB9fc/MDBRQQAEFFFBAAQUUaBVI8OPcIH1P63f+PjoCJeyVO3rr0x+PjIxOQS2JAgoooIACCiigQHMFSnhDbpTelGDb5tZ0vGuW4Oz8nD4z3jWx9AoooIACCiiggAJjK7Aclia4IjdMY8qOacQEpmDvatShgE5B7Eas5BZHAQUUUEABBRRQoHECCQ7NjdObS9iucRUc8wolOD8/n9PHvCoWXwEFFFBAAQUUUGDcBWLnngSX5Qbqh8e9Pk0qfwHPyM/lzhJ2aVLdrIsCCiiggAIKKKDAmAqU8PLcSF13OjxyTKvRqGLPwD0SXJqfy8pGVc7KKKCAAgoooIACCoyvwDJYkuCiaKgW8PX4fXxr04ySJzg2dxzWJhh4ULpmKFoLBRRQQAEFFFBAgb4IrIJHJViXG6xv7Esm3rQrgRJ2q55FCUd2dZEnKaCAAgoooIACCigwSIHa2+6bV8IDB5m3eW0UyKNA33AUyL8IBRRQQAEFFFBAgZEWiK1bS/h+Hn04x+lLg39cJRyV/W9zkfTg/c1RAQUUUEABBRRQYB4CBTwhwe25AWvsh3nYLfbUBPsmuDPsS/j7xd7P6xVQQAEFFFBAAQUU6LtAzLPPnYf1JRzU9wzNgGnYMcF12f2sDXA3WRRQQAEFFFBAAQUUGAuBBKtyQ3aN02f6+8hWw6YJvpW9fzID9+xvjt5dAQUUUEABBRRQQIEeCszA5gm+nRu0PzL6dA9xa7eKEYZaR21t7LRU+9ofFVBAAQUUUEABBRQYD4FpeHCC3+QOxLdXwDbjUfLxKGV0HAo4JfvGFLG/HI+SW0oFFFBAAQUUUEABBWYRKOBJCdbkBu5Fp8FWs5zmoQUIFHBSdo0F0sZzWIChlyiggAIKKKCAAgqMmMAU7J0gIh1vSPDVVbDliBVx7IpTwgm1jsNRY1cBC6yAAgoooIACCiigQDuBvI3ob3OD94IZuFe7cz3eXiAHgftI1XFIcHT7s/1GAQUUUEABBRRQQIExFSjggAS35obvZQl2HtOqDKXYMWKT4Myq41DA+4ZSEDNVQAEFFFBAAQUUUGAQAtPw5ATX5wZwLKZ+2iDyHfc8puC+Cf4ru92V4E3jXifLr4ACCiiggAIKKKDAnAKnw0MTxMhDrIFYl+DQOS+a4BMSPCbBVdnr5gL+YoI5rLoCCiiggAIKKKDApAnEmocEF+QGcXQiklu5/uFfQd6K9W0JbgunEn4ZHYk/PMvfFFBAAQUUUEABBRSYAIEZuEeCk2sdiHi7vu8EVH3OKk7Djgm+XLO5cCXcf84LPUEBBRRQQAEFFFBAgSYLxDScBL/ODeX1CT4cHYsm17lT3RK8LMGN2eOOEo6ZgU06XeN3CiiggAIKKKCAAgpMjMAquE+Cs2pv2n+a4IUTAwAU8OgEZ9cMLp+GJ06SgXVVQAEFFFBAAQUUUKBrgRLeUHvrHmshYl3E47u+wRiemDtOyxPcmTsOsZvSyQbTG8OHaZEVUEABBRRQQAEFBitQwnYJPl5rTMdUppUl7DLYkvQ3twTbJnh3gjW10YbzXRTdX3fvroACCiiggAIKKNBAgTyN5z9rDevoRHyuhH3Gubqr4CEFnJRgba1uV5TwonGul2VXQAEFFFBAAQUUUGDoAgkOLOErtYZ2TGe6OMHBy2GLoRewiwLEtqvR6Snhk7URlajHlRHwbTVs2sVtPEUBBRRQQAEFFFBAAQW6EYjFwwk+lSDWBETDO/6tLaAs4bmjuEPTNOyR4MQco6Eqc3xeErsquYtSN0/ecxRQQAEFFFBAAQUUWKDAFDysgI8luKHWiYgGefz+rwleMgM7LPD2i7osFjkn2D/BcQkubynf7Xna1X6LysSLFVBAAQUUUEABBRRQYH4Cy2HpNDwnwaoEN7U01KMzcXkJpyU4NBZb93pkIkeAfsAUPK+EExJclOCOlnLEDkrnJDgsomrPr4aerYACCiiggAIKKKCAAj0XWAGbFfCC2JUpryOoTxGqfo6G/BU5lsLJJfxtAYdEPIkCDihhr7xIe6cCdk2wZwn7JXh+rK8o4fDcSTgzwaUJbm3pKFT5RIC3WNh9eGzD2vPKekMFFFBAAQUUUEABBRToncA07FjCK0v4RIIfJ4idmqrGfa8/r42F0CUcOQW7L4MlvauJd1JAAQUUUEABBRRQQIGBCszA5iXsVsJBCd5ewCl5BOKiAn6Y4Kq8ZiLWJUTnIhZlx1SoqxNclhc4RwyGVSUcU8ArYmQiYjUMtCJmpoACCiiggAKNEvh/TJpNjR34vnAAAAAASUVORK5CYII=)\r\n",
        "\r\n",
        "La capa de mas izquierda se conoce como la entrada y consiste en un set de neuronas que representan las caracteristicas de entrada. Las capas interiores se denominan capaz escondidas (hidden layers) y transforman las capas anteriores mediante una suma con pesos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xj35op9oqpP"
      },
      "source": [
        "## Hiperparámetros.\r\n",
        "La Redes Neuronales (NN) utilizan los siguientes hiperparámetros:\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Hidden Layer Size\r\n",
        "*   Hidden Layer Activation\r\n",
        "*   Batch Size\r\n",
        "*   Learning Rate.\r\n",
        "*   alpha\r\n",
        "   \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkBEUc92rE0f"
      },
      "source": [
        "## Por qué es util?\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Puede aprender modelos no lineales.\r\n",
        "*   Puede aprender modelos en tiempo real.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdLJGag7qWEP"
      },
      "source": [
        "Ejemplo: Tomado de https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQrSIctmoqFT",
        "outputId": "215f8e01-234b-4255-87be-71ddeee42710"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X, y = make_classification(n_samples=100, random_state=1)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\r\n",
        "                                                    random_state=1)\r\n",
        "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\r\n",
        "clf.predict_proba(X_test[:1])\r\n",
        "\r\n",
        "clf.predict(X_test[:5, :])\r\n",
        "\r\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkpUOm-kw7wY"
      },
      "source": [
        "El ejemplo se incluye en la seccion [Redes Neuronales](https://colab.research.google.com/drive/17yg2aFC4bePYDTkDgyRllIsmljlvp0ju?authuser=3#scrollTo=X1_Xq7ZbFi1a&line=3&uniqifier=1) en la que se obtiene un modelo para el problema a resolver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAVmf4fTNwER"
      },
      "source": [
        "# Aplicacion de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkgJvQSPuI77"
      },
      "source": [
        "Una nota curiosa antes de comenzar es que en un primer inicio se trabajó con valores sin normalizar y los resultados no fueron muy buenos. Ser volvio a normalizar los datos y se obtuvieron resultados mas aceptables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNBWR8KcTIj_"
      },
      "source": [
        "Comencemos por dividir los datos en un set de entrenamiento y en un set de prueba.\r\n",
        "\r\n",
        "Se utilizará 70% Training 30% Test. aleatoriamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDalnWtetxtm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "y = arrhythmia_data_balanced['Class'].to_numpy()\r\n",
        "X = arrhythmia_data_balanced.drop(columns = ['Class'])\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37yUyJK_AWuu"
      },
      "source": [
        "## Logistic Regresion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIAFVJlrxZMh"
      },
      "source": [
        "Se escoge la regression logistica debido a que la misma mide la relacion entre variables categoricamente dependientes, en nuestro caso, el cuerpo humano tiene multiples variables que se relacionan entre si."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljPUD_v6bdNA"
      },
      "source": [
        "Declarando el modelo de Regresion Logistica y utilizando grid search y validacion cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XdAuWL9Bd1r",
        "outputId": "79636f28-ff3a-49e4-d0b7-0971a7e3b008"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "grid={\"C\":np.linspace(0.1,3,15)}# l1 lasso l2 ridge\r\n",
        "\r\n",
        "logreg = LogisticRegression(max_iter = 10000)\r\n",
        "logreg_cv=GridSearchCV(logreg,grid, cv =5)\r\n",
        "logreg_cv.fit(X_train,y_train)\r\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=10000, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': array([0.1       , 0.30714286, 0.51428571, 0.72142857, 0.92857143,\n",
              "       1.13571429, 1.34285714, 1.55      , 1.75714286, 1.96428571,\n",
              "       2.17142857, 2.37857143, 2.58571429, 2.79285714, 3.        ])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pv6NmqaE3lE",
        "outputId": "1495212c-9df1-4801-b3a2-0af086799aa3"
      },
      "source": [
        "print(logreg_cv.score(X_test, y_test))\r\n",
        "print(logreg_cv.best_params_)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6219512195121951\n",
            "{'C': 0.7214285714285714}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHJWw8SuBV-a",
        "outputId": "8cea3d94-e37b-4ae0-eb38-6bc27c9007d0"
      },
      "source": [
        "log_reg_pred = logreg_cv.predict(X_test)\r\n",
        "log_reg_pred"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2, 10, 16,  2,  2,  1,  1, 10,  4,  2, 10,  2,  1, 10,  1, 10,\n",
              "        6,  2,  1,  1, 10,  1,  1,  1,  2, 16,  1, 10,  4, 10, 16,  2, 10,\n",
              "       16, 10,  2,  1,  4,  1,  3, 16,  1,  1, 10,  3, 10, 10,  4,  6,  1,\n",
              "       10,  1,  1, 10,  4, 16, 10, 10, 10,  1, 16, 10,  2,  1,  1, 10, 16,\n",
              "        1,  1,  1, 10,  5, 10,  1,  1,  1, 10,  3,  1,  2,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwQIDqeJBHWl"
      },
      "source": [
        "### Balanced Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbCA8gdXBO1c",
        "outputId": "333bbc9a-a919-44b7-a4e1-8e32d6f6ca5e"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "log_reg_ba = balanced_accuracy_score(y_test, log_reg_pred)\r\n",
        "log_reg_ba"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5689336978810663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JCWnlqVBzb2"
      },
      "source": [
        "### Cohen Kappa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSO6WPHuB3hw",
        "outputId": "d4c08577-14e2-40fe-f1d0-b85383d13e64"
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score\r\n",
        "log_reg_ck = cohen_kappa_score(y_test, log_reg_pred)\r\n",
        "log_reg_ck"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5415689810640216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8pAIKwiCM5G"
      },
      "source": [
        "### Matriz de confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "KT5QSvCECe6c",
        "outputId": "0f71a770-0376-42db-a0ea-2645a4653084"
      },
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "plot_confusion_matrix(logreg_cv, X_test, y_test)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f73ebe65b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpJR6Y-yF9pn"
      },
      "source": [
        "### Hinge loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z71JLNfeGGsz",
        "outputId": "6c8920ee-580c-43f0-aad4-26b62f48cd9d"
      },
      "source": [
        "from sklearn.metrics import hinge_loss\r\n",
        "pred_decision = logreg_cv.decision_function(X_test)\r\n",
        "log_reg_hl = hinge_loss(y_test, pred_decision)\r\n",
        "log_reg_hl"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9371325986651411"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWfvp0fHGbK3"
      },
      "source": [
        "### Matthews correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qKa6IfjGa1s",
        "outputId": "b8e57230-680a-49f8-b50a-d501024d901c"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\r\n",
        "log_reg_mcc = matthews_corrcoef(y_test, log_reg_pred)\r\n",
        "log_reg_mcc"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5592665584774914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZo3IWcjJCaC"
      },
      "source": [
        "### ROC AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eZ0KIPNJFXF",
        "outputId": "0ca750ad-474b-42fe-a7ab-8f63d17aad39"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "roc_auc_score(y_test, logreg_cv.predict_proba(X_test), multi_class='ovr')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8969667709311436"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpQXkHOOLSlk"
      },
      "source": [
        "## k Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIJBELmmzmwD"
      },
      "source": [
        "Se plantea hacer una aproximacion por K Nearest Neighbors dao a la simplicidad de implementacion y la entrega de buenos resultados sin muchos ajustes. Sin embargo, se entiende que no da buenos resultados cuando hay muchos \"features\" pero se quiere usar para una comparación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAWtbe4lMsFB"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "neigh = KNeighborsClassifier()\r\n",
        "grid={\"n_neighbors\":np.arange(1,40,1)}\r\n",
        "neigh_cv = GridSearchCV(neigh,grid, cv =5)\r\n",
        "neigh_cv.fit(X_train,y_train)\r\n",
        "neigh_pred = neigh_cv.predict(X_test)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plSSHmIAOEHu",
        "outputId": "9bc3300a-e6a9-4e5e-b53f-30e3d820ee7b"
      },
      "source": [
        "print(neigh_cv.best_params_)\r\n",
        "print(neigh_cv.score(X_test,y_test))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_neighbors': 8}\n",
            "0.36585365853658536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_N0jSPcP0_h"
      },
      "source": [
        "### Balanced Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTaNTz4wP0_h",
        "outputId": "24f43103-ca76-4291-a74e-28ab9fe830fa"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "neigh_ba = balanced_accuracy_score(y_test, neigh_pred)\r\n",
        "neigh_ba"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3479864433811802"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC-agXAnP0_h"
      },
      "source": [
        "### Cohen Kappa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uWbeN_sP0_i",
        "outputId": "0730d55a-534f-4c71-e75f-718cc2885c8b"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "neigh_ck = cohen_kappa_score(y_test, neigh_pred)\r\n",
        "neigh_ck"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23529411764705888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TWn6RN7P0_i"
      },
      "source": [
        "### Matriz de confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Je6dwHN6P0_j",
        "outputId": "977fc698-57c9-4826-8388-24e4ad6fb8c8"
      },
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "plot_confusion_matrix(neigh_cv, X_test, y_test)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f73eaccdb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMvkrZ4GP0_j"
      },
      "source": [
        "### Hinge loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCSElCZWTCRw"
      },
      "source": [
        "kNN no posee funcion de decision por lo que no se puede calcular el hinge loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxuMsZ6tP0_k"
      },
      "source": [
        "### Matthews correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDGfM240P0_k",
        "outputId": "7534a9c1-a0b3-4f25-f097-9e8522873dc5"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\r\n",
        "neigh_mcc = matthews_corrcoef(y_test, neigh_pred)\r\n",
        "neigh_mcc"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.284011666243716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGcu1-1_P0_k"
      },
      "source": [
        "### ROC AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGIjR2xmP0_k",
        "outputId": "ca8aacc9-0346-4066-c538-ed8f5136c109"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "roc_auc_score(y_test, neigh_cv.predict_proba(X_test), multi_class='ovr')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7825768965442597"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEOZz0C8wo8A"
      },
      "source": [
        "\r\n",
        "\r\n",
        "## Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDB3p3J50pD2"
      },
      "source": [
        "Se escoge Gaussian Naive Bayes dado que nuestro set de datos tiene muchas dimensiones (Mas de 200 columnas) y el modelo esta especializado para ello."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CawVVcDNwo8B"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "gnb = GaussianNB()\r\n",
        "grid= {'var_smoothing': np.logspace(0,-9, num=100)}\r\n",
        "gnb_cv = GridSearchCV(gnb,grid, cv =5)\r\n",
        "gnb_cv.fit(X_train,y_train)\r\n",
        "gnb_pred = gnb_cv.predict(X_test)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JicBTAJ_wo8B",
        "outputId": "7e0af92c-26b0-4414-8d0d-5928f651e684"
      },
      "source": [
        "print(gnb_cv.best_params_)\r\n",
        "print(gnb_cv.score(X_test,y_test))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'var_smoothing': 0.0023101297000831605}\n",
            "0.4146341463414634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeeARqUswo8B"
      },
      "source": [
        "### Balanced Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU-BkCUKwo8C",
        "outputId": "3deb430d-1708-4db3-a43a-3dc44c7d8ed9"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "gnb_ba = balanced_accuracy_score(y_test, gnb_pred)\r\n",
        "gnb_ba"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40968614718614715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0y0YbSzwo8C"
      },
      "source": [
        "### Cohen Kappa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RXijZ7zwo8D",
        "outputId": "66bf7ab5-22cb-4202-8a4a-24e286d33770"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "gnb_ck = cohen_kappa_score(y_test, gnb_pred)\r\n",
        "gnb_ck"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3111655582779139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84pGd3Tdwo8D"
      },
      "source": [
        "### Matriz de confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "0FKCvOv_wo8D",
        "outputId": "03ca419f-52a3-4792-eebd-0e185bff6880"
      },
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "plot_confusion_matrix(gnb_cv, X_test, y_test)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f73eab99f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZHhA_bnwo8E"
      },
      "source": [
        "### Hinge loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8R-bElfwo8E"
      },
      "source": [
        "GNB no posee funcion de decision por lo que no se puede calcular el hinge loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3qrM42Vwo8E"
      },
      "source": [
        "\r\n",
        "### Matthews correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot1ndhnkwo8E",
        "outputId": "38f32e0b-17ab-45d6-8e60-c522c546a05c"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\r\n",
        "gnb_mcc = matthews_corrcoef(y_test, gnb_pred)\r\n",
        "gnb_mcc"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31829777950322835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJh4Ls0jwo8F"
      },
      "source": [
        "### ROC AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guwywTXYwo8F",
        "outputId": "d7bd6a4e-c1c2-4371-e5f0-e0a502920df2"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "roc_auc_score(y_test, gnb_cv.predict_proba(X_test), multi_class='ovr')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7210018810450497"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51KdsLT_AFnW"
      },
      "source": [
        "\r\n",
        "\r\n",
        "## Kernel SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW01AhT51JVN"
      },
      "source": [
        "Se escoge SVC ya que normalmente tienen un buen desempeño para la mayoria de los conjuntos de datos y se adaptan bien a muchas dimensiones como la de nuestros modelos. Ademas de ello, dado que los datos le realizamos un buen preprocesamiento puede darnos mejores resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPeP2OkMAFng"
      },
      "source": [
        "from sklearn.svm import SVC\r\n",
        "svc = SVC(probability =  True)\r\n",
        "grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf','poly','sigmoid'], 'degree': [2,3,4,5,6,7]}\r\n",
        "svc_cv = GridSearchCV(svc,grid, cv =5)\r\n",
        "svc_cv.fit(X_train,y_train)\r\n",
        "svc_pred = svc_cv.predict(X_test)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXXHsSsrAFng",
        "outputId": "d298dab7-0db7-4d3f-cfad-4644138e0ffa"
      },
      "source": [
        "print(svc_cv.best_params_)\r\n",
        "print(svc_cv.score(X_test,y_test))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "0.5853658536585366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb8nqYHQAFnh"
      },
      "source": [
        "### Balanced Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmDwivGeAFnh",
        "outputId": "9ea713d7-40fd-4777-f833-802b4ca918f2"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "svc_ba = balanced_accuracy_score(y_test, svc_pred)\r\n",
        "svc_ba"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5617509683299157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p6W3MGZAFni"
      },
      "source": [
        "### Cohen Kappa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk5tdsruAFni",
        "outputId": "8766daae-ddfe-49b6-c364-a30d5d780701"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "svc_ck = cohen_kappa_score(y_test, svc_pred)\r\n",
        "svc_ck"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5014306151645208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLEX_jKxAFni"
      },
      "source": [
        "### Matriz de confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "0wuJt4RsAFnj",
        "outputId": "921fac29-dc70-4c98-8652-61a7283a8aa2"
      },
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "plot_confusion_matrix(svc_cv, X_test, y_test)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f73e28141d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfHiL3daAFnj"
      },
      "source": [
        "### Hinge loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmk4hJ7_DmoS",
        "outputId": "bcf73461-afd7-4ad6-c775-1b0376954428"
      },
      "source": [
        "from sklearn.metrics import hinge_loss\r\n",
        "pred_decision = svc_cv.decision_function(X_test)\r\n",
        "svc_hl = hinge_loss(y_test, pred_decision)\r\n",
        "svc_hl"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2830519415789459"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmC9E209AFnj"
      },
      "source": [
        "\r\n",
        "### Matthews correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKk_LQiaAFnk",
        "outputId": "4c7d8477-3a7b-4c53-a6a7-b7444fd43237"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\r\n",
        "svc_mcc = matthews_corrcoef(y_test, svc_pred)\r\n",
        "svc_mcc"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5099487454112868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6n7Pg5YAFnk"
      },
      "source": [
        "### ROC AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viF1c_t4AFnk",
        "outputId": "bfdb242c-1f52-49b4-e3e0-32cca06172ae"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "roc_auc_score(y_test, svc_cv.predict_proba(X_test), multi_class='ovr')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9071469834183402"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1_Xq7ZbFi1a"
      },
      "source": [
        "\r\n",
        "\r\n",
        "## Redes Neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmC_sQqC1jG9"
      },
      "source": [
        "Se ecoge las redes neuronales debido a su habilidad de poder aprender modelos no lineales ademas de que permite aprender modelos en tiempo real. Al ser una aplicacion medica resulta util dado que las muestras continuarán llegando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJGEbWjMFi1g",
        "outputId": "69df4665-9183-42c7-f36d-59f4b135c167"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\r\n",
        "mlp = MLPClassifier()\r\n",
        "grid = {\r\n",
        "    'hidden_layer_sizes': [(50,50,50), (50,100,50),(10,30,10),(20,),(100,)],\r\n",
        "    'activation': ['identity','logistic','tanh', 'relu'],\r\n",
        "    'solver': ['lbfgs','sgd', 'adam'],\r\n",
        "    'alpha': [0.0001,0.001, 0.05],\r\n",
        "    'learning_rate': ['invscaling','constant','adaptive']\r\n",
        "}\r\n",
        "mlp_cv = GridSearchCV(mlp,grid, cv =5)\r\n",
        "mlp_cv.fit(X_train,y_train)\r\n",
        "mlp_pred = mlp_cv.predict(X_test)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUNyAzUtFi1h",
        "outputId": "47346cb0-b813-4ada-be7d-70e36a87bd3a"
      },
      "source": [
        "print(mlp_cv.best_params_)\r\n",
        "print(mlp_cv.score(X_test,y_test))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'logistic', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
            "0.6097560975609756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynybuhkWFi1i"
      },
      "source": [
        "### Balanced Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phk9YO0IFi1i",
        "outputId": "34996448-2cad-4137-f3e9-d97eeed17ee2"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "mlp_ba = balanced_accuracy_score(y_test, mlp_pred)\r\n",
        "mlp_ba"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5376836978810663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD7vpGyhFi1j"
      },
      "source": [
        "### Cohen Kappa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2KYzrWpFi1j",
        "outputId": "df8589d1-26de-4a57-f9e3-5dbc9bd9bce8"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\r\n",
        "mlp_ck = cohen_kappa_score(y_test, mlp_pred)\r\n",
        "mlp_ck"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5228223313329696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qutsScG6Fi1k"
      },
      "source": [
        "### Matriz de confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "5Jr3iqW2Fi1k",
        "outputId": "710b0379-6d76-4443-c114-875fcc97725f"
      },
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "plot_confusion_matrix(mlp_cv, X_test, y_test)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f73df6e4f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU9Z3/8ddnJhNuQi4GIcRYoCKWsghuilJbF3RXbOtDumvvtmvdrldstVX56dKupf7Kz9673qXqqlWxVKVY6yVKRbECCogKgtIiF0mQBAihBMgk8/n9cU4ghlxmknO+mTl8no/HPDIzmfm+z5kMX84535uoKsYYE0Wx3t4AY4wJi1VwxpjIsgrOGBNZVsEZYyLLKjhjTGTl9fYGpGNAUb4WlfVzklW/Ju4kx+QmyXP7T0abmpzk7GcvjXpAelLG1CkDdMfO5rReu+LNA8+q6tk9yUtHTlRwRWX9+Pa8SU6ynh870EmOyU3x4sFO85prapzkLNOFPS5jx85mXn32uLReGy9dX9LjwDTkRAVnjMl+CqRI9fZmfIhVcMaYQChKUtM7RXXFKjhjTGDsCM4YE0mK0pxlQz+tgjPGBCaFVXDGmAhSoNkqOGNMVNkRnDEmkhRIZtk1uEgM1Vrz/b68ePoAlny+/2G/23RfgufHDqRxV486aXeoYnI9dy9ex//+ZS1fuuKDUDJ6I8t1XlSzrpq1hodfeJHbH1sSag64/360pSjNad66IiL3ish2EVnd5vlvi8g6EVkjIj/tqpxeqeA62vjuGvb5JBPu3HfY8/urhR2v5NG3NJym61hMmT57K98/fwQXTR7NlGl1HDdqf85nuc6LahbA8wuG8YPLJoRWfgvX+9UuheY0b2m4D/jQUC4RmQJMA05S1Y8DP++qkN46gruPNhvfE0UVzSQKDv/U3v1pH0Z97wCEc/DG6AkNVG3MZ9vmPjQlYyxaUMikqbtzPst1XlSzAFavLGJPfSK08lu43q/2eCMZ0rt1WZbqS8DONk9fBtykqgf812zvqpxeqeA62PhAbf9zHn2OUQaeGF7Hw6OHJqmpyj/4uLY6QUlpMuezXOdFNcul7NgvoTnNG1AiIstb3S5OI+AE4NMiskxEXhSRT3T1hqxtZPB3+GKAwtK+Gb23eR9s/E0+J89pCGPTjDHt8BoZ0j5dqlXVigwj8oBi4FTgE8A8ERmpnSwsk7WNDKo6R1UrVLViQHF+129oZd+WGPu2CkvPG8DLZw3gwAfCsi/250BtsOeqO7YlGDys8eDjktIktdXhnI64zHKdF9Usl7Jhv7x+cGkfwXXH+8Dj6nkV72y301lJsraC64mjTkjxTy/t5VOV3q3PEOWU3zfQpyTYJux3VvWnbEQjQ8oPkJdIMXlaHUsrCwLN6I0s13lRzXIpW/YrpZLWrZv+AEwBEJETgHygtrM3ZO0paibeurYvu16Lk6wTFp85gJGXN1J2XvjXH1LNwm0zy5j98AZicah8pJhN72Z2Op2NWa7zopoFMOOmtxhXsYtBhUkeqFzMg3eMpHJ+WeA5rverPS1HcEEQkbnAZLxrde8DNwD3Avf6vS8agQs6Oz0FkN5YF7X1xgMfADeo6j0dvf7YsQVqE16abBAfHN0JL+t1Z49qp4+N66MPPFma1msnfmTTim5cg8tYrxzBqepXeyPXGBOuHpx+hiISp6jGmN6nCI2aXWuaWAVnjAmE19E3u9otrYIzxgQmqEaGoFgFZ4wJhKrQrHYEZ4yJqJQdwRljoshrZMiuKiW7tsYYk7OskaGb6jcdxXOXfNpJVs30wyfNDMsxt73iLAvcdlJ11UHVNdf75epvJjuDqQqarR+cMSaKFKHZjuCMMVGVslZUY0wUeYPtrYIzxkSQIiRtqJYxJopUsY6+xpioEuvoa4yJJsWO4IwxEZZtjQzZtTXGmJylpLceQzqTYna2OLyIXC0iKiKdLjgDETyCSySa+cWPniaRlyIeT7F46XB+O298aHlH9TnADZ9bxEcH70SBWU9O4c2tQ0PJqphcz6U3VhGPKU/PLWberUNCyQG4atYaJp5eS93OfC4/L/zp4l3uW1SzXP/N2vKWDQysSrkPuBV4oPWTIlIOnAVsTqcQ50dwIlIuIi+IyNsiskZErgyy/GQyxoxZU7ns2nO57Npz+cT4rZw4KrzhNTPOeplXNpTzb3d9lS//5ktsqC0KJScWU6bP3sr3zx/BRZNHM2VaHceN2h9KFsDzC4bxg8smhFZ+ay73LapZ4PZv1r6MFn7uVCeLw/8KmIFXn3apN05Rm4CrVXUM3gKu00VkTHDFC/v3e+tB5sW9o7j0PorMHdXnACcfV838VR8DoCkV5+8H+oSSNXpCA1Ub89m2uQ9NyRiLFhQyaeruULIAVq8sYk+9m3U1Xe5bVLPA7d+sPYo3kiGdG91Y2V5EpgFbVfWNdLfJ+SmqqlYD1f79PSKyFigD3g4qIxZLcdtPnmTY0D088cyJrPtrOAOWhxXuYVdDP2ad8wInDNnB2m0l/LTyU+xPBv8lO3pokpqqQwtg11YnOPHkhsBzeoPLfYtqVrbIYEbfjFa2F5H+wH/hnZ6mrVcbGURkODABWNbO7y5uqd2Tyb0ZlZtKxbjs2nP52iVfZPTxtQwv3xXI9raVF0tx4tAafr/y43z1ni+yrzHBf3zy9VCyjMl2qpLJEVymPgqMAN4QkY3AscBKEen0gnevVXAichTwGHCVqta3/b2qzlHVClWtSCQGdCtjb0M+b6wZSsX4rT3c2vZ9UH8U2+uPYnWVd+H4+XUjOXFoONf7dmxLMHhY48HHJaVJaqt773QkSC73LapZ2cBrZIindcu4bNW3VPUYVR2uqsOB94GTVXVbZ+/rlQpORBJ4ldtDqvp4kGUXDNrPgP7elyo/v4mTx1WxZWtBkBEH7djbn231A/hIsXeEOHH4VjbUhNPI8M6q/pSNaGRI+QHyEikmT6tjaWU4++Way32LalZ28NZkSOfWZUne4vBLgNEi8r6IfKs7W+T8GpyICHAPsFZVfxl0+cWFDVx7xV+IxZSYKC8uGc6yleVBxxz0k8pPM/vzC8mLNbO1bhA3PHlGKDmpZuG2mWXMfngDsThUPlLMpnf7hpIFMOOmtxhXsYtBhUkeqFzMg3eMpHJ+WShZLvctqlng9m/WHq+RIZihWl0tDu8fxXVJVENqYuwoUORTwGLgLSDlP/1fqvpUR+8ZNLBMJ46/3MXmUTPeZvQNQlRn9HXN1d9syc5H2Z3c3qPaqfTjRXrB3DPTeu1PTnpsRSaNDN3VG62oL0OWjcg1xvRYy0iGbBK5kQzGmN5ji84YYyJJFZIpq+CMMRHknaJaBWeMiagMRjI4YRWcMSYQQXYTCYpVcMaYgNgpqjEmwmxNhu74+z7kL6ucRJW+664zbNNp4U3E2Z5mR5+hCY6rDtOqTQGUAcmULRtojIkg6+hrjIk0O0U1xkSStaIaYyLNWlGNMZGkKjRZBWeMiapsO0XNrurWGJOzWq7BhbXws4j8TETWicibIjJfRAq7KscqOGNMYIKq4PAWfj67zXPPAWNVdRzwLnB9V4VYBWeMCURLP7ggKrj2Fn5W1Uo91CN5Kd7KWp2K5DW4isn1XHpjFfGY8vTcYubdOiS0rKtmrWHi6bXU7czn8vMmhZYDkEg084sfPU0iz1vQevHS4fx2XnijIVx+jpaVW1kdyaAfXImILG/1eI6qzskg6j+A33X1ot5YdKYv8BLQx89/VFVvCKr8WEyZPnsr139lJLXVCW55aj1Lny1g8/pwFvt4fsEw/ji3nKt/vCaU8ltLJmPMmDWV/fsTxOMpfnXj07z2ehnr1gc/vMzl52hZuZXVEVVoSn/Cy4wWfm5NRGYCTcBDXb22N05RDwBnqOpJwHjgbBE5NajCR09ooGpjPts296EpGWPRgkImTd0dVPGHWb2yiD31rta6FPbv97Ly4t5RHCGtGeTyc7Ss3MrqTIDX4NolIt8EzgHO1zRWzHJewann7/7DhH8L7J/p0UOT1FTlH3xcW52gpDQZVPG9LhZLccfPnmDePb9j5ZvDWPfXcCYHcPk5WlZuZXUkyGtw7RGRs4EZwLmq2pDOe3pr4ee4iKwCtgPPqeqydl5zsYgsF5HlSQ6438gslUrFuOzac/naJV9k9PG1DC/f1dubZMxBqpLWrSsdLPx8KzAQeE5EVonInV2V0yuNDKraDIz3+7HMF5Gxqrq6zWvmAHMABklx2kd4O7YlGDys8eDjktIktdWuTiHd2duQzxtrhlIxfisbtxQFXr7Lz9GyciurM0ENtu9g4ed7Mi2nV7uJqGod8AKH93fptndW9adsRCNDyg+Ql0gxeVodSysLgiq+VxUM2s+A/t6XOD+/iZPHVbFlazj75vJztKzcyuqIavjX4DLVG62og4GkqtaJSD/gX4CfBFV+qlm4bWYZsx/eQCwOlY8Us+nd8FqSZtz0FuMqdjGoMMkDlYt58I6RVM4vCyWruLCBa6/4C7GYEhPlxSXDWbayPJQsl5+jZeVWVseE5ixbNlDSaIgINlBkHHA/EMc7gpynqj/q7D2DpFhPkTNdbB7xwQ5n9D0hnIqwI65mRTa5Z5kupF539ujQ6qgTSnXsLd9ML+/sm1Z0t5tIJpwfwanqm8AE17nGmHDZfHDGmOhS7zpcNrEKzhgTGJuy3BgTSZqFjQxWwRljAmOnqMaYyEpnlIJLVsEZYwKhahWcMSbCrJuIMSay7BpclmuuqXGWJQ6zAOIfG+Usq3ntemdZLrkc6QJuv489pQgpa0U1xkRVlh3AWQVnjAmINTIYYyItyw7hrIIzxgQmZ47gROQWOqmPVfU7oWyRMSYnKZBKBVPBici9eIvLbFfVsf5zxXhLBQ4HNgJfUtVO5+zvrMljObCik5sxxhyigEp6t67dx+EzfV8HLFTVUcBC/3GnOjyCU9X7Wz8Wkf7prmRjjDkyBdUPTlVfEpHhbZ6eBkz2798PLAL+T2fldNlpRUQmicjbwDr/8Ukicntmm2uMOSJomjd/ZftWt4vTKH2Iqlb797cBQ7p6QzqNDL8GpgJPAKjqGyJyehrv6zUVk+u59MYq4jHl6bnFzLu1y8/BstooGdzA1de9RlHRflSFZ/40ggWPh9dROKqf41Wz1jDx9FrqduZz+XmTQssBt/vVvvSWBPR1e2V78NZXFpFgFn5W1S1tnmru1la14q+N+rqIPNnTslqLxZTps7fy/fNHcNHk0UyZVsdxo/YHGRH5LIDmZuHuO8dx6X9M5XtXTOGcaX+j/CP1oWRF+XN8fsEwfnBZ+DP0u96vDqV/BNcdH4hIKYD/c3tXb0ingtsiIp8EVEQSInINsLbbm3jIlQGV8yGjJzRQtTGfbZv70JSMsWhBIZOm7g46JtJZALt29uNv6731VvftS7B500BKSvaFkhXlz3H1yiL21Ie/Pqnr/WqXgqYkrVs3PQFc4N+/AFjQ1RvSqeAuBaYDZUAVMN5/3G0icizwOeDunpTTnqOHJqmpyj/4uLY6QUlpMuiYSGe1dcyQvXz0+DrWrS0Opfwj5XMMU/bsl6R566KU9le2vwn4FxFZD/yz/7hTXV6DU9Va4PwutygzvwZmAAM7eoF/0fFigL70DzjepKtv3yZm/nAJc24fz74G9yulmxwTXCtqeyvbA2S0fmg6ragjReSPIlIjIttFZIGIjMwkpE15LZ33Ou1Lp6pzVLVCVSsS9Em7/B3bEgwe1njwcUlpktrqcP5hRjWrRTyeYuYPl7Bo4XG88nJ4a7hG/XN0IWv2K9xrcBlL5xT1YWAeUAoMA34PzO1B5mnAuSKyEXgEOENEHuxBeR/yzqr+lI1oZEj5AfISKSZPq2NpZUFQxR8RWR7lqmuWs2XzQOY/ekKIOVH/HN3Iiv0KtqNvINLpJtJfVX/b6vGDInJtdwNV9XrgegARmQxco6pf7255baWahdtmljH74Q3E4lD5SDGb3u0bVPFHRBbAmLE7OPOszby3oYBb7noOgPvvGcvyV0sDz4ry5zjjprcYV7GLQYVJHqhczIN3jKRyfvBHw673qyPZNuGlaAdb5I/7Aq+n8C68oy0FvgwU+RVVz8IPVXDndPa6QVKsp0hGp96mHTbhZc9FdcLLZbqQet3Zo0OrPsOP1aHfvzKt126+aMaKnvSDS1dnR3Ar8Cq0lp2+pNXvFP8orCdUdRHecAtjTAR03fXWrc7Goo5wuSHGmBznuAEhHWnNByciY4ExwMGTelV9IKyNMsbkIrcNCOnosoITkRvwRvCPAZ4CPgO8DFgFZ4z5sCw7gkunm8gX8DrXbVPVC4GTgNxvVzfGBC+V5s2RdE5R96lqSkSaRGQQ3gDX8pC3yxiTa1r6wWWRdCq45SJSCPwGr2X173hjxIwx5kNyphW1hape7t+9U0SeAQap6pvhbpYxJiflSgUnIid39jtVXRnOJhljTDA6O4L7RSe/U+CMgLelQ9K3D/GRbnrhR7UHPkR735wpKXSb52gkQ1By5hRVVae43BBjTI5TIKBlA4NiCz8bY4KTZUdwaa3JYIwx6RBN75ZWWSLfFZE1IrJaROaKSMbTo1gFZ4wJTkATXopIGfAdoMJf2T4OfCXTzUlnRl8Rka+LyH/7j48TkYmZBhljjgDBzuibB/QTkTygP96aMBlJ5wjudmAS0DJH+h7gtkyDjDHRlu7pqaSx8LOqbgV+DmwGqoHdqlqZ6Tal08hwiqqeLCKv+8G7RCS/qzcZY45A6beidrrws4gUAdOAEUAd8HsR+bqqZrS8QTpHcEkRieMfWIrIYJwOlzXG5IoAGxn+GXhPVWtUNQk8Dnwy0+1Jp4K7GZgPHCMiP8abKml2pkHGmCNAcNfgNgOnikh/ERG8GY0yXig+nbGoD4nICj9AgM+rauAr0gelZHADV1/3GkVF+1EVnvnTCBY8Ht4oiIrJ9Vx6YxXxmPL03GLm3TokElmu86KYFeXvYrsy6ALSZVGqy0TkUWAl0AS8DszJtJx0Jrw8DmgA/tj6OVXdnGlYq/dvxGusaAaaglx8orlZuPvOcfxtfRH9+iW5+c6FrFwxhC2bBgUVcVAspkyfvZXrvzKS2uoEtzy1nqXPFrB5ffCrGbnMcp0X1ayofhc7FWBHX1W9AbihJ2Wkc4r6J+BJ/+dCYAPwdE9CfVNUdXzQK+vs2tmPv60vAmDfvgSbNw2kpGRfkBEHjZ7QQNXGfLZt7kNTMsaiBYVMmro757Nc50U1K6rfxc5IKr2bK11WcKr6D6o6zv85CphIjswHd8yQvXz0+DrWrS3u+sXdcPTQJDVVhxqUa6sTlJQmcz7LdV5Us1qL0ncxl2Q8ksGfJumUHuYqUCkiK9r2f2khIhe39JFpbG7IOKBv3yZm/nAJc24fz76GRA8315juO6K+i8F29O2xdK7Bfa/VwxhwMt3oUdzGp1R1q4gcAzwnIutU9aXWL1DVOfgXFQv6lWb0kcTjKWb+cAmLFh7HKy8Hv4p4ix3bEgwe1njwcUlpktrqcL7ALrNc50U1C6L5XexQgI0MQUnnCG5gq1sfvGtx03oS6vdSRlW343VBCXDol3LVNcvZsnkg8x89Ibhi2/HOqv6UjWhkSPkB8hIpJk+rY2llOOvxuMxynRfVrKh+FzuVS0dwfgffgap6TVCBIjIAiKnqHv/+WcCPgip/zNgdnHnWZt7bUMAtdz0HwP33jGX5q6VBRRyUahZum1nG7Ic3EItD5SPFbHo3nFYrl1mu86KaFdXvYqey7AhOVNvfIhHJU9UmEVmiqpMCCxQZiXfUBl4F+7Cq/riz9xT0K9VJIy8MahM6ZbPems7EP+ZmZukWrr6Py3Qh9bqzR7NV9htWrsO/9b2uXwis+7/fWxF0D4r2dHYE9yre9bZVIvIE8Htgb8svVfXx7gSq6ga8tVWNMVGShdfg0hls3xfYgbcGg+KNZlC8sWHGGHNIDlVwx/gtqKs5VLG1yLLdMMZkhSyrGTqr4OLAUXy4YmuRZbthjMkGuXSKWq2qgbVuGmOOADlUwWXX+l/GmOymbseZpqOzCu5MZ1thjImGXDmCU9WdLjfEGJP7cukaXNZo6p/Hzn882klWgXX0zTnxwYOdZbnuCO5q32RnQFWBVXDGmEhyPM40HbbwszEmEELgK9sXisijIrJORNaKSMZDRu0IzhgTmICvwf0P8IyqfsFfqrR/pgVYBWeMCU5AFZyIFACnA98EUNVGoLGz97THTlGNMcFJfz64Tle2x1vwuQb4XxF5XUTu9qdXy4hVcMaYYKR5/c0/ja1V1YpWt7ZLAubhzWZ0h6pOwJvJ6LpMN8kqOGNMcIKb0fd94H1VXeY/fhSvwsuIVXDGmMAEtWygqm4DtojIaP+pM4G3M90ea2QwxgQm4FbUbwMP+S2oG4CMp/WOZAU3/7qH2Hsgn5QKzSnhwpvPCy2rYnI9l95YRTymPD23mHm3DolElus8V1lXzVrDxNNrqduZz+XnBTYTf4dcfoau9+0wAXf0VdVVQI+mNe+VU9QgOvB1Zfpd5/Dvv/5CqJVbLKZMn72V758/gosmj2bKtDqOG7U/57Nc57nMen7BMH5w2YRQym7L9d/M5b51KMtW1eqta3AtHfhOxFufYW0vbUePjJ7QQNXGfLZt7kNTMsaiBYVMmro757Nc57nMWr2yiD31btYLdf03c7lv7Ql6JEMQnFdwrTrw3QNeBz5VrQsyQxFuvugp7vvOY0w7JePrkmk7emiSmqr8g49rqxOUlCZzPst1nut9cyWq+9UZSWlaN1d64xpc6w58JwErgCtVdW/rF/kd/y4GyB9QlFHAJbdPo6Z+AEUD9nHzRU+yaXshq94bFszWG2PaZ4PtgTQ78KnqnJZOgHl9MuvAXFPvvX7X3n68uGYEY8prer7V7dixLcHgYYdGj5SUJqmtDucUwWWW6zzX++ZKVPerM0f8KSoBdeDrSN9Ekv59Gg/enzjqfTZsy+wIMF3vrOpP2YhGhpQfIC+RYvK0OpZWFuR8lus81/vmSlT3q1NZ1sjg/BRVVbeJyBYRGa2q79DNDnwdKR64j5/8+7MAxGNK5arjWfrucUEV/yGpZuG2mWXMfngDsThUPlLMpnf75nyW6zyXWTNueotxFbsYVJjkgcrFPHjHSCrnl4WS5fpv5nLfOpJtM/qKqvstEpHxwN3AwQ58qrqro9cPOLpcP/65q5xsW8GDS53kmOA4ndG3JpzLHR1xtW9Ldj7K7uT2Hi00NaCkXD/+ue+m9drXHrh6har2qI9bOnqlo28QHfiMMVkmx1bVMsaYtLX0g8smVsEZY4LTC5e8OmMVnDEmMHYEZ4yJpizs6GsVnDEmMNbIYIyJLKvgjDHRpFgjQ3fkNTRRvGKHk6xmJykmSC473z5btcpZFsDUYeOd5Kg2BVJOkI0MIhIHlgNbVfWc7pRhazIYY4IT7FjUK+nhXJFWwRljAhHkhJcicizwObwhnd2WE6eoxpgcoIFOZvlrYAYwsCeF2BGcMSY4AaxsLyLnANtVdUVPN8eO4IwxgcmgkaG2k9lETgPOFZHPAn2BQSLyoKp+PdPtsSM4Y0wwFEhperfOilG9XlWPVdXhwFeAP3encgM7gjPGBCm7usFZBWeMCU7Qg+1VdRGwqLvvtwrOGBMYl0sCpiNyFVzJ4Aauvu41ior2oyo886cRLHh8VGh5FZPrufTGKuIx5em5xcy7dUgkslznRSXrF98tZ9nzgygsaWLOC+8A8ONLPsL7f/PWYthbH2fAoGbueP6dwDJbuP5+HOZImk1ERO4FWpp7x/rPFQO/A4YDG4EvdbYWQ3c0Nwt33zmOv60vol+/JDffuZCVK4awZdOgIGMAiMWU6bO3cv1XRlJbneCWp9az9NkCNq8PfmERl1mu86KUddaXd3LuhbX87MpDCx3NvGvTwft3zRrGgIHBDwh0/f1oj9fRN7tquDBbUe8Dzm7z3HXAQlUdBSyknfVQe2rXzn78bb23TOC+fQk2bxpIScm+oGMAGD2hgaqN+Wzb3IemZIxFCwqZNHV3zme5zotS1j+cupeBRe1XYKrw0hOFTPl8oP+nA+6/Hx1KpXlzJLQKTlVfAna2eXoacL9//37g82HlAxwzZC8fPb6OdWuLQyn/6KFJaqryDz6urU5QUprM+SzXeVHNamv1sgEUDW6ibGRj1y/OUG/uV2uimtbNFdfX4IaoarV/fxvQ4UUCv2fzxQB9E5mfXvbt28TMHy5hzu3j2dcQ7dXETW544Q9FTA7h6C1rZOE1uF7r6KvegqwdfhyqOkdVK1S1Ij/eP6Oy4/EUM3+4hEULj+OVl8Nb+HbHtgSDhx3637ikNEltdTiVqcss13lRzWqtuQn+8lQB/3RuXSjl99Z+fZg3FjWdmyuuK7gPRKQUwP+5PfgI5aprlrNl80DmP3pC8MW38s6q/pSNaGRI+QHyEikmT6tjaWVBzme5zotqVmsrFw+k/PgDDB4Wzmljb+3XYVTTuzni+hT1CeAC4Cb/54KgA8aM3cGZZ23mvQ0F3HLXcwDcf89Ylr9aGnQUqWbhtpllzH54A7E4VD5SzKZ3w2m1cpnlOi9KWf/vso/w5pKj2L0zj/P/cQzfuHobZ39tJy8uCPf01PX3o11ZuPCzaEi1qYjMBSYDJcAHwA3AH4B5wHHAJrxuIm0bIg5T0K9UJ428MJTtbKt57XonOSY3RXVG32W6kHrdKT0pY9BRZXrKSZel9drnX/nBik4G2wcmtCM4Vf1qB786M6xMY0wvy7JGhsiNZDDG9B5JZdc5qlVwxphgKE478abDKjhjTCAEt51402EVnDEmOFbBGWMiyyo4Y0wkZeE1OFuTwRgTGEml0rp1WY5IuYi8ICJvi8gaEbmyO9tjR3DGmIAEOgyrCbhaVVeKyEBghYg8p6pvZ1JITlRwmhejqXiAk6z6r5/qJAeg4MGlzrIA4oMHO8tqrqlxluXSWV/8ptO8rddnNtFEdyXvDeC7qARWwfmzDlX79/eIyFqgDIheBWeMyRHpX4MrEZHlrR7PUdU57b1QRIYDE4BlmW6OVXDGmMBk0A+us4WfD5UnchTwGHCVqtZnuj1WwRljghNgNxERSeBVbg+p6s7Qiu8AAAuMSURBVOPdKcMqOGNMMFShOZh+IiIiwD3AWlX9ZXfLsW4ixpjgBDfh5WnAN4AzRGSVf/tspptjR3DGmOAE14r6Mt5KhD1iFZwxJhgK2Mr2xphoUtDsGqsVuQoukWjmFz96mkReing8xeKlw/ntvPCmfZ5/3UPsPZBPSoXmlHDhzeeFllUxuZ5Lb6wiHlOenlvMvFs7XHWxx66atYaJp9dStzOfy8+bFFpOC5f75irL5XdxeOEufnH2cwcfH1tQz61LP8Fv3zgplLx2KYE1MgQltApORO4FzgG2q+rYVs9/G5gONAN/UtUZQeYmkzFmzJrK/v0J4vEUv7rxaV57vYx168PrxT/9rnPY3dAvtPIBYjFl+uytXP+VkdRWJ7jlqfUsfbaAzevDWVjk+QXD+OPccq7+8ZpQym/N5b65zHL5XdxYV8R5j3wJgJikeOHCB3h+w8jAc7qUZbOJhNmKeh9wdusnRGQK3ur2J6nqx4GfBx8r7N/vrQeZF/f+58y2eeK7Y/SEBqo25rNtcx+akjEWLShk0tTdoeWtXlnEnno362q63De3n2PvfBdPPXYrW3YXUL1nYPhhbR0pywaq6kv+EIvWLgNuUtUD/mtCWBcVYrEUt/3kSYYN3cMTz5zIur+Gd/SmCDdf9BSqMH/Zx1iwbEwoOUcPTVJTlX/wcW11ghNPbgglyzWX++b6c3T5XWzxmRP+ylPrjw8953BuK690uL4GdwLwaRH5MbAfuEZVX2vvhSJyMXAxQN8+mS1gm0rFuOzacxnQv5Ebrn2B4eW72LilqIeb3r5Lbp9GTf0Aigbs4+aLnmTT9kJWvTcslCyTe1x+FwESsWamjNjIr185JbSMDimQZYvOuO7omwcUA6cC1wLz/B7Lh1HVOapaoaoViUT3ZhLZ25DPG2uGUjF+a7c3uCs19d627drbjxfXjGBMeTizaOzYlmDwsMaDj0tKk9RWuzmFDJvLfeutz9HFdxHgUx/ZzNs1JezY52YWksNk2Smq6wrufeBx9byKN/dASZABBYP2M6C/9wXOz2/i5HFVbNma2RFguvomkvTv03jw/sRR77NhWzj/O7+zqj9lIxoZUn6AvESKydPqWFoZzn655nLfXGa5/C62+OwJf+Wpd0eFmtExf6hWOjdHXJ+i/gGYArwgIicA+UBtkAHFhQ1ce8VfiMWUmCgvLhnOspXlQUYcyhq4j5/8+7MAxGNK5arjWfrucaFkpZqF22aWMfvhDcTiUPlIMZveDacFFWDGTW8xrmIXgwqTPFC5mAfvGEnl/LJQslzum8ssl99FgH55ST5ZvoVZL5weWkanFDTL+sGJhnS4KCJzgcl4R2gfADcAvwXuBcYDjXjX4P7cVVmDBpbpxPGXh7KdbdWPCK/SaMsmvMw9elp4fSrbs/V0N6eaG+/9Jfuqt/RoaFRB3mCdNOjzab322V13r0hnuqSeCrMV9asd/OrrYWUaY3rZEd6KaoyJKtWsa0W1Cs4YExw7gjPGRJOizc29vREfYhWcMSYYNl2SMSbSsqybiE1ZbowJhAKa0rRu6RCRs0XkHRH5q4hc151tsgrOGBMM9Se8TOfWBRGJA7cBnwHGAF8VkYxnsrBTVGNMYAJsZJgI/FVVNwCIyCN4U61ltLJ9aCMZgiQiNcCmbry1hICHglmWZeVAXneyPqKqPRrqIiLPkP7Y8r54Mwq1+NDK9iLyBeBsVf1P//E3gFNU9YpMtiknjuC6+8GLyHIXw0Esy7KyKc/1vrVQ1bO7fpVbdg3OGJONtgKtZyY41n8uI1bBGWOy0WvAKBEZISL5wFeAJzItJCdOUXtgTtcvsSzLilye630LnKo2icgVwLNAHLhXVTNeASknGhmMMaY77BTVGBNZVsEZYyIrchWciNwrIttFZLWDrHIReUFE3haRNSJyZch5fUXkVRF5w8+bFXJeXEReF5Enw8zxszaKyFsiskpEloecVSgij4rIOhFZKyKTAiz7sO+fiBSLyHMist7/GdjCHR1930Xk2/7+rRGRnwaVl2siV8HRzoLTIWoCrlbVMXgrhU3vznCSDBwAzlDVk/CmfT9bRE4NMe9KYG2I5bc1RVXHO+jD9T/AM6p6InASwe7jfRz+/bsOWKiqo4CF/uPQ8twssJ4bIlfBqepLwE5HWdWqutK/vwfvH0o4K7N4Gaqqf/cfJvxbKK1EInIs8Dng7jDK7y0iUgCcDtwDoKqNqloXVPkdfP+mAff79+8H0lu4oPt5ThZYzwWRq+B6i4gMByYAy0LOiYvIKmA78JyqhpX3a2AG3tKOLihQKSIr/EW/wzICqAH+1z/9vltEurfwbvqGqGq1f38bMCTkvJYF1peJyIsi8omQ87KWVXABEJGjgMeAq1S1PswsVW1W1fF4PbsnisjYoDNE5Bxgu6quCLrsTnxKVU/Gmz1iuoiEtfZdHnAycIeqTgD2EuwpY6fU65cVdt+stBdYjzqr4HpIRBJ4ldtDqvq4q1z/tOoFwrneeBpwrohsBB4BzhCRB0PIOUhVt/o/twPz8WaTCMP7wPutjnwfxavwwvSBiJQC+D/DPmUMfYH1XGEVXA/4/yveA6xV1V86yBssIoX+/X7AvwDrgs5R1etV9VhVHY43RObPqhraco8iMkBEBrbcB84CQmkFV9VtwBYRGe0/dSYZTsHTDU8AF/j3LwAWhJzXssA6YS2wnisiN1Sr9YLTIvI+cIOq3hNS3GnAN4C3/OtiAP+lqk+FlFcK3O9PBhgD5qlq6F04HBgCzPfPovKAh1X1mRDzvg085I9x3ABcGFTB7X3/gJvwThO/hTft15dCzrsXuNfvOtIIXKBH6JAlG6pljIksO0U1xkSWVXDGmMiyCs4YE1lWwRljIssqOGNMZFkFFwEi0uzPwrFaRH4vIv17UNZ9/opG+MOYOpw8QEQmi8gnu5GxUUQO63ja0fNtXvP3zn7fzut/KCLXZLqNJhqsgouGff4sHGPx+j1d2vqXItKt/o6q+p+q2lkn2MlAxhWcMa5YBRc9i4Hj/aOrxSLyBPC2P0j/ZyLymoi8KSKXgDcaQ0RuFZF3ROR54JiWgkRkkYhU+PfPFpGV/lx0C/3JBS4FvusfPX7aH2nxmJ/xmoic5r/3aBGp9OcmuxvoclykiPzBH3i/pu3gexH5lf/8QhEZ7D/3URF5xn/PYhE5MYgP0+S2yI1kOJL5R2qfAVpGAZwMjFXV9/xKYreqfkJE+gB/EZFKvBlQRgNj8EYUvI3XE751uYOB3wCn+2UVq+pOEbkT+Luq/tx/3cPAr1T1ZRE5Dm/BkI/h9a5/WVV/JCKfA76Vxu78h5/RD3hNRB5T1R3AAGC5qn5XRP7bL/sKvIVWLlXV9SJyCnA7cEY3PkYTIVbBRUO/VkPFFuONj/0k8Kqqvuc/fxYwruX6GlAAjMKbG22uqjYDVSLy53bKPxV4qaUsVe1ovr1/Bsa0mrhikD/TyunAv/nv/ZOI7Epjn74jIv/q3y/3t3UH3sDx3/nPPwg87md8Evh9q+w+aWSYiLMKLhr2+VMoHeT/Q9/b+ing26r6bJvXfTbA7YgBp6rq/na2JW0iMhmvspykqg0isgjo28HL1c+ta/sZGGPX4I4czwKX+dM7ISIn+DN3vAR82b9GV4o/C0UbS4HTRWSE/95i//k9wMBWr6vEG8iO/7qWCucl4Gv+c58BulqToADY5VduJ+IdQbaIAS1HoV/DO/WtB94TkS/6GSIiJ3WRYY4AVsEdOe7Gu7620p9l4i68I/j5wHr/dw8AS9q+UVVrgIvxTgff4NAp4h+Bf21pZAC+A1T4jRhvc6g1dxZeBbkG71R1cxfb+gyQJyJr8WbiWNrqd3vxJvpcjXeN7Uf+8+cD3/K3bw3eNOHmCGeziRhjIsuO4IwxkWUVnDEmsqyCM8ZEllVwxpjIsgrOGBNZVsEZYyLLKjhjTGT9f3Kkd7l6mlOOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky_AUHwpFi1k"
      },
      "source": [
        "### Hinge loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMKjQ7rRFi1l"
      },
      "source": [
        "\r\n",
        "### Matthews correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCP3oMfFFi1l",
        "outputId": "3baed510-f223-4f28-c86d-769eb8ea5e12"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\r\n",
        "mlp_mcc = matthews_corrcoef(y_test, mlp_pred)\r\n",
        "mlp_mcc"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5419543610867927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp478QjdFi1l"
      },
      "source": [
        "### ROC AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvpGCMTMFi1m",
        "outputId": "4e8051e2-2369-412b-fdea-3853793b6b0b"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "roc_auc_score(y_test, mlp_cv.predict_proba(X_test), multi_class='ovr')"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8959506984251056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M29rNIaFfjAW"
      },
      "source": [
        "# Resultados y análisis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1KxP9UMjo4h"
      },
      "source": [
        "Se obtuvieron modelos optimos de aprendizaja automatico utilizando por medio del metodo de Grid CV. Los modelos optimos encontrados fueron: Logistic Regresion, k Nearest Neighbors, Gaussian Naive Bayes, Kernel SVC y Redes Neuronales. A cada uno de ellos se les midieron metricas de Balanced Accuracy, Cohen's Kappa, Matriz de confusión, Matthews correlation coefficient y ROC AUC. La tabla a continuacion representa un resumen de los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNZag3yNmenS"
      },
      "source": [
        "| Nombre del modelo | Balanced Accuracy| Cohen Kappa| Hinge loss | Matthews correlation coefficient | ROC AUC |\r\n",
        "| --- | --- | --- | --- | --- | --- | \r\n",
        "| Logistic Regression | **0.5689** | **0.5416** |**0.9371** |**0.5593** | 0.8970 |\r\n",
        "| k Nearest Neighbors | **0.3480** | **0.2353** | NA | **0.2840** | 0.7826 |\r\n",
        "| Gaussian Naive Bayes | 0.4097 |  0.3112| NA | 0.3183 | **0.7210** |\r\n",
        "| Kernel SVC | 0.5618 | 0.5014 | **1.283** | 0.5099 | **0.9071** |\r\n",
        "| Redes Neuronales | 0.5377 | 0.5228 | NA | 0.5420 | 0.8960 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxRjhMt3q7la"
      },
      "source": [
        "De acuerdo a la tabla podemos notar que el modelo generado a partir del Logistic Regression nos produce el mejor resultado a excepción del ROC AUC,para el cual se tiene que el mejor es el modelo de Kernel SVC. Aun nos falta una metrica por estudiar, la Matriz de confusion que se expresa a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "457N4XdUrWRx",
        "outputId": "be3a8b09-6dc0-4d1c-b625-299e93f5eff5"
      },
      "source": [
        "\r\n",
        "plot_confusion_matrix(logreg_cv, X_test, y_test, normalize ='true')\r\n",
        "plt.title(\"Logistic Regression\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plot_confusion_matrix(neigh_cv, X_test, y_test,normalize ='true')\r\n",
        "plt.title(\"k-Neares Neighbors\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plot_confusion_matrix(gnb_cv, X_test, y_test,normalize ='true')\r\n",
        "plt.title(\"Gaussian Naive Bayes\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plot_confusion_matrix(svc_cv, X_test, y_test,normalize ='true')\r\n",
        "plt.title(\"Kernel SVS\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plot_confusion_matrix(mlp_cv, X_test, y_test,normalize ='true')\r\n",
        "plt.title(\"Redes Neuronales\")\r\n",
        "plt.show()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEWCAYAAAD7MitWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxU1fn/38/MZIfsC0nYdxEFFFmKIqIC1gW/rXWpWPVXRS227vvS1oWqte7a1t26obZW0YLghogCsoqAQDBs2RcSEgJJZnl+f8yQZMg2SSaTGXLer9d9Ze69557POWdunjn7I6qKwWAwdAcsXZ0Ag8FgCBTG4BkMhm6DMXgGg6HbYAyewWDoNhiDZzAYug3G4BkMhm6DMXhHCCLyDxG5px3P9RWR/SJi7Yx0BSsislBELu3qdBgCi5h5eIFHRHYCV6jqZ6GqLSKXAS8BBwEXsAO4S1U/7mgaDYbOwtTwDB1huar2AOKB54B5IhLvb5HuVvs0dB7G4AURIhIhIk+ISJ7neEJEIhrcv1VE8j33rhARFZHBnnuvisgDns/JIvKxiJSLyF4R+VpELCLyOtAX+MjTjL1VRPp74rF5nk0UkVc8GmUi8kFr6VZVF/A6EAMMaZCXR0Vkt4gUeprcUW3Iy99FZIGIVAGniEiGiPxHRIpFZIeI/KFBXONEZLWIVHi0HvNcjxSRN0Sk1FMWq0QkzXNviYhc4flsEZG7RWSXiBSJyL9EJM5z71D5XOrJS4mI3NX+b9nQlRiDF1zcBUwARgOjgHHA3QAiMgO4ETgNGAxMaSGem4AcIAVIA+4EVFUvAXYDZ6tqD1V9pIlnXweigaOBVODx1hLtqYFdDtiBXZ7LDwFDPXkZDGQC97YhL78GHgR6At8CHwHfe+I5FbheRKZ7wj4JPKmqscAg4F3P9UuBOKAPkARcjbsJfjiXeY5TgIFAD+CZw8KcCAzzaN8rIke1UCSGIMUYvODiYuA+VS1S1WLgz8AlnnvnA6+o6iZVPQD8qYV47EA60E9V7ar6tfrQWSsi6cAZwNWqWuZ59qsWHpkgIuVANfAoMEtVi0REgNnADaq6V1UrgbnAhW3Iy4eq+o2n9ngMkKKq96lqrapmAy80iM8ODBaRZFXdr6orGlxPAgarqlNV16hqRRNaFwOPqWq2qu4H7gAuPFTr9fBnVT2oqt/jNryjWigXQ5BiDF5wkUF9DQnP54wG9/Y0uNfw8+H8FdgOLBaRbBG53Uf9PsBeVS3zMfwKVY0HEoD5wEme6ym4a4lrPE3JcuATz3XwLS8Nr/UDMg7F5YnvTty1V4Df4q5NbvE0W8/yXH8dWIS7bzFPRB4RkbAmtJoqd1uD+AEKGnw+gLsWaAgxjMELLvJw/3Mfoq/nGkA+0LvBvT7NRaKqlap6k6oOBM4BbhSRUw/dbkF/D5DY1oEHT63oGuASERkDlOBuOh6tqvGeI84zwOFrXhqmcw+wo0Fc8araU1V/7tHPUtWLcDfBHwb+LSIxnhrqn1V1BPAz4CzgN01oNVXuDqCwLeVgCH6Mwes6wjyd6ocOG/A2cLeIpIhIMu4+rzc84d8FLheRo0QkGmh2zp2InCUigz1Ny32AE/fUEXD/Ew9s6jlVzQcWAs+JSIKIhInIZF8yo6p7gReBez3N0BeAx0Uk1ZOmzAZ9bj7nxcN3QKWI3CYiUSJiFZGRInKCJ+5ZIpLi0S33POMSkVNE5BhPH2MF7iauq4n43wZuEJEBItIDd/P7HVV1+JJ3Q+hgDF7XsQB3LejQ8SfgAWA1sAH4AVjruYaqLgSeAr7E3Vw91E9V00TcQ4DPgP3AcuA5Vf3Sc+8vuI1quYjc3MSzl+A2DFuAIuD6NuTpCeDnInIscNuhdIpIhSc9w9qRF1TVibt2Nhr3fL8S3MY1zhNkBrBJRPbjHsC4UFUPAr2Af+M2dj8CX+Fu5h7Oy57rSz3xVwO/b0O+DSGCmXgconhGCTcCEaFeEzmS8mIIbkwNL4QQkf/zzG9LwN1X9VGoGogjKS+G0MEYvNDiKtzNzJ9w98td07XJ6RBHUl4MIYJp0hoMhm6DqeEZDIZug631IF1PcqJV+/dpar6o/9m2ITogOobQRMIC+y+j9sB0a1ZTRa3WSEfimH5KjJbudfoUds2GmkWqOqMjeu0hJAxe/z5hfLeo2Xm2fmV6xuiA6BhCE1tKr4DqOfILWg/kB1bq5x2Oo3Svk+8W9fUprDU9K7nDgu0gJAyewWAIfhRwNTmvO3gwBs9gMPgFRbGrb03arsIYPIPB4DdMDc9gMHQLFMUZ5NPcjMEzGAx+w9XiZjxdjzF4BoPBLyjgNAbPYDB0F0wNz2AwdAsUsJs+PP+z6sue/OOeTJwu4YyLSrng90Ve9wtzwnjsxr7sK7XRM97JrU/vIiXDTmFOGPf9vwG4XILDATP/Xwln/aa0Q2kZO6WCq+/Pw2pRFr6dyLvPpLX+UAhoBVovlLSOn1jM7Ju3YLEqiz/ozXuveu+nagtzcdN9PzD4qH1U7gvnodtHUZTvdtjWf3Al1961iegYB6rC9ZdMwGZTHnnxu7rnk9Kq+XJBOi/8rW1+ggL9fhyOoqZJ2xQi8jLuDR2LVHVkW551OuHZO3vzl3k/kZxu5/c/H8qE6fvoN7R+78gX7svktPP2cvr5Zaxf1oNX/pLOrU/vJjHVweMfZREeoRyssnDVKcOZOG0fSb3at3zHYlHmzM3ljgsHUpIfxtMLslixKI7dWZHtii9YtAKtF0paFotyze0/cvfvxlJSGMnjry9nxVep7NlR7+Ji+rk57K+wceW5k5k8LZ/L/7CNh+8YhcXq4uYHNvC3e45hR1YsPeNqcTos2GuF3//6Z3XPP/nGcr79om3GKtDvR5MoOIPb3nXZ5gGv4t6lts1sXRdNRv8a0vvVEhauTJlZxvJFcV5hdm2LYNSk/QCMmrS/7n5YuBIe4f5G7DWCq4NThoaNOUDeznAKdkfgsFtY8mE8E6fv61ikQaAVaL1Q0hp69D7y9kRTkBuNw2Fh6eJ0JkzxbmGMP7mIzz/OBGDZ52mMGlcKKMdNKGVnVk92ZMUCULkvHJfLe/lqRt8q4hJq2bQuIaD58gfulRa+HV1Flxg8VV0K7G3Ps6UFYaRk2OvOk9PtlOR7bywwcEQ13yx0G7lvFsZxYL+Vir1u5/VFuWFcfeowZo09mvPnFLW7dgeQ1MtOcV543XlJfhjJ6fYWnmg/gdQKtF4oaSWlVlNSWF9rKimMJCml2jtMSg3FnjAup4UD+23ExtvJ7FuFKtz3zGqefPNbfvmbHY3iP3l6Pl9/2gto2zr+QL8fTSM4fTy6iqDdHkpEZnu8ya8uLm3bcpXZ9+byw/Ie/O70ofywvAfJ6bVY3PaO1Ew7//h8K698u5lP30ugrDgkuzENIYjVpowYXc6jdx/Lrb8dz8RTChl1gncf8uRpBXz1SWA3KPAX7kEL8enoKoLW4Knq86o6VlXHpiRZ6667f8nqa3RN/ZIl9XJw70s7ee7TbVx2ez4APeKcjcL0H1bNxpUx7U6ju7ZZW3feVG3TXwRSK9B6oaRVWhRJclp9jS45rZrSYu9+stLiCFI8YSxWF9E9HFSUh1FSGMnGdQlUlIdTU21l9TcpDBpe7xd8wJAKrFZl+xbvLppA5MsfuOfhmRqeXxk2+gC5OyIo2B2OvVZY8mECE6Z5O5PfV2qt65+b93Qq0y5wt56L88KoOegu7MpyK5tWxdB7UJOOsnxi6/poMgfUktanBluYiykzy1mxuO0va7BpBVovlLS2bY4ls88B0jIOYLO5mDwtn5VfpXqFWflVKqeelQvAiacWsmFVIiCsXZ5M/8GVREQ6sVhdHHPcXq/BjpNnFPDVovQuyZe/cKn4dHQVIdees9pgzoM53PnrgbicwrQL99J/WDWvPdKLoaMOMHF6BRuW9+Dlv2Qgohwzvoo5c3MA2J0VwQv3DXR3jyicd3UxA46qblmwBVxO4dm7Mpn7VjYWKyyel8iubZ0zKhZIrUDrhZKWy2nh748cxf3PrMFiVT79MJPd2T2YdXUWWZvjWLk0lcUfZnLz/T/wwgdLqdwXxiN3jgJgf2UYH7zRn8f/tRxVYfU3yaxallIX90mnFfDH647rknz5g0M1vGCmS3xaiMjbwBQgGbdj6D+q6kvNhR87KlLNBqCGYMCWfuRuAFqheztkrY46NkL/9bFvNdRx/XatUdWxHdFrD11Sw1PVi7pC12AwdC5d2Vz1hZBr0hoMhuBEEWrV2nrALsQYPIPB4BfcE4+DexzUGDyDweA3gn3Qwhg8g8HgF1QFp5oansFg6Ca4TA3PYDB0B9yDFsFtUoI7dQaDIWQwgxZ+4secFCbccnVAtIpfb/9Ss7Yy+JJ1AdMCsA3oFzAtx45dAdMKJIGaCHyIQH1nkhPeeiAfcAb5PLzgNscGgyFkUAQnFp8OXxCRGSKyVUS2i8jtTdzvKyJfisg6EdkgIj9vLc6QqOEZDIbQwOWnUVoRsQLPAqcDOcAqEZmvqpsbBLsbeFdV/y4iI4AFQP+W4jUGz2Aw+AX35gF+azSOA7arajaAiMwDZgINDZ4CsZ7PcUBea5Eag2cwGPyCIth9X1qWLCKrG5w/r6rPNzjPBPY0OM8Bxh8Wx5+AxSLyeyAGOK01UWPwDAaDX1ClLROPS/ywW8pFwKuq+jcRmQi8LiIjVbVZtxnG4BkMBj8h/px4nAs03BOut+daQ36LxxmYqi4XkUjcW84V0QxmlNZgMPgFxV3D8+XwgVXAEBEZICLhwIXA/MPC7AZOBRCRo4BIoLilSE0Nz2Aw+A1/DVqoqkNErgUWAVbgZVXdJCL3AatVdT5wE/CCiNyA295epq3saGwMnsFg8AuKf/1VqOoC3FNNGl67t8HnzcCktsQZkgZvwrDd3HDOt1gsyvzvhvP6l2O87l80eQPnjPsRp8tC2f5IHnx3CgXlPTluUC7Xn7O8Lly/lHLuefNUlm4a0KxW9IYKkl/PAZdSMSWJ8rO9t/juubSU5Hl5OBLcHqL2nZ5MxZRkAAb9Zh21faIAcCSFkX/joA7le+yUCq6+Pw+rRVn4diLvPtM27/THjy9i9vU/YLEoiz/qx3tvDPG6bwtzctM96xg8rJzKfeE8dO9YigqisdlcXHvr9wwZXo7LJTz/5Eh+WOfO429m/8jUGXvo0dPOeaef2WV5O1K1gvk7Oxy3m8bgNikB78MTkT6e2dGbRWSTiFzXluct4uLm//uGG176ORc9ej7TRm+nf2qZV5ituUlc9uQvmPXYr/jyh4Fce+YKANb+lMlvHj+P3zx+Htf+4yyq7TZWbuvdvJhLSXltD3m3DGL3w0fRc3kZYbkHGwWrHB/PngeHs+fB4XXGDkDDLXXXO2rsLBZlztxc7r54AFdOGcYpM8vpO8R3B0QWi3LNTRv4400TuObiqUw+LZc+/Su9wkw/azf7K8O48oLT+OCdQVz+O/eUp+nnuJeJzfnNKdx9/USuuHYTIu6Ww8pv0rjhysldmrcjVSuYv7OmMY64m8IB3KSqI4AJwBzPLGmfGNG3iJySWPL2xuJwWvl0/WAmH73TK8zanzKpsbtrXBt3pZEaX9UonlOOzWbFlj514Zoi8qcD2NMicKRGgM3C/gkJ9Fizz9ek+pVhYw6QtzOcgt0ROOwWlnwYz8Tpvqdl2JgD5OXEUJAXg8NhYennmUw4yXtd6PiTCvh8gXtgbNmSdEYdXwIofftX8v0atyHfVx7B/v1hDBleDsDWTYmUlXbMO1ZH83akagXzd9YUinulhS9HVxFwZVXNV9W1ns+VwI+4Jxn6RErsAYrK6315Fu2LISWusUE7xNnjtrB8S99G108f/ROL1w9uUctaVos9sX5RtSMxHGuZvVG4HqvK6XPnj/R6age20npnyGJ30fveLfT+01ZiVpe3qNUabgfk9WlpygF5a8+XFEXVP18USVKKd201KaWaYk8Yl9PCgSobsXG17Ngey4QTC7BYXaSlVzF4WDnJaY1ruu2lo3k7UrWC+TtrjmCv4XVpg1tE+gNjgJVN3JsNzAYIj0loV/wzjtvGUb2Luebv53hdT+pZxaBee1mxtYXmrI9UjYmjcmIChFmI/aKE1H/uIu9Odz/LzsePxpkYjq2ohsy/bKemTxSOtIgOawaaxf/rS5/++3nypaUUFUTz48ZEXM7g3hWju9MV35mqdGntzRe6zOCJSA/gP8D1qlpx+H3PMpPnAWKS+tQNNRdXRJMav78uXGpcFcX7YhrFf8KQHC6buo5r/n4Odqf3cpdTR2Xz1cb+OF0tL4NxJoQTtre+xmbbW4szwbsJ7OpZX4QVU5JImlc/N9LpqR06UiM4OLwHEbsOtNvglRaEkZJRn5bkdDsl+c03x5t6Pjm1vjmVnFpNaXGUd5jiSFJSD1JaHIXF6iI6xkHFvnBAeOGpkXXhHv3H1+Tu6YG/6GjejlStYP7OmsI9aBHcXsu6xByLSBhuY/emqr7flmd/3JNKn+R9pCdUYLM6OX30dr7e7L1n2NCMEm775dfc8uoMyqqiGsUxbfT2VpuzANUDowkrqMFWVAMOFz1WlFF1XJxXGGt5fRMlZu0+7BnuvhFLlQPs7hUulkoHkVlV1Ga2v99k6/poMgfUktanBluYiykzy1mxOK71Bxs+37uKtPQqbDYXk0/NZeUy7xHDlct6cerP3csXT5ySz4Y1yYAQEeEgItIBwOgTinA6hT07e7Y7L/7O25GqFczfWdOIPycedwoBr+GJiAAvAT+q6mNtfd7psvDoByfy5JULsFiUj78bxo7CRK6ctootOSl8vbk/vz9rBdHhdh685FMACst6cMurMwBIT6gkNX4/67IzWhezCsW/6U3GX39CXErF5CRqe0eR+J98qgdEc+C4OOIXFRO9bh9YwNnDRuFst/ENz60m5ZU9IIBC2Vlp2DMbG19fcTmFZ+/KZO5b2VissHheIru2+W5AXU7h748fw/2PrcBiVT79uC+7d8Qy64otZG2JZ+WyXiz+uC8337OWF975jMqKcB754/EAxCXUcv/jy1GXUFocyaP3HVcX7+W/28SU03OJiHTy2n8Xs+ijvrz18vCA5u1I1Qrkd/btfR3Pr3vQIri7OqSVicn+FxQ5Efga+AE4tMj3Ts8kwyaJSeqjR//8+kAkj+IZZsdjf3Ck7ngcaAL1nX2b8wb7ago6ZK3Sj07QS98+1aewD4/6zxo/bB7QZgJew1PVZRDkro0MBkOb8fdKi84guKdFGwyGkMI48TEYDN0CVbC7jMEzGAzdAHeT1hg8g8HQTejKVRS+YAyewWDwC6EwLcUYPIPB4CdMk9ZgMHQj/OjTolMICYNn3VtF3JsrAqNVe7gnuM5jwveds0tHc6wYZSYDhxqBmsCtWtt6oFbjAHsr69O7mpAweAaDIfgxE48NBkO3wjRpDQZDt8CM0hoMhm6FGaU1GAzdAlXBYQyewWDoLpgmrcFg6BaYPjyDwdCtMAbPYDB0C8w8vC5i7JQKrr4/D6tFWfh2Iu8+k9b6Q80wfvgerv/Ft1gsykcrhvPGZ6O97l8wZQNnT9yC02WhfH8kc986mcIyt7OUpY+/QHZeIgCFZTHc9uKMFrXKvxF2PmxFXZD6fy4yf+vyur/zrxYqVrk7hV0HwV4GJyxzO2pZMcZGtNs7JBG9lGFPOdud50P4sxyN1pGl1RxmHt5hiEgksBSI8Oj/W1X/6K/4LRZlztxc7rhwICX5YTy9IIsVi+LYndV2Ry0WcXHTr5Zx/XNnUlQew4s3/ZdlP/RjZ2G9n9ysnGR+++gvqLHbOHfSZuacs5J7XzsNgBq7lcv++kuftNQJO+ZaOeqfDsLTYOOvbSRMcRE9qD5M/1tcHHIDUvCWhaot9S+XJQKOfdfR5jw2hz/L0WgdWVrNoQqOIN8AtCtSVwNMVdVRwGhghohM8Ffkw8YcIG9nOAW7I3DYLSz5MJ6J0/e1/mATHNWvmJziOPJKY3E4rXy+dhAnHbPTK8za7RnU2N2/G5t2ppISX9Uurf0bhcg+SmRvsIRB0gwXZUua/3pKPhGSznA1e7+j+LMcjdaRpdUSLhWfjq4i4AZP3RzypB3mOfzmOi2pl53ivPC685L8MJLT27dIPyWuiqLyeiffReUxpMQ1b9DOnrCFFT/2qTsPtzl56ab3ef6GDxoZysOpLYLwXvXn4alKbWHTYWvyoCZXiBtXX2yuWvjhIisbZ1nZ+0XHXyh/lqPROrK0muNQH14wG7wu6cMTESuwBhgMPKuqK5sIMxuYDRBJdGAT2A6mjc1ieN8S5jx1dt21X/7515TsiyEjqYKn5nxMdl4iuaWxHdYq+cRC4mkupMHGFMctdDeFq3Ng85U2ooc4iOzTfBwGQ2egQT5o0SUNblV1qupooDcwTkRGNhHmeVUdq6pjw4jwOe7SgjBSMuq3uklOt1OSH9audBbviyG1QRM1Nb6K4n0xjcKNHZrDpaev49YXpmN31luhEk/YvNJY1m3PYEjvkma1wlOhtqD+vLZICG+mz7n0EwvJZ3hXig+FjewNsWPVq3+vPfizHI3WkaXVEi7Ep6Or6NIeRlUtB74EWh6+bANb10eTOaCWtD412MJcTJlZzorFce2Ka8vuFHqn7CM9sQKb1cmpx/3Eso3ejpGHZJZw6wVfc9uL0ynfH1V3vWdUDWFW90hpXEw1xwwsYGdBAs3R42ilerdQnQMuu9uoJZzcuI/u4A5wVEKPUfUGz1HhbtKCe+R2/3ohamDHegn8WY5G68jSag7V4O/D64pR2hTArqrlIhIFnA487K/4XU7h2bsymftWNhYrLJ6XyK5t7RupcrosPP6fSTx2zUKsFhcfrxjGjoJErjhjNVv2JLNsY3/mzFxJVISDBy77DKifftIvrYxbL/galwoWUd74bLTX6O7hiA363+FkyzU297SUc11ED4Y9z1qIOVpJnOI2YCWfWEie7kIavDMHs4Xs+62IBdQFGZc7vUZ324M/y9FoHVlazSM4g3yUVlT9Nl7gm6DIscBrgBV3DfNdVb2vpWdiJVHHy6mBSB77fxW4HY9Pu3tZwLQAVowKfBPHEBqs1M+p0L0dqnr1GJquI5++zDe9GQ+tUdWxHdFrDwGv4anqBmBMoHUNBkPnYtbSGgyG7oO6+/GCmeBucBsMhpDCn6O0IjJDRLaKyHYRub2ZMOeLyGYR2SQib7UWp6nhGQwGv6B+HLTwzNV9FvegZg6wSkTmq+rmBmGGAHcAk1S1TERSW4vX1PAMBoPfUPXt8IFxwHZVzVa3D8l5wMzDwlyJe+FCmVtbi1qL1Bg8g8HgN1TFpwNIFpHVDY7Zh0WVCexpcJ7judaQocBQEflGRFaISKvzeU2T1mAw+AV37c3nUdoSP0xLsQFDgCm4V20tFZFjPAsamn3AYDAY/IIfp6XkAg1Xg/f2XGtIDrBSVe3ADhHZhtsArmouUtOkNRgMfsOPfXirgCEiMkBEwoELgfmHhfkAd+0OEUnG3cTNbilSU8M7jB7vNdq4pdNY8V5gVz6ELUkPmJZ9Sn7AtAJJ0bU/C6he6jPfBlSvIyiCy0+jtKrqEJFrgUW4V2W9rKqbROQ+YLWqzvfcmyYimwEncIuqlrYUrzF4BoPBb/hz3rGqLgAWHHbt3gafFbjRc/iEMXgGg8E/tG3QokswBs9gMPiPIF9aZgyewWDwGyFbwxORp2nBXqvqHzolRQaDISRRwOUKUYMHrA5YKgwGQ+ijQKjW8FT1tYbnIhKtqgc6P0kGgyFUCfntoURkomeeyxbP+SgRea7TU2YwGEIP9fHoInwZtHgCmI5nlrOqfi8ikzs1VR1k7JQKrr4/D6tFWfh2Iu8+04z7r26u5VpZjfOZCnCC5cxorBf3aBzmy4M4X90PAjLIhu2eBFzratzPHWK3A+u9CVhOar8PhVAtx58N3M0tpy/DIsoH3x/FK8uP87p/3phNnH/8RlwqHKgN44GFJ5NdksjR6YXc8/OvABDgH1+P5cttAzuSrYCWYdNI6A5aNERV94h4ZcTZUWHPflergVxVPauj8R3CYlHmzM3ljgsHUpIfxtMLslixKI7dWf53aBLKWupUnE9WYHs0EVKsOK4uwTIpAulfv/pDcxw439yP7ZkkpKcFLXN/7ZYxEVheSnGHqXDhuLgIOcF3V5qdnbdAaVnExe3Tv+aat8+msCKGNy//D19l9Se7JLEuzMJNQ/j3uqMBOHnIDm489VuufecsfipO5OKXz8OpFpJjqnjnindZmtUfp7ZvpUIgy7BFQr1JC+wRkZ8BKiJhInIz8KMftK/zUzxeDBtzgLyd4RTsjsBht7Dkw3gmTt/nb5mQ19ItdiTTimTYkDDBMjUK1zc1XmFcHx/Aem4M0tP9mkiCtXE8X1Uj4yOQyPb/sodqOY7MKGJPWRy55bE4XFYWbR7MlCE7vcJU1YbXfY4Kc9R9rnaE1Rm3cJsT7aCv1kCWYbMoqEt8OroKXwze1cAc3HtR5QGjPeftRkR6A2cCL3YknqZI6mWnOK/+JSvJDyM53e5vmdDXKnZCSr0BkxSL+1oDdI8DzXHguLYExzUluFZWN4rG9cVBLFOjGl1vC6Fajqk9qyisqHfMXlgZQ0rPqkbhzj9+I/OveZPrpi7nkcUn1l0fmVHIv6+cx3tXvsODCye3u3YHgS3DlhEfj66h1SatqpYAF/tZ9wngVqBncwE8GwLOBogk2s/yBp9wupu11ieSoNiJ4w+lyMvhdTU+LXWi2Q5kXPubs92Bd9eM5N01I5kxYhtXTFrDvR+7XY5uzEvjvBcuZEBSGfed/QXf/NSXWmeIrwUI9SatiAwUkY9EpFhEikTkQxFpd++qiJwFFKnqmpbCqerzqjpWVceG4fs/VGlBGCkZtXXnyel2SvI7Z1eSkNZKsXrV6LTY5VXjA5AUK5ZJkYhNkHQb0seG5tY3y1xfViMnRSC2jv1ih2o5FlXGkBZbX6NL61lFcWVMs+EXbR7ClKE7G13fUZrAgVobg1P2tisdENgybJEgH6X1pQ79FvAukA5kAO8Bb3dAcxJwjojsxL1P/VQReaMD8XmxdX00mQNqSetTgy3MxZSZ5axYHOev6I8YLRkWhgIhzDMAACAASURBVOY40XwHald30/Rn3j8scmIErvXufyItd6F7HEh6fQ1EPz+I5dSONWchdMtxU14qfRPKyYirwGZxMn3EdpZk9fcK0zehfvPdkwbvYk+ZWysjrgKruABIj61kQFI5efuabfC0SiDLsFkOTTz25egifKk/R6vq6w3O3xCRW9orqKp34PY0hIhMAW5W1Vntje9wXE7h2bsymftWNhYrLJ6XyK5tnTNSFcpaYhOs18XiuGUvuMByRhQyIAzny5XIsDB3zW5cBLK6FvulxWAB69WxSJynOZvvQIudyKjwVpQCn7dAaTnVwsOLT+K5Cz/GYlE+/H442SWJXDP5Ozbnp/BV1gAuGLuR8f1zcLgsVFRHcM9HUwEY0yefyyeuw+Gy4FJh7qLJlB9s/49HIMuwJYJ94rFoMykUkUNj67cBZbhrYwpcACR4DFfHxOsNXovTUmIlUcfLqR2V6/aYDUA7zpG6AehK/ZwK3duhqldE/97a6+7rfAq7+8pb1/jBp0WbaamGtwa3gTtUCFc1uKd4amkdQVWXAEs6Go/BYAgOJMhreC2tpR0QyIQYDIYQp4sHJHzBpzFwERkJjADqOgVU9V+dlSiDwRCKdO2AhC+0avBE5I+4PQONwL2//BnAMsAYPIPB4E2Q1/B8mZZyHnAqUKCqlwOjgACPdxsMhpDA5ePRRfjSpD2oqi4RcYhILFCEt4Ncg8FgCO0NQBuwWkTigRdwj9zuB5Z3aqoMBkNIErKjtIdQ1d95Pv5DRD4BYlV1Q+cmy2AwhCShavBE5LiW7qnq2s5JksFgMHQOLdXw/tbCPQWm+jktzVLTN5ptd40LiNbQq78LiE5XEMjVD/t/NT5gWj3eWxkwrejCDu99e0QTsk1aVT0lkAkxGAwhjgIh7KbRYDAY2kao1vAMBoOhrYRsk9ZgMBjaTJAbPF92PBYRmSUi93rO+4pIYEYQDAZDaHEE7Hj8HDARuMhzXgk822kpMhgMIYmo70dX4UuTdryqHici6wBUtUxEOr7NrcFgOPI4AkZp7R6n2QogIil06fJfg8EQrAT7oIUvTdqngP8CqSLyIO6toeZ2aqoMBkNoEuR9eL6spX1TRNbg3iJKgHNV9cdOT5mPRG8qJ/Xd3eBS9k1KoWxGhtf92G+LSX5/D454dyu8fEoqFSem+k1/7JQKrr4/D6tFWfh2Iu8+k+a3uLtSy99644fv4fpffIvFony0YjhvfDba6/4FUzZw9sQtOF0WyvdHMvetkyksc3vxWvr4C2TnuV2sFJbFcNuLM9qfKUy+Oo0u7p/zBV82AO0LHAA+anhNVXe3V9TjorEScAKOdjvzcCmpb+8i97ph2BPC6feXTVQdm0Bthrf3p/3HJ1J0Uf/2JrdZLBZlztxc7rhwICX5YTy9IIsVi+LYneV/b1GB1PK3nkVc3PSrZVz/3JkUlcfw4k3/ZdkP/dhZmFAXJisnmd8++gtq7DbOnbSZOees5N7XTgOgxm7lsr/+0uQrQPnqEEFu8Hxp0v4P+Njz93MgG1joB+1TVHV0RzwXRe7cjz01AntKJNgsVJyQRMyGMj8kzTeGjTlA3s5wCnZH4LBbWPJhPBOn7wt5LX/rHdWvmJziOPJKY3E4rXy+dhAnHbPTK8za7RnU2N2/v5t2ppISX9VETB3H5KtzEZdvh09xicwQka0isl1Ebm8h3C9FREWkVVvSqsFT1WNU9VjP3yHAOIJkPzxbmR1HQr3zaEd8OGFltY3C9VhXRr/7fyD9n1nY9tb4TT+pl53ivPoB65L8MJLT7X6Lv6u0/K2XEldFUXlM3XlReQwpcc3/4589YQsrfqzfYzbc5uSlm97n+Rs+aGRQ2orJV2jgGSh9FrdLiRHARSIyoolwPYHrAJ92kGjzSgtVXSsiHd0KQ4HFIqLAP1X1+cMDiMhsYDaANTG+3UL7j42n8oQkNMxC3NIier2WTc4NR7U7PkPnMm1sFsP7ljDnqbPrrv3yz7+mZF8MGUkVPDXnY7LzEsktje3CVLadIzVfjfBfk3YcsF1VswFEZB4wE9h8WLj7gYeBW3yJ1Jc+vBsbnFqA44A8XyJvgRNVNVdEUoFPRWSLqi5tGMBjBJ8HiOjXu8lidCSEYSurr7HZymuxJ3hPEXT1CKv7vO/EFJLf39PBpNdTWhBGSkZ9jTI53U5JflgLT4SGlr/1ivfFkNqgKZcaX0XxvphG4cYOzeHS09cx5+mzsTutdddLPGHzSmNZtz2DIb1L2m0YTL46Ef8OWmQCDf9ZcwCvipZnz84+qvo/EfHJ4PnSh9ezwRGBuy9vpi+RN4eq5nr+FuGe8tKupWrV/XoQVlSDraQGHC5iV5VSdax3bdC6r/4l6PF9GbXp/uvE3bo+mswBtaT1qcEW5mLKzHJWLO4c/0aB1PK33pbdKfRO2Ud6YgU2q5NTj/uJZRv7eYUZklnCrRd8zW0vTqd8f/2gU8+oGsKs7j3o4mKqOWZgATsLEmgvJl+djO/TUpJFZHWDY3ZbZETEAjwG3NSW51qs4Xna0T1V9ea2RNpKnDGARVUrPZ+nAfe1KzKrUHxBP3o/tQVcUPGzFGozokman0N1vxiqRiWQ8EUhMRvKwQLOGBsFlw70V1ZwOYVn78pk7lvZWKyweF4iu7Z1zqhYILX8red0WXj8P5N47JqFWC0uPl4xjB0FiVxxxmq27Elm2cb+zJm5kqgIBw9c9hlQP02jX1oZt17wNS4VLKK88dlor1FQky//56tD+F7DK2llwDIXb2dhvT3XDtETGAksERGAXsB8ETlHVVc3F6moNp1CEbGpqkNElqvqRB8z0SoiMhB3rQ7cBvctVX2wpWci+vXWXndd568ktMiRvONxIDlSdzwOZL4gcHlbqZ9ToXs7tC4sKqOP9v/tja0HBLY8cOOalgyeiNiAbbjn/+YCq4Bfq+qmZsIvAW5uydhByzW873D3160XkfnAe0Bdh4Wqvt9SxM3h6YQc1Z5nDQZDEOPHPjxPZetaYBFgBV5W1U0ich+wWlXntydeX0ZpI4FS3D4sFPdqCwXaZfAMBsMRjB8nHqvqAmDBYdfubSbsFF/ibMngpXpGaDdSb+jq4vclcoPB0M0IcsvQksGzAj3wNnSHCPJsGQyGriCU19Lmq2r7Rk8NBkP3JIQNXnDv5GcwGIIL9X2dbFfRksE7NWCpMBgMRwahWsNT1b2BTIjBYAh9QrkPL2iIjTnItON+CIjWzoCoHPkEcjKwjB0ZMK2eOzpne6fmCHL70ZggT3BIGDyDwRACdPH27b5gDJ7BYPALgmnSGgyGboQxeAaDoftgDJ7BYOg2GINnMBi6BUeCm0aDwWDwGWPwDAZDdyGUl5YZDAZDmwj2Jq0vTnyCjgPLneScV03OL6opf62x7829j9WSe3E1uRdXk/PLanZNPVh3r+APNeyaepDCG/zjn3bslApe/HoLr3zzI+dfW+iXOINBK9B6/tQ6/rg8XnxuPi//80PO/2XjHcFHHl3IM48v4H//fYsTf7a70f3oKDuvv/w+v7tqVVBptUag349G+OrApwuNYpcYPBGJF5F/i8gWEflRRHz2maFOZe8jdtKeDCfznQiqFjmpzfauRyfeGE7mm5FkvhlJ7Pk2Yk6pd40XN8tGyp/DD4+2XVgsypy5udx98QCunDKMU2aW03dItV/i7kqtQOv5U8ticTHnqlXc/edTmD3nLKZM3knfPvu8whQXx/C3Jyfy5Vf9m4zjNxd/z8ZNqUGl1XpaAvt+NIsxeE3yJPCJqg7H7d/iR18frNnkwtZbCMu0IGFCzDQrB5Y6mw1ftdhJzLR6gxc1zopEdyDlDRg25gB5O8Mp2B2Bw25hyYfxTJy+r/UHg1wr0Hr+1Bo2pJT8/J4UFPbE4bDy1df9mDje2xdxYVEPduxMQLXxDmiDB5USH1/N2nXpQaXValoC/H40xaGVFr4cXUXADZ6IxAGTgZcAVLVWVct9fd5ZDLa0+pfHlio4i5suQUe+C0eei8ixnZPNpF52ivPqa4sl+WEkpzduYoeaVqD1/KmVlHSQ4pL6X7SSkmiSkg628EQ9Isrs/7eWF185Lui0Wk1LgN+P5hCX+nR0FV1RwxsAFAOviMg6EXnR45/WCxGZfchJb3VZ+/rbqhY7iZ5qRaxmL1ND65z18218tyaDklI/NQGCRCtghEAfXleM0tpwu3/8vaquFJEngduBexoGUtXngecBUkYk1RWRNQUchfUl5ihSrClNG7SqT50k3hrm9wwcorQgjJSM2rrz5HQ7JfmdoxdIrUDr+VOrtDSKlOQD9XElH6C0NMqnZ48aVsLIo4s4+4wsIqMc2GxODh608cq/xnS5VmsE+v1ojmAfpe0Kg5cD5KjqoQ3T/o3b4PlExAgLjj2KPdeFLVWoWuwk5f7GgxC1O104KyHimM6rxG5dH03mgFrS+tRQWhDGlJnlPDSnX8hrBVrPn1pbs5LIyKgkLW0/paVRnHzSLh5+dJJPzz7yWH2406f+xJAhe1s0QIHUao1Avx/NYgyeN6paICJ7RGSYqm7FvZX8Zl+fF5uQeEsYhX+oBRf0ONtK+CALZf+0E3GUhejJ7gGKqsVOYk63IuJd+8u/sgb7Lhd6EPacdZDku8KJmmhtSqpVXE7h2bsymftWNhYrLJ6XyK5tke2KK5i0Aq3nTy2Xy8Jz/xzLg3/6AotFWfzZIHbtieeSX39P1vYkVnzXm6GDS7nnzq/o2aOW8SfkcMmvN3DVtWcFtVaraQnw+9EcwV7DE9XAp1BERgMvAuFANnC5qpY1Fz5lRJKe+68zA5K2neN863Q2BA+B3PE40OjqjQHRWamfU6F7O9TZHZPcR48+8wafwq76101rVHVsR/TaQ5estFDV9UDAM2swGDqREPdaZjAYDD5jdjw2GAzdiy7oImsLxuAZDAa/YWp4BoOhe2C8lhkMhu6EGbQwGAzdBmPwDAZD90Axgxb+oDY7nD2zMgKk9lOAdAz+IlCTcwFe3b0sYFoAl/U9MaB6HcUMWhgMhu6DMXgGg6E7YCYeGwyG7oN27eaevmAMnsFg8B/Bbe9C02uZwWAITvzp00JEZojIVhHZLiKN9swUkRtFZLOIbBCRz0Wk1Q0AjcEzGAz+QQGX+na0gohYgWeBM4ARwEUiMuKwYOuAsap6LO6NhB9pLV5j8AwGg//wn0+LccB2Vc1W1VpgHjDTS0r1S1U9tMf+CqB3a5Eag2cwGPxGG5q0yYecdHmO2YdFlQk09HmZ47nWHL8FFraWPjNoYTAY/EYbRmlL/LXjsYjMwr2h8MmthQ1Jg3f8uAKuunYDFquy6H/9ee+tYV73Rx5bwuxrv2fAoAoeum8c33xV/8Nw3yPLGD6ijM0/JPGnO37W4bSMnVLB1ffnYbUoC99O5N1n0jocZzBoBVovVLU2LInnrT8NxOUUJl9YyFlzcrzul+ZG8MKNQzhQYcPlFH51+05GTS3DUSu8esdgdm7ogVjg13/K5qiJHXOcHej3oxH+3S0lF+jT4Ly355oXInIacBdwsqq26s+105q0IvKyiBSJyMYG1xJF5FMRyfL8TWhrvBaL8rvrvufe2yZx9aWnc/LUHPr0q/AKU1QUxWMPjWXJZ30aPf+feUN59EH/7C5vsShz5uZy98UDuHLKME6ZWU7fIdV+ibsrtQKtF6paLie8fvcgbnxtE3M/X8vK+SnkbvN20zj/qT6MO6uE+xau55pntvCvuwcBsOTtXgA88Ok6bnlzI/PuH4CrAwvvA/1+NIV74rH6dPjAKmCIiAwQkXDgQmC+l57IGOCfwDmqWuRLpJ3Zh/cqMOOwa7cDn6vqEOBz2uCe8RBDh+8lLzeGgvwYHA4LS7/ozcRJ+V5higpi2Jkd1+Rg0PdrUzl40D8V22FjDpC3M5yC3RE47BaWfBjPxOkd+5UOBq1A64WqVvb6nqT1rya1Xw22cGX82cWsW5zkFUZEOVjp9op3sNJGQprbd2xeVhRH/awcgNhkO9GxDnZu6BEU+eoQLh+PVlBVB3AtsAj4EXhXVTeJyH0ico4n2F+BHsB7IrJeROY3E10dnWbwVHUpsPewyzOB1zyfXwPObWu8SSnVlBTX/4qWFEeRlNI1nsaSetkpzqv3iVuSH0Zyuj3ktQKtF6paZQXhJGbUt6IS0msoK/T2kXzuDbtZ/t9Ubhh3Ao9dejSz/uzenKLvUVWs+zQJpwOKd0ewc2MPSvMi2pUOCPz70Rx+rOGhqgtUdaiqDlLVBz3X7lXV+Z7Pp6lqmqqO9hzntBxj4Pvw0lT1UHWsAGi2k8EzajMbINIWG4CkGQz+Z8X8FCb9qogzZueyfU1Pnr9+GA98tpaTLigkb3s0fzprNMmZNQw5vgKLNciXKbSG2fG4eVRVRZqfc62qzwPPA8RFpteFKy2OJLlBjS455SClxVGNIwgApQVhpGTU1qcl3U5JfljIawVaL1S1EnrVsrdBrawsP6KuyXqIpfPSuOn1TQAMPr4Se42F/XvDiE228+s/7qgL98D/HUuvAe1vqQT6/Wia4F9LG+h5eIUikg7g+etTR2NDtm1NIKP3ftJ6VWGzuZg8NYcV36b7PaG+sHV9NJkDaknrU4MtzMWUmeWsWBwX8lqB1gtVrQGjKincEUXx7ggctcLKj1IYc7p3L05SZg2bv4kH3P129hqhZ5KdmoMWag64//02Lo3HYlUyh7bf4AX6/WgWVd+OLiLQNbz5wKXAQ56/H7Y1ApfTwt+fHM0Df/0Gi0VZvLAfu3fGMuvyzWRtjWfltxkMGbaXex5YQY8edsZPLGDWZZu55vLTAXjkqa/o07eSyCgH/3pvAU88cjxrV7Vv+N7lFJ69K5O5b2VjscLieYns2hbZrriCSSvQeqGqZbXBrPt/4tFLRuJywkkXFJI57ADv/60vA47Zz5hpe7nw7h28ctsQFr+YCaJc8VgWIlBREsbfLjkasUBCWi2zn9gWNPlqNyHgiFu0k6ytiLwNTAGSgULgj8AHwLtAX2AXcL6qHj6w0Yi4yHSd2P/STknn4Ti3mR2PDc1zpO54vFI/p0L3SkfiiO2RqeNHXeNT2M++vWeNvyYet4VOq+Gp6kXN3Dq1szQNBkMXE9xdeKG50sJgMAQn0pHZ0wHAGDyDweAfFJ8mFXclxuAZDAa/IPg+qbirMAbPYDD4D2PwDAZDt8EYPIPB0C0wfXgGg6E7YUZpDQZDN6Frl435gjF4h1FzxgkB04pelR0wLQAS4wMmFcgVK9bkpNYD+YnfnhaYFT+HyLs1MLsW219b0fFIFGPwDAZDNyK4W7TG4BkMBv9h5uEZDIbugzF4BoOhW6AKzuBu0xqDZzAY/Iep4RkMhm6DMXgGg6FboNCkb9Qgwhg8g8HgJxTU9OH5nePHFXDVtRuwWJVF/+vPe28N87o/8tgSZl/7PQMGVfDQfeP45qvMunv3PbKM4SPK2PxDEn+642etao0buYdrL1qBVZT/fT2MtxaO8rr/q2k/cOZJW3E6hfL9UTzyykkUlvYE4JHrP2HEoCJ+yErjjqemN52XSaVcdVsWFouy6P103nu5v9d9W5iLmx/czOARlVTuC+MvtxxNUV4UqRkH+ecHK8nZGQ3A1g2xPPPAcHce/76exORarFZl09o4nps7DJer8e7dgSzH1hg7pYKr78/DalEWvp3Iu8+0bcJtwMrxcN0AluGkfru57eRlWC3K+xuP4qXVx3nd/9Uxm7ho1EacKhyoDePPn59M9t5Ezhy2jcvGrq8LNzS5lPPf+hVbi5Nb1WwTSvcdtBCRl4GzgCJVHdng+u+BOYAT+J+q3tqWeC0W5XfXfc9dN59ISXEUT/zjS1Z8k86eXfW+a4uKonjsobH88oKsRs//Z95QIiKc/PycHY3uNdISF9dd/C03/+0Misti+Mc9H/LN+r7syk+oC5O1K4mrlpxLTa2Nc6Zs5qrzvuO+f7p3sZ+36Bgiwh2cc/KW5vNy51bumj2GksIInnh7NSuWpLAnO6YuzPRf5LG/wsYVZ01k8oxC/t/1P/HQre7izM+J4vfnj2sU719uHsnBKhug3PXYRk6cVsTST7wNSCDLsTUsFmXO3FzuuHAgJflhPL0gixWL4tid5ZsTmoCW43f1332g38W7Tvma2e+fTcH+GOZd9B++zO5P9t7EujALtg7hvR+OBmDKwB3cMvlbrvngLP63dSj/2zoUgCFJpTx59if+N3aHCPI+vM500/gqMKPhBRE5BZgJjFLVo4FH2xrp0OF7ycuNoSA/BofDwtIvejNxUr5XmKKCGHZmxzXZnfD92lQOHvTNzg8fWExuUSz5JbE4nFa++G4gk8bs8gqzfmsGNbXu+DZnp5KSUFV3b+2PmRysbt436NCRFeTtjqYgN8qdl09SmXhKsVeYCVNK+Gy+2w3lsk9TGDW+jNYcB7j/ScFqU2xhriaDB7IcW2PYmAPk7QynYHcEDruFJR/GM3H6Pp+f76pyDGQZHtOriN374sipiMXhsrJw22BOGbTTK0xVbXjd56gwR5PxnDEsi4XbBvuk2S6C3E1jpxk8VV0KHO6R7BrgIVWt8YRps1/apJRqSho43i4pjiIppf3+PFsiJf4AxXvrawnFZTGkxB9oNvyZJ27ju419fI4/Ka2GksJ6R84lhREkpdY0ClPsCeNyWjiw30psvB2AXpkHefqd73j45bUcfVy513P3/309by1ZxsEqG8s+TW2sHcBybI2kXnaK8+r/WUvyw0hOt/v+fBeVYyDLMDWmioLK+nexsDKGtJiqRuEuPHYjCy57kxtPXM5fljT2eDZj6E8s3NpZBs9HY3ckGrxmGAqcJCIrReQrEWl2pb6IzBaR1SKyutbZvJEJFk6fkMWw/sXM++TYgOjtLY7g0mmT+P0F43jhr4O59aFNRMXU/6rfc81oZk2dRFi4i1HjygKSplDkSCvHeRtG8vNXL+bxZROYPW6N171jehVS7bCxvbSTNltQwOXy7egiAm3wbEAiMAG4BXhXRJr0hamqz6vqWFUdG26NrrteWhxJcoNf0eSUg5Q2+JX1J8Xl0aQk1v+KpiRUUVwe3Sjc8UflMuvM9dz59DTsDqvP8ZcWRpCcVl8TSU6robQoolGYFE8Yi9VFdA8nFeVhOOwWKve5m8vbf4wlf08Uvft5/zDYa60s/zKZCYc17yCw5dgapQVhpGTU1qcl3U5JfvNdAY2e76JyDGQZFlXF0Ktn/buY1rOKwqqYZsMv3DqEqYc1ec8Yup0FnVa782BqeF7kAO+rm+9w763Qpt7TbVsTyOi9n7ReVdhsLiZPzWHFt+mdktitO1LonVZBr+RKbFYnU8dl8+36fl5hBvct4cbfLOPOp6dRXtm2l33bpp5k9DtAWuZBd15mFLFiiXdxrFySzGnnuPuFTjy9mA3fJQBCbEItFov7xemVeZCMvgfIz4kiMspBQnL9P/a4k0rZs6PxP0Ygy7E1tq6PJnNALWl9arCFuZgys5wVi+N8fr6ryjGQZbixIJV+8eVkxlZgszg5Y+h2lvzU3ytM3/j65vjkAbvYXV5fhoIybehPfLJ1SKekz41naZkvRxch2onWVkT6Ax8fGqUVkauBDFW9V0SGAp8DfbWVRMRFpuvE/vX7kI0d75kKYFEWL+zHO28MZ9blm8naGs/KbzMYMmwv9zywgh497NTWWinbG8E1l58OwCNPfUWfvpVERjmorAjniUeOZ+2q+hHMA4MSvbTHH7OHay9cjsWiLFw2lDf+N4bLZ65h685kvv2+H3+7aQEDMveyd5+75le4twd3PT0NgKdu+4i+6fuIirBTsT+CR16dzKpNvevijl6VzdgTS7jq1iwsVmXxBxm880J/Zv0um6zNPVm5JIWwcCc3z93MoOH7qdxn4+FbR1KQG8Wk04qY9bsdOByCKrzx3EC++yqZ+MRa/vTM94SFuxALbPgugef/OhiX09JoP7zOLMe27od3wtQKrv5zLhYrLJ6XyNtP+T4txZqcFLhyjPN+PzqzDAH2nFt/flL/Xdx68jdYRfnvpuG8sOp45kz4jk1FKSzJHsBtJy9jQt8cHC4LFdURzP3yJH7yjOKO7Z3L9ZNWMOudXzZZhtmvPcbB/D1NtrZ8Jc6WohPj/8+nsItKX1ijqmM7otceOs3gicjbwBTcNbhC4I/A68DLwGigFrhZVb9oLa7DDV5ncrjB60zMBqD+IZAbgAayDMHb4HUmfjN4sef6FHZR2YtdYvA6bR6eql7UzK1ZnaVpMBi6mCCfhxeSKy0MBkMQotqlI7C+YAyewWDwH6aGZzAYugeKOp1dnYgWMQbPYDD4B7M9lMFg6FYE+fZQgZ54bDAYjlAUUJf6dPiCiMwQka0isl1Ebm/ifoSIvOO5v9Iz77dFjMEzGAz+QT0bgPpytIKIWIFngTOAEcBFIjLisGC/BcpUdTDwOPBwa/Eag2cwGPyGOp0+HT4wDtiuqtmqWgvMw721XENmAq95Pv8bOLW5tfmH6NSlZf5CRIqBXa0GbEwyUOLn5BgtoxXseu3R6qeqKR0RFZFP8H1tfCRQ3eD8eVV9vkFc5wEzVPUKz/klwHhVvbZBmI2eMDme8588YZrNe0gMWrT3ixCR1YFavmK0jFaw6AU6b4dQ1Rmth+paTJPWYDAEI7lAw910e3uuNRlGRGxAHFDaUqTG4BkMhmBkFTBERAaISDhwITD/sDDzgUO7ipwHfNHazksh0aTtAM+3HsRoGa0jTi/QefM7quoQkWuBRYAVeFlVN4nIfcBqVZ0PvAS8LiLbcbuTuLC1eENi0MJgMBj8gWnSGgyGboMxeAaDodtwxBk8EXlZRIo8c3Q6W6uPiHwpIptFZJOIXNfJepEi8p2IfO/R+3Mn61lFZJ2IfNyZOh6tnSLyg4isF5HVnawVLyL/FpEtIvKjiEz0Y9yN3j8RSRSRT0Uky/M3oaU4Oqrnuf57T/42icgj/tILQFfQZwAABctJREFUdY44g0cTDsA7EQdwk6qOwO2JbU4Ty1/8SQ0wVVVH4d4mf4aITOhEveuAHzsx/sM5RVVHB2AO2ZPAJ6o6HBiFf/P4Ko3fv9uBz1V1CG4/Lo3WhfpTzx8O749UjjiD14wD8M7SylfVtZ7Plbj/cTI7UU9Vdb/nNMxzdMqok4j0Bs4EXuyM+LsKEYkDJuMe4UNVa1W1vOWnfKeZ96/hEqjXAN8cP7Rfr8MO749UjjiD11V4dmoYA6zsZB2riKwHioBPVbWz9J4AbsXtSjMQKLBYRNaIyOxO1BkAFAOveJrrL4pI8w5e/UOaquZ7PhcAne2Zx2eH990NY/D8gIj0AP4DXK+qFZ2ppapOVR2Ne+b5OBEZ6W8NETkLKFLVNa0G9h8nqupxuHfHmCMikztJxwYcB/xdVccAVfi3idkinomxnT0XzGeH990NY/A6iIiE4TZ2b6rq+4HS9TTDvqRz+isnAeeIyE7cu1RMFZE3OkGnDlXN9fwtAv6Le7eMziAHyGlQM/43bgPYmRSKSDqA529nNzE77PD+SMUYvA7g+dV8CfhRVR8LgF6KiMR7PkcBpwNb/K2jqneoam9V7Y979voXqtpp7jVFJEZEeh76DEwDOmWUXVULgD0iMsxz6VRgc2doNaDhEqhLgQ87We8D4BQAj8P7cAK7M0zQcsQtLWvoAFxEcoA/qupLnSQ3CbgE+MHTrwZwp6r+//bOL8TKIgzjv2cRzMICw8KLguifiRSEkW20LBGSdWVQQV1EbdQGKQhdR3oVFHgjUiSSUUqJGUWxLhmyu5G0IBTuRghtdNFNmEWaEcjrxbwnT6ddz67tFnzz/K4O880375yPcx5m5pv3mU8WKN4KYHeaI/YA70XEgm8Z+Q+4GjiQs65FwJ6IGFrAeBuBdzJH8zvgyflqeLrfH/AyZVo5QLE5e2SB4+0CduVWlT+BJ7rlmNaCU8uMMdXgKa0xphoseMaYarDgGWOqwYJnjKkGC54xphoseA1A0tl0GTkmaZ+kS/9FW2/miVFk2tWMZgiS+iX1XkSM7yX9YyPsTOUddU5d6Po09V+S9MJc+2iaiQWvGZxJl5HVlH1Xg+0X84CTORMRT0fEhTbl9gNzFjxj/i8seM1jFLghR1+jkj4EJtN04BVJ45K+lvQslGwRSdslfSvpU+CqVkOSDktak5/vl3Q0vfgOpVnCILA5R5f3ZCbI/owxLunuvPdKScPpzbYT6JrXKemDNBKY6DQTkLQtyw9JWp5l10sayntGJa2cj4dpmkXjMi1qJkdy64FWlsLtwOqImErR+DUi7pC0GPhc0jDF4eVmYBUl42GSslO/vd3lwBtAX7a1LCJ+lvQacCoiXs16e4BtETEm6VrKASy3UHb/j0XEVkkPAgOz+DpPZYwlwLik/RFxAriMcojLZkkvZtvPUw6uGYyI45LuBHYA917EYzQNxoLXDJa0pbaNUvJ7e4EvI2Iqy9cBt7bW5yhneN5I8YbbGxFngR8lfTZN+2uBkVZbETGT3+B9wKo2Y47L00mmD3go7/1Y0slZfKdNkjbk52uyrycoifDvZvnbwPsZoxfY1xZ78SximMqw4DWDM2kZ9Rf5xz/dXgRsjIiDHfUemMd+9ABrI+KPafoyayT1U8Tzroj4XdJh4JIZqkfG/aXzGRjTidfw6uEg8FzaWSHppnQmGQEezTW+FaTLRgdHgD5J1+W9y7L8N2BpW71hSmI+Wa8lQCPAY1m2Huh2psMVwMkUu5WUEWaLHsqhy2SbY+lBOCXp4YwhSbd1iWEqxIJXDzsp63NH00XjdcoI/wBwPK+9BXzReWNE/AQ8Q5k+fsX5KeVHwIbWSwtgE7AmX4pMcv5t8RaKYE5QprY/dOnrELBI0jcUp5EjbddOU4xPj1HW6LZm+ePAQPZvgmKrbszfsFuKMaYaPMIzxlSDBc8YUw0WPGNMNVjwjDHVYMEzxlSDBc8YUw0WPGNMNZwDU9CFI+LpmCQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcx9_KOittKp"
      },
      "source": [
        "Comencemos la observación notando cual de los modelos logran de mejor manera detectar un electrocardiograma sano, dado un paciente sano y cuales de ellos diagnostican un electrocardiograma sano dado un paciente enfermo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9o38-2Pt7MG"
      },
      "source": [
        "En primer lugar podemos ver que el k-Neares-Neighbors logra detectar un 100% de los casos de electrocardiograma sano, sin embargo al mirar que el modelo tambien clasifica como saludable un 73% de los pacientes de clase 2, 25% de los clase 3, 75% de los clase 6, 100% de los clase 6, 53% de los clase 10 y 42% de otras patologias. Esto hace que este modelo no sea el mejor para poder diferenciar entra pacientes sanos y pacientes con alguna patología cardiaca."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWzAIGu7vDWF"
      },
      "source": [
        "Seguidamente podemos notar que los modelos de Logistic Regression y redes neuronales ambos tienen 93% de deteccion de pacientes sanos dado que el paciente estaba sano. \r\n",
        "\r\n",
        "Ante una inspeccion mas a fondo, se puede notar que los modelos se comportan de manera muy similar. Para los falsos positivos de electrocardiogramas sanos la unica diferencia es que para el caso de la Red Neuronal se predijeron erroneamenta 16% de los pacientes con otras patologías, mientras que para el caso de Logistic Regression se predijeron erroneamente 11% de los pacientes con otras patologías, haciendo el modelo de Logistic Regression ligeramente superior al de Redes Neuronales para el caso de detección de enfermedad cardiaca o no."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrelsfWTwUGw"
      },
      "source": [
        "Es por esto que basados en las metricas y en las matrices de confusion se escoge el modelo de **Logistic Regression** como el modelo que mejor soluciona el problema de clasificacion.\r\n",
        "\r\n",
        "Sin embargo, es importante saber que dependiendo de que problema se quiera resolver otros modelos pueden tener un mejor desempeño."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d567jgswTgx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}